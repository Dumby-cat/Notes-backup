[
    {
        "type": "text",
        "text": "电子工程系列丛书(影印版)",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "SIGNALS & SYSTEMS SECONDEDITION",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "信号与系统",
        "text_level": 1,
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "第2版",
        "page_idx": 0
    },
    {
        "type": "image",
        "img_path": "images/8c5b656a68fedbf75691f21f570cf17f5cb89849509716b1964f725ab2f023a6.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "ALAN V. OPPENHEIM ALAN S. WILLSKY WITH S. HAMID NAWAB",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "清华大学出版社·PRENTICE HALL http://www.tup.edu.tw.edu.cn",
        "page_idx": 0
    },
    {
        "type": "text",
        "text": "SECONDEDITION",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "SIGNALS & SYSTEMS",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "信号与系统",
        "text_level": 1,
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "第2版",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "Alan V. Oppenheim Alan S. Willsky Massachusetts Institute Technology with S. Hamid Nawab Boston University",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "清华大学出版社Prentice- Hall International, Inc.",
        "page_idx": 1
    },
    {
        "type": "text",
        "text": "(京)新登字158号",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Signals and systems 2nd ed./Alan V. Oppenheim, Alan S. Willsky with S. Hamid Nawab",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Copyright © 1997 by Alan V. Oppenheim and Alan S. Willsky",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "Original English Language Edition Published by Prentice- Hall, Inc.",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "All Rights Reserved.",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "For sale in Mainland China (only.",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本书影印版由Prentice Hall出版公司授权清华大学出版社在中国境内(不包括香港特别行政区、澳门和台湾地区)独家出版、发行。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "未经出版者书面许可,不得以任何方式复制或抄袭本书的任何部分。",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "本书封面贴有清华大学出版社激光防伪标签,无标签者不得销售。",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "北京市版权局著作权合同登记号:01- 98- 2893",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "图书在版编目(CIP)数据",
        "text_level": 1,
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "信号与系统:英文/奥本海姆(Oppenheim,A.V.)等著.- 2版.- 北京:清华大学出版社,1998.9",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "(电子工程系列丛书)",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "ISBN 7- 302- 03058- 8",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "I. 信… II. 奥… III. 信号理论-英文 IV. TN911.2",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "中国版本图书馆CIP数据核字(98)第21433号",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "出版者:清华大学出版社(北京清华大学学研楼,邮编100084)",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "http://www.tup.tsinghua.edu.cn",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "印刷者:清华大学印刷厂",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "发行者:新华书店总店北京发行所",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "开本:850×1168 1/32 印张:30.75",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "版次:1999年1月第1版 1999年12月第2次印刷",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "书号:ISBN 7- 302- 03058- 8/TN·97",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "印数:5001~10000",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "定价:44.00元",
        "page_idx": 2
    },
    {
        "type": "text",
        "text": "出版前言",
        "text_level": 1,
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "清华大学出版社与Prentice Hall出版公司合作推出的\"大学计算机教育丛书(影印版)\"和\"ATM与B- ISDN技术丛书(影印版)\"受到了广大读者的欢迎。很多读者通过电话、信函、电子邮件对我们的工作以积极评价,并提出了不少极好的建议,令我们感动和鼓舞。我们除了继续努力完善上述两套丛书以外,还将努力拓宽影印图书的专业范围,以更好地满足读者的需要。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "清华大学出版社与Prentice Hall出版公司合作推出的\"大学计算机教育丛书(影印版)\"和\"ATM与B- ISDN技术丛书(影印版)\"受到了广大读者的欢迎。很多读者通过电话、信函、电子邮件对我们的工作以积极评价,并提出了不少极好的建议,令我们感动和鼓舞。我们除了继续努力完善上述两套丛书以外,还将努力拓宽影印图书的专业范围,以更好地滿足读者的需要。电子工程是信息科学的基础,高等学校新的教学要求指出,计算机专业和电子学专业的学生应相互学习渗透到彼此的专业领域、拓宽知识面,以适应信息技术飞速发展的时代。培养通晓相关专业领域知识的人才,成为面向新世纪的理工科教育的迫切要求。为此,我们挑选了与信息科学、电子学有关的国外优秀著作,组成电子工程系列丛书(影印版),奉献给国内读者。我们希望这套新的丛书能为国内的大专院校师生和科研单位的工作人员提供新的知识和营养,也衷心期待着读者对我们一如既往的支持。",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "清华大学出版社Prentice Hall出版公司1998.12",
        "page_idx": 3
    },
    {
        "type": "text",
        "text": "ACKNOWLEDGMENTS",
        "text_level": 1,
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "In producing this second edition we were fortunate to receive the assistance of many colleagues, students, and friends who were extremely generous with their time. We express our deep appreciation to:",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Jon Maira and Ashok Papot for their help in generating many of the figures and images. Babak Ayazifar and Austin Frakt for their help in updating and assembling the bibliography.",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Ramamurthy Mani for preparing the solutions manual for the text and for his help in generating many of the figures.",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Michael Daniel for coordinating and managing the LaTeX files as the various drafts of the second edition were being produced and modified.",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "John Buck for his thorough reading of the entire draft of this second edition.",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Robert Becker, Sally Bemus, Maggie Beucler, Ben Halpern, Jon Maira, Chirag Patel, and Jerry Weinstein for their efforts in producing the various LaTeX drafts of the book.",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "And to all who helped in careful reviewing of the page proofs:",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "Babak Ayazifar Christina Lamarre Richard Barron Nicholas Laneman Rebecca Bates Li Lee George Bevis Sean Lindsay Sarit Birzon Jeffrey T. Ludwig Nabil Bitar Seth Pappas Anne Findlay Adrienne Prabler Austin Frakt Ryan Riddols Siddhartha Gupta Sekhar Tatkonda Christoforos Hadjicostis Shawn Verbout Terrence Ho Kathleen Wage Mark Ibanez Alex Wang Seema Jaggi Joseph Winograd Patrick Kreidl",
        "page_idx": 4
    },
    {
        "type": "text",
        "text": "PREFACE",
        "text_level": 1,
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "This book is the second edition of a text designed for undergraduate courses in signals and systems. While such courses are frequently found in electrical engineering curricula, the concepts and techniques that form the core of the subject are of fundamental importance in all engineering disciplines. In fact, the scope of potential and actual applications of the methods of signal and system analysis continues to expand as engineers are confronted with new challenges involving the synthesis or analysis of complex processes. For these reasons, we feel that a course in signals and systems not only is an essential element in an engineering program but also can be one of the most rewarding, exciting, and useful courses that engineering students take during their undergraduate education.",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "Our treatment of the subject of signals and systems in this second edition maintains the same general philosophy as in the first edition but with significant rewriting, restructuring, and additions. These changes are designed to help both the instructor in presenting the subject material and the student in mastering it. In the preface to the first edition we stated that our overall approach to signals and systems had been guided by the continuing developments in technologies for signal and system design and implementation, which made it increasingly important for a student to have equal familiarity with techniques suitable for analyzing and synthesizing both continuous- time and discrete- time systems. As we write the preface to this second edition, that observation and guiding principle are even more true than before. Thus, while students studying signals and systems should certainly have a solid foundation in disciplines based on the laws of physics, they must also have a firm grounding in the use of computers for the analysis of phenomena and the implementation of systems and algorithms. As a consequence, engineering curricula now reflect a blend of subjects, some involving continuous- time models and others focusing on the use of computers and discrete representations. For these reasons, signals and systems courses that bring discrete- time and continuous- time concepts together in a unified way play an increasingly important role in the education of engineering students and in their preparation for current and future developments in their chosen fields.",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "It is with these goals in mind that we have structured this book to develop in parallel the methods of analysis for continuous- time and discrete- time signals and systems. This approach also offers a distinct and extremely important pedagogical advantage. Specifically, we are able to draw on the similarities between continuous- and discrete- time methods in order to share insights and intuition developed in each domain. Similarly, we can exploit the differences between them to sharpen an understanding of the distinct properties of each.",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "In organizing the material both originally and now in the second edition, we have also considered it essential to introduce the student to some of the important uses of the basic methods that are developed in the book. Not only does this provide the student with an appreciation for the range of applications of the techniques being learned and for directions for further study, but it also helps to deepen understanding of the subject. To achieve this goal we include introductory treatments on the subjects of filtering, commu",
        "page_idx": 5
    },
    {
        "type": "text",
        "text": "nucations, sampling, discrete- time processing of continuous- time signals, and feedback. In fact, in one of the major changes in this second edition, we have introduced the concept of frequency- domain filtering very early in our treatment of Fourier analysis in order to provide both motivation for and insight into this very important topic. In addition, we have again included an up- to- date bibliography at the end of the book in order to assist the student who is interested in pursuing additional and more advanced studies of the methods and applications of signal and system analysis.",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "The organization of the book reflects our conviction that full mastery of a subject of this nature cannot be accomplished without a significant amount of practice in using and applying the tools that are developed. Consequently, in the second edition we have significantly increased the number of worked examples within each chapter. We have also enhanced one of the key assets of the first edition, namely the end- of- chapter homework problems. As in the first edition, we have included a substantial number of problems, totaling more than 600 in number. A majority of the problems included here are new and thus provide additional flexibility for the instructor in preparing homework assignments. In addition, in order to enhance the utility of the problems for both the student and the instructor we have made a number of other changes to the organization and presentation of the problems. In particular, we have organized the problems in each chapter under several specific headings, each of which spans the material in the entire chapter but with a different objective. The first two sections of problems in each chapter emphasize the mechanics of using the basic concepts and methods presented in the chapter. For the first of these two sections, which has the heading Basic Problems with Answers, we have also provided answers (but not solutions) at the end of the book. These answers provide a simple and immediate way for the student to check his or her understanding of the material. The problems in this first section are generally appropriate for inclusion in homework sets. Also, in order to give the instructor additional flexibility in assigning homework problems, we have provided a second section of Basic Problems for which answers have not been included.",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "A third section of problems in each chapter, organized under the heading of Advanced Problems, is oriented toward exploring and elaborating upon the foundations and practical implications of the material in the text. These problems often involve mathematical derivations and more sophisticated use of the concepts and methods presented in the chapter. Some chapters also include a section of Extension Problems which involve extensions of material presented in the chapter and/or involve the use of knowledge from applications that are outside the scope of the main text (such as advanced circuits or mechanical systems). The overall variety and quantity of problems in each chapter will hopefully provide students with the means to develop their understanding of the material and instructors with considerable flexibility in putting together homework sets that are tailored to the specific needs of their students. A solutions manual is also available to instructors through the publisher.",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Another significant additional enhancement to this second edition is the availability of the companion book Explorations in Signals and Systems Using MATLAB by Buck. Daniel, and Singer. This book contains MATLAB- based computer exercises for each topic in the text, and should be of great assistance to both instructor and student",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "Students using this book are assumed to have a basic background in calculus as well as some experience in manipulating complex numbers and some exposure to differential",
        "page_idx": 6
    },
    {
        "type": "text",
        "text": "equations. With this background, the book is self- contained. In particular, no prior experience with system analysis, convolution, Fourier analysis, or Laplace and z- transforms is assumed. Prior to learning the subject of signals and systems most students will have had a course such as basic circuit theory for electrical engineers or fundamentals of dynamics for mechanical engineers. Such subjects touch on some of the basic ideas that are developed more fully in this text. This background can clearly be of great value to students in providing additional perspective as they proceed through the book.",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "The Foreword, which follows this preface, is written to offer the reader motivation and perspective for the subject of signals and systems in general and our treatment of it in particular. We begin Chapter 1 by introducing some of the elementary ideas related to the mathematical representation of signals and systems. In particular we discuss transformations (such as time shifts and scaling) of the independent variable of a signal. We also introduce some of the most important and basic continuous- time and discrete- time signals, namely real and complex exponentials and the continuous- time and discrete- time unit step and unit impulse. Chapter I also introduces block diagram representations of interconnections of systems and discusses several basic system properties such as causality, linearity and time- invariance. In Chapter 2 we build on these last two properties, together with the sifting property of unit impulses to develop the convolution- sum representation for discrete- time linear, time- invariant (LTI) systems and the convolution integral representation for continuous- time LTI systems. In this treatment we use the intuition gained from our development of the discrete- time case as an aid in deriving and understanding its continuous- time counterpart. We then turn to a discussion of causal, LTI systems characterized by linear constant coefficient differential and difference equations. In this introductory discussion we review the basic ideas involved in solving linear differential equations (to which most students will have had some previous exposure) and we also provide a discussion of analogous methods for linear difference equations. However, the primary focus of our development in Chapter 2 is not on methods of solution, since more convenient approaches are developed later using transform methods. Instead, in this first look, our intent is to provide the student with some appreciation for these extremely important classes of systems, which will be encountered often in subsequent chapters. Finally, Chapter 2 concludes with a brief discussion of singularity functions—steps, impulses, doublets, and so forth—in the context of their role in the description and analysis of continuous- time LTI systems. In particular, we stress the interpretation of these signals in terms of how they are defined under convolution—that is, in terms of the responses of LTI systems to these idealized signals.",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "Chapters 3 through 6 present a thorough and self- contained development of the methods of Fourier analysis in both continuous and discrete time and together represent the most significant reorganization and revision in the second edition. In particular, as we indicated previously, we have introduced the concept of frequency- domain filtering at a much earlier point in the development in order to provide motivation for and a concrete application of the Fourier methods being developed. As in the first edition, we begin the discussions in Chapter 3 by emphasizing and illustrating the two fundamental reasons for the important role Fourier analysis plays in the study of signals and systems in both continuous and discrete time: (1) extremely broad classes of signals can be represented as weighted sums or integrals of complex exponentials, and (2) the response of an LTI system to a complex exponential input is the same exponential multiplied by a complex-",
        "page_idx": 7
    },
    {
        "type": "text",
        "text": "number characteristic of the system. However, in contrast to the first edition, the focus of attention in Chapter 3 is on Fourier series representations for periodic signals in both continuous time and discrete time. In this way we not only introduce and examine many of the properties of Fourier representations without the additional mathematical generalization required to obtain the Fourier transform for aperiodic signals, but we also can introduce the application to filtering at a very early stage in the development. In particular, taking advantage of the fact that complex exponentials are eigenfunctions of LTI systems, we introduce the frequency response of an LTI system and use it to discuss the concept of frequency- selective filtering, to introduce ideal filters, and to give several examples of nonideal filters described by differential and difference equations. In this way, with a minimum of mathematical preliminaries, we provide the student with a deeper appreciation for what a Fourier representation means and why it is such a useful construct.",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "Chapters 4 and 5 then build on the foundation provided by Chapter 3 as we develop first the continuous- time Fourier transform in Chapter 4 and, in a parallel fashion, the discrete- time Fourier transform in Chapter 5. In both chapters we derive the Fourier transform representation of an aperiodic signal as the limit of the Fourier series for a signal whose period becomes arbitrarily large. This perspective emphasizes the close relationship between Fourier series and transforms, which we develop further in subsequent sections and which allows us to transfer the intuition developed for Fourier series in Chapter 3 to the more general context of Fourier transforms. In both chapters we have included a discussion of the many important properties of Fourier transforms, with special emphasis placed on the convolution and multiplication properties. In particular, the convolution property allows us to take a second look at the topic of frequency- selective filtering, while the multiplication property serves as the starting point for our treatment of sampling and modulation in later chapters. Finally, in the last sections in Chapters 4 and 5 we use transform methods to determine the frequency responses of LTI systems described by differential and difference equations and to provide several examples illustrating how Fourier transforms can be used to compute the responses for such systems. To supplement these discussions (and later treatments of Laplace and z- transforms) we have again included an Appendix at the end of the book that contains a description of the method of partial fraction expansion.",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "Our treatment of Fourier analysis in these two chapters is characteristic of the parallel treatment we have developed. Specifically, in our discussion in Chapter 5, we are able to build on much of the insight developed in Chapter 4 for the continuous- time case, and toward the end of Chapter 5 we emphasize the complete duality in continuous- time and discrete- time Fourier representations. In addition, we bring the special nature of each domain into sharper focus by contrasting the differences between continuous- and discrete- time Fourier analysis.",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "As those familiar with the first edition will note, the lengths and scopes of Chapters 4 and 5 in the second edition are considerably smaller than their first edition counterparts. This is due not only to the fact that Fourier series are now dealt with in a separate chapter but also to our moving several topics into Chapter 6. The result, we believe, has several significant benefits. First, the presentation in three shorter chapters of the basic concepts and results of Fourier analysis, together with the introduction of the concept of frequency- selective filtering, should help the student in organizing his or her understanding of this material and in developing some intuition about the frequency domain and appreciation for its potential applications. Then, with Chapters 3- 5 as a foundation, we can engage in",
        "page_idx": 8
    },
    {
        "type": "text",
        "text": "a more detailed look at a number of important topics and applications In Chapter 6 we take a deeper look at both the time- and frequency- domain characteristics of LTI systems. For example, we introduce magnitude- phase and Bode plot representations for frequency responses and discuss the effect of frequency response phase on the time domain characteristics of the output of an LTI system. In addition, we examine the time- and frequency- domain behavior of ideal and nonideal filters and the tradeoffs between these that must be addressed in practice. We also take a careful look at first- and second- order systems and their roles as basic building blocks for more complex system synthesis and analysis in both continuous and discrete time. Finally, we discuss several other more complex examples of filters in both continuous and discrete time. These examples together with the numerous other aspects of filtering explored in the problems at the end of the chapter provide the student with some appreciation for the richness and flavor of this important subject. While each of the topics in Chapter 6 was present in the first edition, we believe that by reorganizing and collecting them in a separate chapter following the basic development of Fourier analysis, we have both simplified the introduction of this important topic in Chapters 3- 5 and presented in Chapter 6 a considerably more cohesive picture of time- and frequency- domain issues.",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "In response to suggestions and preferences expressed by many users of the first edition we have modified notation in the discussion of Fourier transforms to be more consistent with notation most typically used for continuous- time and discrete- time Fourier transforms. Specifically, beginning with Chapter 3 we now denote the continuous- time Fourier transform as  $X(j\\omega)$  and the discrete- time Fourier transform as  $X(e^{j\\omega})$ . As with all options with notation, there is not a unique best choice for the notation for Fourier transforms. However, it is our feeling, and that of many of our colleagues, that the notation used in this edition represents the preferable choice.",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Our treatment of sampling in Chapter 7 is concerned primarily with the sampling theorem and its implications. However, to place this subject in perspective we begin by discussing the general concepts of representing a continuous- time signal in terms of its samples and the reconstruction of signals using interpolation. After using frequency- domain methods to derive the sampling theorem, we consider both the frequency and time domains to provide intuition concerning the phenomenon of aliasing resulting from undersampling. One of the very important uses of sampling is in the discrete- time processing of continuous- time signals, a topic that we explore at some length in this chapter. Following this, we turn to the sampling of discrete- time signals. The basic result underlying discrete- time sampling is developed in a manner that parallels that used in continuous time, and the applications of this result to problems of decimation and interpolation are described. Again a variety of other applications, in both continuous and discrete time, are addressed in the problems.",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Once again the reader acquainted with our first edition will note a change, in this case involving the reversal in the order of the presentation of sampling and communications. We have chosen to place sampling before communications in the second edition both because we can call on simple intuition to motivate and describe the processes of sampling- and reconstruction from samples and also because this order of presentation then allows us in Chapter 8 to talk more easily about forms of communication systems that are closely related to sampling or rely fundamentally on using a sampled version of the signal to be transmitted.",
        "page_idx": 9
    },
    {
        "type": "text",
        "text": "Our treatment of communications in Chapter 8 includes an in- depth discussion of continuous- time sinusoidal amplitude modulation (AM), which begins with the straightforward application of the multiplication property to describe the effect of sinusoidal AM in the frequency domain and to suggest how the original modulating signal can be recovered. Following this, we develop a number of additional issues and applications related to sinusoidal modulation, including frequency- division multiplexing and single- sideband modulation. Many other examples and applications are described in the problems. Several additional topics are covered in Chapter 8. The first of these is amplitude modulation of a pulse train and time- division multiplexing, which has a close connection to the topic of sampling in Chapter 7. Indeed we make this tie even more explicit and provide a look into the important field of digital communications by introducing and briefly describing the topics of pulse- amplitude modulation (PAM) and intersymbol interference. Finally, our discussion of frequency modulation (FM) provides the reader with a look at a nonlinear modulation problem. Although the analysis of FM systems is not as straightforward as for the AM case, our introductory treatment indicates how frequency- domain methods can be used to gain a significant amount of insight into the characteristics of FM signals and systems. Through these discussions and the many other aspects of modulation and communications explored in the problems in this chapter we believe that the student can gain an appreciation both for the richness of the field of communications and for the central role that the tools of signals and systems analysis play in it.",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "Chapters 9 and 10 treat the Laplace and z- transforms, respectively. For the most part, we focus on the bilateral versions of these transforms, although in the last section of each chapter we discuss unilateral transforms and their use in solving differential and difference equations with nonzero initial conditions. Both chapters include discussions on: the close relationship between these transforms and Fourier transforms; the class of rational transforms and their representation in terms of poles and zeros; the region of convergence of a Laplace or z- transform and its relationship to properties of the signal with which it is associated; inverse transforms using partial fraction expansion; the geometric evaluation of system functions and frequency responses from pole- zero plots; and basic transform properties. In addition, in each chapter we examine the properties and uses of system functions for LTI systems. Included in these discussions are the determination of system functions for systems characterized by differential and difference equations; the use of system function algebra for interconnections of LTI systems; and the construction of cascade, parallel- and direct- form block- diagram representations for systems with rational system functions.",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "The tools of Laplace and z- transforms form the basis for our examination of linear feedback systems in Chapter 11. We begin this chapter by describing a number of the important uses and properties of feedback systems, including stabilizing unstable systems, designing tracking systems, and reducing system sensitivity. In subsequent sections we use the tools that we have developed in previous chapters to examine three topics that are of importance for both continuous- time and discrete- time feedback systems. These are root locus analysis, Nyquist plots and the Nyquist criterion, and log- magnitude/phase plots and the concepts of phase and gain margins for stable feedback systems.",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "The subject of signals and systems is an extraordinarily rich one, and a variety of approaches can be taken in designing an introductory course. It was our intention with the first edition and again with this second edition to provide instructors with a great deal of",
        "page_idx": 10
    },
    {
        "type": "text",
        "text": "flexibility in structuring their presentations of the subject. To obtain this flexibility and to maximize the usefulness of this book for instructors, we have chosen to present thorough, in- depth treatments of a cohesive set of topics that forms the core of most introductory courses on signals and systems. In achieving this depth we have of necessity omitted introductions to topics such as descriptions of random signals and state space models that are sometimes included in first courses on signals and systems. Traditionally, at many schools, such topics are not included in introductory courses but rather are developed in more depth in follow- on undergraduate courses or in courses explicitly devoted to their investigation. Although we have not included an introduction to state space in the book, instructors of introductory courses can easily incorporate it into the treatments of differential and difference equations that can be found throughout the book. In particular, the discussions in Chapters 9 and 10 on block diagram representations for systems with rational system functions and on unilateral transforms and their use in solving differential and difference equations with initial conditions form natural points of departure for the discussions of state- space representations.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "A typical one- semester course at the sophomore- junior level using this book would cover Chapters 1- 5 in reasonable depth (although various topics in each chapter are easily omitted at the discretion of the instructor) with selected topics chosen from the remaining chapters. For example, one possibility is to present several of the basic topics in Chapters 6- 8 together with a treatment of Laplace and z- transforms and perhaps a brief introduction to the use of system function concepts to analyze feedback systems. A variety of alternate formats are possible, including one that incorporates an introduction to state space or one in which more focus is placed on continuous- time systems by de- emphasizing Chapters 5 and 10 and the discrete- time topics in Chapters 3, 7, 8, and 11.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "In addition to these course formats this book can be used as the basic text for a thorough, two- semester sequence on linear systems. Alternatively, the portions of the book not used in a first course on signals and systems can, together with other sources, form the basis for a subsequent course. For example, much of the material in this book forms a direct bridge to subjects such as state space analysis, control systems, digital signal processing, communications and statistical signal processing. Consequently, a follow- on course can be constructed that uses some of the topics in this book together with supplementary material in order to provide an introduction to one or more of these advanced subjects. In fact, a new course following this model has been developed at MIT and has proven not only to be a popular course among our students but also a crucial component of our signals and systems curriculum.",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "As it was with the first edition, in the process of writing this book we have been fortunate to have received assistance, suggestions, and support from numerous colleagues, students and friends. The ideas and perspectives that form the heart of this book have continued to evolve as a result of our own experiences in teaching signals and systems and the influences of the many colleagues and students with whom we have worked. We would like to thank Professor Ian T. Young for his contributions to the first edition of this book and to thank and welcome Professor Hamid Nawab for the significant role he played in the development and complete restructuring of the examples and problems for this second edition. We also express our appreciation to John Buck, Michael Daniel and Andrew Singer for writing the MATLAB companion to the text. In addition, we would like to thank Jason Oppenheim for the use of one of his original photographs and Vivian Berman",
        "page_idx": 11
    },
    {
        "type": "text",
        "text": "for her ideas and help in arriving at a cover design. Also, as indicated on the acknowledgment page that follows, we are deeply grateful to the many students and colleagues who devoted a significant number of hours to a variety of aspects of the preparation of this second edition.",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "We would also like to express our sincere thanks to Mr. Ray Stata and Analog Devices, Inc. for their generous and continued support of signal processing and this text through funding of the Distinguished Professor Chair in Electrical Engineering. We also thank M.I.T. for providing support and an invigorating environment in which to develop our ideas.",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "The encouragement, patience, technical support, and enthusiasm provided by Prentice- Hall, and in particular by Marcia Horton, Tom Robbins, Don Fowley, and their predecessors and by Ralph Pescatore of TKM Productions and the production staff at Prentice- Hall, have been crucial in making this second edition a reality.",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Alan V. Oppenheim  Alan S. Willsky",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "Cambridge, Massachusetts",
        "page_idx": 12
    },
    {
        "type": "text",
        "text": "FOREWORD",
        "text_level": 1,
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "The concepts of signals and systems arise in a wide variety of fields, and the ideas and techniques associated with these concepts play an important role in such diverse areas of science and technology as communications, aeronautics and astronautics, circuit design, acoustics, seismology, biomedical engineering, energy generation and distribution systems, chemical process control, and speech processing. Although the physical nature of the signals and systems that arise in these various disciplines may be drastically different, they all have two very basic features in common. The signals, which are functions of one or more independent variables, contain information about the behavior or nature of some phenomenon, whereas the systems respond to particular signals by producing other signals or some desired behavior. Voltages and currents as a function of time in an electrical circuit are examples of signals, and a circuit is itself an example of a system, which in this case responds to applied voltages and currents. As another example, when an automobile driver depresses the accelerator pedal, the automobile responds by increasing the speed of the vehicle. In this case, the system is the automobile, the pressure on the accelerator pedal the input to the system, and the automobile speed the response. A computer program for the automated diagnosis of electrocardiograms can be viewed as a system which has as its input a digitized electrocardiogram and which produces estimates of parameters such as heart rate as outputs. A camera is a system that receives light from different sources and reflected from objects and produces a photograph. A robot arm is a system whose movements are the response to control inputs.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "In the many contexts in which signals and systems arise, there are a variety of problems and questions that are of importance. In some cases, we are presented with a specific system and are interested in characterizing it in detail to understand how it will respond to various inputs. Examples include the analysis of a circuit in order to quantify its response to different voltage and current sources and the determination of an aircraft's response characteristics both to pilot commands and to wind gusts.",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "In other problems of signal and system analysis, rather than analyzing existing systems, our interest may be focused on designing systems to process signals in particular ways. One very common context in which such problems arise is in the design of systems to enhance or restore signals that have been degraded in some way. For example, when a pilot is communicating with an air traffic control tower, the communication can be degraded by the high level of background noise in the cockpit. In this and many similar cases, it is possible to design systems that will retain the desired signal, in this case the pilot's voice, and reject (at least approximately) the unwanted signal, i.e., the noise. A similar set of objectives can also be found in the general area of image restoration and image enhancement. For example, images from deep space probes or earth- observing satellites typically represent degraded versions of the scenes being imaged because of limitation of the imaging equipment, atmospheric effects, and errors in signal transmission in returning the images to earth. Consequently, images returned from space are routinely processed by systems to compensate for some of these degradations. In addition, such images are usu",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "xxiii",
        "page_idx": 13
    },
    {
        "type": "text",
        "text": "ally processed to enhance certain features, such as lines (corresponding, for example, to river beds or faults) or regional boundaries in which there are sharp contrasts in color or darkness.",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "In addition to enhancement and restoration, in many applications there is a need to design systems to extract specific pieces of information from signals. The estimation of heart rate from an electrocardiogram is one example. Another arises in economic forecasting. We may, for example, wish to analyze the history of an economic time series, such as a set of stock market averages, in order to estimate trends and other characteristics such as seasonal variations that may be of use in making predictions about future behavior. In other applications, the focus may be on the design of signals with particular properties. Specifically, in communications applications considerable attention is paid to designing signals to meet the constraints and requirements for successful transmission. For example, long distance communication through the atmosphere requires the use of signals with frequencies in a particular part of the electromagnetic spectrum. The design of communication signals must also take into account the need for reliable reception in the presence of both distortion due to transmission through the atmosphere and interference from other signals being transmitted simultaneously by other users.",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "Another very important class of applications in which the concepts and techniques of signal and system analysis arise are those in which we wish to modify or control the characteristics of a given system, perhaps through the choice of specific input signals or by combining the system with other systems. Illustrative of this kind of application is the design of control systems to regulate chemical processing plants. Plants of this type are equipped with a variety of sensors that measure physical signals such as temperature, humidity, and chemical composition. The control system in such a plant responds to these sensor signals by adjusting quantities such as flow rates and temperature in order to regulate the ongoing chemical process. The design of aircraft autopilots and computer control systems represents another example. In this case, signals measuring aircraft speed, altitude, and heading are used by the aircraft's control system in order to adjust variables such as throttle setting and the position of the rudder and ailerons. These adjustments are made to ensure that the aircraft follows a specified course, to smooth out the aircraft's ride, and to enhance its responsiveness to pilot commands. In both this case and in the previous example of chemical process control, an important concept, referred to as feedback, plays a major role, as measured signals are fed back and used to adjust the response characteristics of a system.",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "The examples in the preceding paragraphs represent only a few of an extraordinarily wide variety of applications for the concepts of signals and systems. The importance of these concepts stems not only from the diversity of phenomena and processes in which they arise, but also from the collection of ideas, analytical techniques, and methodologies that have been and are being developed and used to solve problems involving signals and systems. The history of this development extends back over many centuries, and although most of this work was motivated by specific applications, many of these ideas have proven to be of central importance to problems in a far larger variety of contexts than those for which they were originally intended. For example, the tools of Fourier analysis, which form the basis for the frequency- domain analysis of signals and systems, and which we will develop in some detail in this book, can be traced from problems of astronomy studied by the ancient Babylonians to the development of mathematical physics in the eighteenth and nineteenth centuries.",
        "page_idx": 14
    },
    {
        "type": "text",
        "text": "In some of the examples that we have mentioned, the signals vary continuously in time, whereas in others, their evolution is described only at discrete points in time. For example, in the analysis of electrical circuits and mechanical systems we are concerned with signals that vary continuously. On the other hand, the daily closing stock market average is by its very nature a signal that evolves at discrete points in time (i.e., at the close of each day). Rather than a curve as a function of a continuous variable, then, the closing stock market average is a sequence of numbers associated with the discrete time instants at which it is specified. This distinction in the basic description of the evolution of signals and of the systems that respond to or process these signals leads naturally to two parallel frameworks for signal and system analysis, one for phenomena and processes that are described in continuous time and one for those that are described in discrete time.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "The concepts and techniques associated both with continuous- time signals and systems and with discrete- time signals and systems have a rich history and are conceptually closely related. Historically, however, because their applications have in the past been sufficiently different, they have for the most part been studied and developed somewhat separately. Continuous- time signals and systems have very strong roots in problems associated with physics and, in the more recent past, with electrical circuits and communications. The techniques of discrete- time signals and systems have strong roots in numerical analysis, statistics, and time- series analysis associated with such applications as the analysis of economic and demographic data. Over the past several decades, however, the disciplines of continuous- time and discrete- time signals and systems have become increasingly entwined and the applications have become highly interrelated. The major impetus for this has come from the dramatic advances in technology for the implementation of systems and for the generation of signals. Specifically, the continuing development of high- speed digital computers, integrated circuits, and sophisticated high- density device fabrication techniques has made it increasingly advantageous to consider processing continuous- time signals by representing them by time samples (i.e., by converting them to discrete- time signals). As one example, the computer control system for a modem high- performance aircraft digitizes sensor outputs such as vehicle speed in order to produce a sequence of sampled measurements which are then processed by the control system.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "Because of the growing interrelationship between continuous- time signals and systems and discrete- time signals and systems and because of the close relationship among the concepts and techniques associated with each, we have chosen in this text to develop the concepts of continuous- time and discrete- time signals and systems in parallel. Since many of the concepts are similar (bot not identical), by treating them in parallel, insight and intuition can be shared and both the similarities and differences between them become better focused. In addition, as will be evident as we proceed through the material, there are some concepts that are inherently easier to understand in one framework than the other and, once understood, the insight is easily transferable. Furthermore, this parallel treatment greatly facilitates our understanding of the very important practical context in which continuous and discrete time are brought together, namely the sampling of continuous- time signals and the processing of continuous- time signals using discrete- time systems.",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "As we have so far described them, the notions of signals and systems are extremely general concepts. At this level of generality, however, only the most sweeping statements can be made about the nature of signals and systems, and their properties can be discussed only in the most elementary terms. On the other hand, an important and fundamental notion in dealing with signals and systems is that by carefully choosing subclasses of each with",
        "page_idx": 15
    },
    {
        "type": "text",
        "text": "particular properties that can then be exploited, we can analyze and characterize these signals and systems in great depth. The principal focus in this book is on the particular class of linear time- invariant systems. The properties of linearity and time invariance that define this class lead to a remarkable set of concepts and techniques which are not only of major practical importance but also analytically tractable and intellectually satisfying.",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "As we have emphasized in this foreword, signal and system analysis has a long history out of which have emerged some basic techniques and fundamental principles which have extremely broad areas of application. Indeed, signal and system analysis is constantly evolving and developing in response to new problems, techniques, and opportunities. We fully expect this development to accelerate in pace as improved technology makes possible the implementation of increasingly complex systems and signal processing techniques. In the future we will see signals and systems tools and concepts applied to an expanding scope of applications. For these reasons, we feel that the topic of signal and system analysis represents a body of knowledge that is of essential concern to the scientist and engineer. We have chosen the set of topics presented in this book, the organization of the presentation, and the problems in each chapter in a way that we feel will most help the reader to obtain a solid foundation in the fundamentals of signal and system analysis; to gain an understanding of some of the very important and basic applications of these fundamentals to problems in filtering, sampling, communications, and feedback system analysis; and to develop some appreciation for an extremely powerful and broadly applicable approach to formulating and solving complex problems.",
        "page_idx": 16
    },
    {
        "type": "text",
        "text": "CONTENTS",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "PREFACE XVII ACKNOWLEDGMENTS XXV FOREWORD XXVII",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "SIGNALS AND SYSTEMS 1",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.0 Introduction 1",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.1 Continuous- Time and Discrete- Time Signals 1",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.1.1 Examples and Mathematical Representation 1 1.1.2 Signal Energy and Power 5",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.2 Transformations of the Independent Variable 7",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.2.1 Examples of Transformations of the Independent Variable 8",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.2.2 Periodic Signals 11",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.2.3 Even and Odd Signals 13",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.3 Exponential and Sinusoidal Signals 14",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.3.1 Continuous- Time Complex Exponential and Sinusoidal Signals 15",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.3.2 Discrete- Time Complex Exponential and Sinusoidal Signals 21",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.3.3 Periodicity Properties of Discrete- Time Complex Exponentials 25",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.4 The Unit Impulse and Unit Step Functions 30",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.4.1 The Discrete- Time Unit Impulse and Unit Step Sequences 30",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.4.2 The Continuous- Time Unit Step and Unit Impulse Functions 32",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.5 Continuous- Time and Discrete- Time Systems 38",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.5.1 Simple Examples of Systems 39",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.5.2 Interconnections of Systems 41",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6 Basic System Properties 44",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.1 Systems with and without Memory 44",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.2 Invertibility and Inverse Systems 45",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.3 Causality 46",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.4 Stability 48",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.5 Time Invariance 50",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.6.6 Linearity 53",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "1.7 Summary 56",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "Problems 57",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "2 LINEAR TIME-INVARIANT SYSTEMS 74",
        "text_level": 1,
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "2.0 Introduction 74",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "2.1 Discrete- Time LTI Systems: The Convolution Sum 75",
        "page_idx": 17
    },
    {
        "type": "text",
        "text": "2.1.1 The Representation of Discrete- Time Signals in Terms of Impulses 75",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.1.2 The Discrete- Time Unit Impulse Response and the Convolution- Sum Representation of LTI Systems 77",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.2 Continuous- Time LTI Systems: The Convolution Integral 90",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.2.1 The Representation of Continuous- Time Signals in Terms of Impulses 90",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.2.2 The Continuous- Time Unit Impulse Response and the Convolution Integral Representation of LTI Systems 94",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3 Properties of Linear Time- Invariant Systems 103",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.1 The Commutative Property 104",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.2 The Distributive Property 104",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.3 The Associative Property 107",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.4 LTI Systems with and without Memory 108",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.5 Invertibility of LTI Systems 109",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.6 Causality for LTI Systems 112",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.7 Stability for LTI Systems 113",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.3.8 The Unit Step Response of an LTI System 115",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.4 Causal LTI Systems Described by Differential and Difference Equations 116",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.4.1 Linear Constant- Coefficient Differential Equations 117",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.4.2 Linear Constant- Coefficient Difference Equations 121",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.4.3 Block Diagram Representations of First- Order Systems Described by Differential and Difference Equations 124",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.5 Singularity Functions 127",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.5.1 The Unit Impulse as an Idealized Short Pulse 128",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.5.2 Defining the Unit Impulse through Convolution 131",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.5.3 Unit Doublets and Other Singularity Functions 132",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "2.6 Summary 137",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "Problems 137",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3 FOURIER SERIES REPRESENTATION OF PERIODIC SIGNALS 177",
        "text_level": 1,
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.0 Introduction 177",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.1 A Historical Perspective 178",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.2 The Response of LTI Systems to Complex Exponentials 182",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.3 Fourier Series Representation of Continuous- Time Periodic Signals 186",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.3.1 Linear Combinations of Harmonically Related Complex Exponentials 186",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.3.2 Determination of the Fourier Series Representation of a Continuous- Time Periodic Signal 190",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.4 Convergence of the Fourier Series 195",
        "page_idx": 18
    },
    {
        "type": "text",
        "text": "3.5 Properties of Continuous-Time Fourier Series 202",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.5.1 Linearity 202 3.5.2 Time Shifting 202 3.5.3 Time Reversal 203 3.5.4 Time Scaling 204 3.5.5 Multiplication 204 3.5.6 Conjugation and Conjugate Symmetry 204 3.5.7 Parseval's Relation for Continuous- Time Periodic Signals 205 3.5.8 Summary of Properties of the Continuous- Time Fourier Series 205 3.5.9 Examples 205",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.6 Fourier Series Representation of Discrete-Time Periodic Signals 211",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.6.1 Linear Combinations of Harmonically Related Complex Exponentials 211 3.6.2 Determination of the Fourier Series Representation of a Periodic Signal 212",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.7 Properties of Discrete-Time Fourier Series 221",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.7.1 Multiplication 222 3.7.2 First Difference 222 3.7.3 Parseval's Relation for Discrete-Time Periodic Signals 223 3.7.4 Examples 223",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.8 Fourier Series and LTI Systems 226",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.9 Filtering 231 3.9.1 Frequency- Shaping Filters 232 3.9.2 Frequency- Selective Filters 236",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.10 Examples of Continuous-Time Filters Described by Differential Equations 239",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.10.1 A Simple RC Lowpass Filter 239 3.10.2 A Simple RC Highpass Filter 241",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.11 Examples of Discrete-Time Filters Described by Difference Equations 244",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.11.1 First- Order Recursive Discrete- Time Filters 244 3.11.2 Nonrecursivc Discrete- Time Filters 245",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "3.12 Summary 249 Problems 250",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4 THE CONTINUOUS-TIME FOURIER TRANSFORM 284",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.0 Introduction 284",
        "text_level": 1,
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.1 Representation of Aperiodic Signals: The Continuous- Time Fourier Transform 285",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.1.1 Development of the Fourier Transform Representation of an Aperiodic Signal 285",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.1.2 Convergence of Fourier Transforms 289",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.1.3 Examples of Continuous- Time Fourier Transforms 290",
        "page_idx": 19
    },
    {
        "type": "text",
        "text": "4.2 The Fourier Transform for Periodic Signals 296",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3 Properties of the Continuous-Time Fourier Transform 300",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.1 Linearity 301",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.2 Time Shifting 301",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.3 Conjugation and Conjugate Symmetry 303",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.4 Differentiation and Integration 306",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.5 Time and Frequency Scaling 308",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.6 Duality 309",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.3.7 Parseval's Relation 312",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.4 The Convolution Property 314",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.4.1 Examples 317",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.5 The Multiplication Property 322",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.5.1 Frequency- Selective Filtering with Variable Center Frequency 325",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.6 Tables of Fourier Properties and of Basic Fourier Transform Pairs 328",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.7 Systems Characterized by Linear Constant- Coefficient Differential Equations 330",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "4.8 Summary 333",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "Problems 334",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5 THE DISCRETE-TIME FOURIER TRANSFORM 358",
        "text_level": 1,
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.0 Introduction 358",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.1 Representation of Aperiodic Signals: The Discrete- Time Fourier Transform 359",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.1.1 Development of the Discrete- Time Fourier Transform 359",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.1.2 Examples of Discrete- Time Fourier Transforms 362",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.1.3 Convergence Issues Associated with the Discrete- Time Fourier Transform 366",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.2 The Fourier Transform for Periodic Signals 367",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3 Properties of the Discrete- Time Fourier Transform 372",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.1 Periodicity of the Discrete- Time Fourier Transform 373",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.2 Linearity of the Fourier Transform 373",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.3 Time Shifting and Frequency Shifting 373",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.4 Conjugation and Conjugate Symmetry 375",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.5 Differencing and Accumulation 375",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.6 Time Reversal 376",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.7 Time Expansion 377",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.8 Differentiation in Frequency 380",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.3.9 Parseval's Relation 380",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.4 The Convolution Property 382",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.4.1 Examples 383",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.5 The Multiplication Property 388",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.6 Tables of Fourier Transform Properties and Basic Fourier Transform Pairs 390",
        "page_idx": 20
    },
    {
        "type": "text",
        "text": "5.7 Duality 390",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "5.7.1 Duality in the Discrete- Time Fourier Series 391",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "5.7.2 Duality between the Discrete- Time Fourier Transform and the Continuous- Time Fourier Series 395",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "5.8 Systems Characterized by Linear Constant- Coefficient Difference Equations 396",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "5.9 Summary 399 Problems 400",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "TIME AND FREQUENCY CHIARACTERIZATION",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "OF SIGNALS AND SYSTEMS 423",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.0 Introduction 423",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.1 The Magnitude- Phase Representation of the Fourier Transform 423",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.2 The Magnitude- Phase Representation of the Frequency Response of LTI Systems 427",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.2.1 Linear and Nonlinear Phase 428",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.2.2 Group Delay 430",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.2.3 Log- Magnitude and Bode Plots 436",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.3 Time- Domain Properties of Ideal Frequency- Selective Filters 439",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.4 Time- Domain and Frequency- Domain Aspects of Nonideal Filters 444",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.5 First- Order and Second- Order Continuous- Time Systems 448",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.5.1 First- Order Continuous- Time Systems 448",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.5.2 Second- Order Continuous- Time Systems 451",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.5.3 Bode Plots for Rational Frequency Responses 456",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.6 First- Order and Second- Order Discrete- Time Systems 461",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.6.1 First- Order Discrete- Time Systems 461",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.6.2 Second- Order Discrete- Time Systems 465",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.7 Examples of Time- and Frequency- Domain Analysis of Systems 472",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.7.1 Analysis of an Automobile Suspension System 473",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.7.2 Examples of Discrete- Time Nonrecursive Filters 476",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "6.8 Summary 482",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "Problems 483",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7 SAMPLING 514",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.0 Introduction 514",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.1 Representation of a Continuous- Time Signal by Its Samples: The Sampling Theorem 515",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.1.1 Impulse- Tram Sampling 516",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.1.2 Sampling with a Zero- Order Hold 520",
        "page_idx": 21
    },
    {
        "type": "text",
        "text": "7.2 Reconstruction of a Signal from Its Samples Using Interpolation 522",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.3 The Effect of Undersampling: Aliasing 527",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.4 Discrete- Time Processing of Continuous- Time Signals 534",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.4.1 Digital Differentiator 541",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.4.2 Half- Sample Delay 543",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.5 Sampling of Discrete- Time Signals 545",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.5.1 Impulse- Train Sampling 545",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.5.2 Discrete- Time Decimation and Interpolation 549",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "7.6 Summary 555 Problems 556",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8 COMMUNICATION SYSTEMS 582",
        "text_level": 1,
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.0 Introduction 582",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.1 Complex Exponential and Sinusoidal Amplitude Modulation 583",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.1.1 Amplitude Modulation with a Complex Exponential Carrier 583",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.1.2 Amplitude Modulation with a Sinusoidal Carrier 585",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.2 Demodulation for Sinusoidal AM 587",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.2.1 Synchronous Demodulation 587",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.2.2 Asynchronous Demodulation 590",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.3 Frequency- Division Multiplexing 594",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.4 Single- Sideband Sinusoidal Amplitude Modulation 597",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.5 Amplitude Modulation with a Pulse- Train Carrier 601",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.5.1 Modulation of a Pulse- Train Carrier 601",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.5.2 Time- Division Multiplexing 604",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.6 Pulse- Amplitude Modulation 604",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.6.1 Pulse- Amplitude Modulated Signals 604",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.6.2 Intersymbol Interference in PAM Systems 607",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.6.3 Digital Pulse- Amplitude and Pulse- Code Modulation 610",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.7 Sinusoidal Frequency Modulation 611",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.7.1 Narrowband Frequency Modulation 613",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.7.2 Wideband Frequency Modulation 615",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.7.3 Periodic Square- Wave Modulating Signal 617",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.8 Discrete- Time Modulation 619",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.8.1 Discrete- Time Sinusoidal Amplitude Modulation 619",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.8.2 Discrete- Time Transmodulation 623",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "8.9 Summary 623",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "Problems 625",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "9 THE LAPLACE TRANSFORM 654",
        "text_level": 1,
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "9.0 Introduction 654",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "9.1 The Laplace Transform 655",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "9.2 The Region of Convergence for Laplace Transforms 662",
        "page_idx": 22
    },
    {
        "type": "text",
        "text": "9.3 The Inverse Laplace Transform 670 9.4 Geometric Evaluation of the Fourier Transform from the Pole- Zero Plot 674 9.4.1 First- Order Systems 676 9.4.2 Second- Order Systems 677 9.4.3 All- Pass Systems 681",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.5 Properties of the Laplace Transform 682",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.5.1 Linearity of the Laplace Transform 683 9.5.2 Time Shifting 684 9.5.3 Shifting in the s- Domain 685 9.5.4 Time Scaling 685 9.5.5 Conjugation 687 9.5.6 Convolution Property 687 9.5.7 Differentiation in the Time Domain 688 9.5.8 Differentiation in the s- Domain 688 9.5.9 Integration in the Time Domain 690 9.5.10 The Initial- and Final- Value Theorems 690 9.5.11 Table of Properties 691",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.6 Some Laplace Transform Pairs 692",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.7 Analysis and Characterization of LTl Systems Using the Laplace Transform 693",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.7.1 Causality 693",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.7.2 Stability 695",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.7.3 LTI Systems Characterized by Linear Constant- Coefficient Differential Equations 698",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.7.4 Examples Relating System Behavior to the System Function 701 9.7.5 Butterworth Filters 703",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.8 System Function Algebra and Block Diagram Representations 706",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.8.1 System Functions for Interconnections of LTI Systems 707 9.8.2 Block Diagram Representations for Causal LTI Systems Described by Differential Equations and Rational System Functions 708",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.9 The Unilateral Laplace Transform 714",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.9.1 Examples of Unilateral Laplace Transforms 714",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.9.2 Properties of the Unilateral Laplace Transform 716",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.9.3 Solving Differential Equations Using the Unilateral Laplace Transform 719",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "9.10 Summary 720 Problems 721",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "10 THE Z-TRANSFORM 741",
        "text_level": 1,
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "10.0 Introduction 741 10.1 The z- Transform 741 10.2 The Region of Convergence for the z- Transform 748",
        "page_idx": 23
    },
    {
        "type": "text",
        "text": "10.3 The Inverse z- Transform 757",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.4 Geometric Evaluation of the Fourier Transform from the Pole- Zero Plot 763",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.4 1 First- Order Systems 763 10.4.2 Second- Order Systems 765",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.5 Properties of the z- Transform 767",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.5.1 Linearity 767",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.5.2 Time Shifting 767 10.5.3 Scaling in the z- Domain 768 10.5.4 Time Reversal 769 10.5.5 Time Expansion 769 10.5.6 Conjugation 770 10.5.7 The Convolution Property 770 10.5.8 Differentiation in the z- Domain 772 10.5.9 The Initial- Value Theorem 773 10.5.10 Summary of Properties 774",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.6 Some Common z- Transform Pairs 774",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.7 Analysis and Characterization of LTI Systems Using z- Transforms 774",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.7.1 Causality 776",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.7.2 Stability 777",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.7.3 LTI Systems Characterized by Linear Constant- Coefficient Difference Equations 779",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.7.4 Examples Relating System Behavior to the System Function 78",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.8 System Function Algebra and Block Diagram",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "Representations 783",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.8.1 System Functions for Interconnections of LTI Systems 784 10 8.2 Block Diagram Representations for Causal LTI Systems Described by Difference Equations and Rational System Functions 784",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.9 The Unilateral z- Transform 789",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.9.1 Examples of Unilateral z- Transforms and Inverse Transforms 790 10 9.2 Properties of the Unilateral z- Transform 792 10 9.3 Solving Difference Equations Using the Unilateral z- Transform 795",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "10.10 Summary 796 Problems 797",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "1 LINEAR FEEDBACK SYSTEMS 816",
        "text_level": 1,
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "11.0 Introduction 816",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "11.1 Linear Feedback Systems 819",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "11.2 Some Applications and Consequences of Feedback 820",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "11.2.1 Inverse System Design 820 11.2.2 Compensation for Nonideal Elements 821 11.2.3 Stabilization of Unstable Systems 823",
        "page_idx": 24
    },
    {
        "type": "text",
        "text": "11.2.4 Sampled- Data Feedback Systems  826 11.2.5 Tracking Systems  828 11.2.6 Destabilization Causcd by Feedback  830  \n\n11.3 Root- Locus Analysis of Linear Feedback Systems  832 11.3.1 An Introductory Example  833 11.3.2 Equation for the Closed- Loop Poles  834 11.3.3 The End Points of the Root Locus: The Closed- Loop Poles for  $K = 0$  and  $|K| = +x$  836 11.3.4 The Angle Criterion  836 11 3.5 Properties of the Root Locus  841  \n\n11.4 The Nyquist Stability Criterion  846 11.4.1 The Encirclement Property  847 11.4.2 The Nyquist Criterion for Continuous- Time LTI Feedback Systems  850 11.4.3 The Nyquist Criterion for Discrete- Time LTI Feedback Systems  856",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "11.5 Gain and Phase Margins 858",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "11.6 Summary 866 Problems 867",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "APPENDIX PARTIAL- FRACTION EXPANSION 909",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "BIBLIOGRAPHY 921",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "ANSWEERS 931",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "INDEX 941",
        "page_idx": 25
    },
    {
        "type": "text",
        "text": "SIGNALS AND SYSTEMS",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "image",
        "img_path": "images/dc35ced450677eaee7aab2ad7ded0f77708d834973fe9b68a339840847219f28.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "1.0 INTRODUCTION",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "As described in the Foreword, the intuitive notions of signals and systems arise in a rich variety of contexts. Moreover, as we will see in this book, there is an analytical framework—that is, a language for describing signals and systems and an extremely powerful set of tools for analyzing them—that applies equally well to problems in many fields. In this chapter, we begin our development of the analytical framework for signals and systems by introducing their mathematical description and representations. In the chapters that follow, we build on this foundation in order to develop and describe additional concepts and methods that add considerably both to our understanding of signals and systems and to our ability to analyze and solve problems involving signals and systems that arise in a broad array of applications.",
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "1.1 CONTINUOUS-TIME AND DISCRETE-TIME SIGNALS",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "1.1.1 Examples and Mathematical Representation",
        "text_level": 1,
        "page_idx": 26
    },
    {
        "type": "text",
        "text": "Signals may describe a wide variety of physical phenomena. Although signals can be represented in many ways, in all cases the information in a signal is contained in a pattern of variations of some form. For example, consider the simple circuit in Figure 1.1. In this case, the patterns of variation over time in the source and capacitor voltages,  $\\nu_{x}$  and  $\\nu_{r}$ , are examples of signals. Similarly, as depicted in Figure 1.2, the variations over time of the applied force  $f$  and the resulting automobile velocity  $\\nu$  are signals. As another example, consider the human vocal mechanism, which produces speech by creating fluctuations in acoustic pressure. Figure 1.3 is an illustration of a recording of such a speech signal, obtained by",
        "page_idx": 26
    },
    {
        "type": "image",
        "img_path": "images/ffd4d7b4b2bcb68ae97bd249c33496fdd83a294060228297684ca497a1c37c89.jpg",
        "image_caption": [
            "Figure 1.1 A simple RC circuit with source voltage  $v_{s}$  and capacitor voltage  $v_{c}$ ."
        ],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/f8cca88e6f4881768c5d1f6022de75e2416dc2fbc6167358f9d4a4561a5b7943.jpg",
        "image_caption": [
            "Figure 1.2 An automobile responding to an applied force  $f$  from the engine and to a retarding frictional force  $\\rho v$  proportional to the automobile's velocity  $v$ ."
        ],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/44169d58a805bec1868716d734ab1cce50016de4985face3b7df8f310ac06dbf.jpg",
        "image_caption": [
            "Figure 1.3 Example of a recording of speech. [Adapted from Applications of Digital Signal Processing, A.V. Oppenheim, ed. (Englewood Cliffs, N.J.: Prentice-Hall, Inc., 1978). p. 121.] The signal represents acoustic pressure variations as a function of time for the spoken words \"should we chase.\" The top line of the figure corresponds to the word \"should,\" the second line to the word \"we,\" and the last two lines to the word \"chase.\" (We have indicated the approximate beginnings and endings of each successive sound in each word.)"
        ],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/f271e77d860a7018734b3b0d692ab0c09c2da9e27b3a6405b22f4a34b0d837b5.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 27
    },
    {
        "type": "text",
        "text": "using a microphone to sense variations in acoustic pressure, which are then converted into an electrical signal. As can be seen in the figure, different sounds correspond to different patterns in the variations of acoustic pressure, and the human vocal system produces intelligible speech by generating particular sequences of these patterns. Alternatively, for the monochromatic picture, shown in Figure 1.4, it is the pattern of variations in brightness across the image that is important.",
        "page_idx": 27
    },
    {
        "type": "image",
        "img_path": "images/f1f0023ed2c9cd88eb2ea3dae14a427978741077a1946f64f484b18054590dd9.jpg",
        "image_caption": [
            "Figure 1.4 A monochromatic picture."
        ],
        "image_footnote": [],
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "Signals are represented mathematically as functions of one or more independent variables. For example, a speech signal can be represented mathematically by acoustic pressure as a function of time, and a picture can be represented by brightness as a function of two spatial variables. In this book, we focus our attention on signals involving a single independent variable. For convenience, we will generally refer to the independent variable as time, although it may not in fact represent time in specific applications. For example, in geophysics, signals representing variations with depth of physical quantities such as density, porosity, and electrical resistivity are used to study the structure of the earth. Also, knowledge of the variations of air pressure, temperature, and wind speed with altitude are extremely important in meteorological investigations. Figure 1.5 depicts a typical example of annual average vertical wind profile as a function of height. The measured variations of wind speed with height are used in examining weather patterns, as well as wind conditions that may affect an aircraft during final approach and landing.",
        "page_idx": 28
    },
    {
        "type": "text",
        "text": "Throughout this book we will be considering two basic types of signals: continuous- time signals and discrete- time signals. In the case of continuous- time signals the independent variable is continuous, and thus these signals are defined for a continuum of values",
        "page_idx": 28
    },
    {
        "type": "image",
        "img_path": "images/d449850d97f89e47d3b5c467e5541e820db1300ffa2dca69bd0d28df54168b7e.jpg",
        "image_caption": [
            "Figure 1.5 Typical annual vertical wind profile. (Adapted from Crawford and Hudson, National Severe Storms Laboratory Report, ESSA ERLTM-NSSL 48, August 1970.)"
        ],
        "image_footnote": [],
        "page_idx": 28
    },
    {
        "type": "image",
        "img_path": "images/d2fab5534a16577f4cf06e1f167ae288a871ea9a5f02c3ced1b7bce66cebcb77.jpg",
        "image_caption": [
            "Figure 1.6 An example of a discrete-time signal: The weekly Dow-Jones stock market index from January 5, 1929, to January 4, 1930."
        ],
        "image_footnote": [],
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "of the independent variable. On the other hand, discrete- time signals are defined only at discrete times, and consequently, for these signals, the independent variable takes on only a discrete set of values. A speech signal as a function of time and atmospheric pressure as a function of altitude are examples of continuous- time signals. The weekly Dow- Jones stock market index, as illustrated in Figure 1.6, is an example of a discrete- time signal. Other examples of discrete- time signals can be found in demographic studies in which various attributes, such as average budget, crime rate, or pounds of fish caught, are tabulated against such discrete variables as family size, total population, or type of fishing vessel, respectively.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "To distinguish between continuous- time and discrete- time signals, we will use the symbol  $t$  to denote the continuous- time independent variable and  $n$  to denote the discrete- time independent variable. In addition, for continuous- time signals we will enclose the independent variable in parentheses  $(\\cdot)$ , whereas for discrete- time signals we will use brackets  $[\\cdot ]$  to enclose the independent variable. We will also have frequent occasions when it will be useful to represent signals graphically. Illustrations of a continuous- time signal  $x(t)$  and a discrete- time signal  $x[n]$  are shown in Figure 1.7. It is important to note that the discrete- time signal  $x[n]$  is defined only for integer values of the independent variable. Our choice of graphical representation for  $x[n]$  emphasizes this fact, and for further emphasis we will on occasion refer to  $x[n]$  as a discrete- time sequence.",
        "page_idx": 29
    },
    {
        "type": "text",
        "text": "A discrete- time signal  $x[n]$  may represent a phenomenon for which the independent variable is inherently discrete. Signals such as demographic data are examples of this. On the other hand, a very important class of discrete- time signals arises from the sampling of continuous- time signals. In this case, the discrete- time signal  $x[n]$  represents successive samples of an underlying phenomenon for which the independent variable is continuous. Because of their speed, computational power, and flexibility, modem digital processors are used to implement many practical systems, ranging from digital autopilots to digital audio systems. Such systems require the use of discrete- time sequences representing sampled versions of continuous- time signals—e.g., aircraft position, velocity, and heading for an",
        "page_idx": 29
    },
    {
        "type": "image",
        "img_path": "images/a9fd60c815661d7d9d595383abd933f177702df89a85fdb60c3e6b28ee852115.jpg",
        "image_caption": [
            "Figure 1.7 Graphical representations of (a) continuous-time and (b) discrete-time signals."
        ],
        "image_footnote": [],
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "autopilot or speech and music for an audio system. Also, pictures in newspapers—or in this book, for that matter—actually consist of a very fine grid of points, and each of these points represents a sample of the brightness of the corresponding point in the original image. No matter what the source of the data, however, the signal  $j[n]$  is defined only for integer values of  $n$ . It makes no more sense to refer to the  $3\\frac{1}{2}$ th sample of a digital speech signal than it does to refer to the average budget for a family with  $2\\frac{1}{2}$  family members.",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "Throughout most of this book we will treat discrete- time signals and continuous- time signals separately but in parallel, so that we can draw on insights developed in one setting to aid our understanding of another. In Chapter 7 we will return to the question of sampling, and in that context we will bring continuous- time and discrete- time concepts together in order to examine the relationship between a continuous- time signal and a discrete- time signal obtained from it by sampling.",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "1.1.2 Signal Energy and Power",
        "text_level": 1,
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "From the range of examples provided so far, we see that signals may represent a broad variety of phenomena. In many, but not all, applications, the signals we consider are directly related to physical quantities capturing power and energy in a physical system. For example, if  $\\nu (t)$  and  $i(t)$  are, respectively, the voltage and current across a resistor with resistance  $R$ , then the instantaneous power is",
        "page_idx": 30
    },
    {
        "type": "equation",
        "text": "\n$$\np(t) = \\nu (t)i(t) = \\frac{1}{R}\\nu^2 (t). \\tag{1.1}\n$$\n",
        "text_format": "latex",
        "page_idx": 30
    },
    {
        "type": "text",
        "text": "The total energy expended over the time interval  $t_{1} \\leq t \\leq t_{2}$  is",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{t_{1}}^{t_{2}}p(t)dt = \\int_{t_{1}}^{t_{2}}\\frac{1}{R}\\nu^{2}(t)dt, \\tag{1.2}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "and the average power over this time interval is",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{1}{t_{2} - t}\\int_{t_{1}}^{t_{2}}p(t)dt = \\frac{1}{t_{2} - t_{1}}\\int_{t_{1}}^{t_{2}}\\frac{1}{R}\\nu^{2}(t)dt. \\tag{1.3}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "Similarly, for the automobile depicted in Figure 1.2, the instantaneous power dissipated through friction is  $p(t) = b\\nu^{2}(t)$ , and we can then define the total energy and average power over a time interval in the same way as in eqs. (1.2) and (1.3).",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "With simple physical examples such as these as motivation, it is a conimon and worthwhile convention to use similar terminology for power and energy for any continuous- time signal  $x(t)$  or any discrete- time signal  $x[n]$ . Moreover, as we will see shortly, we will frequently find it convenient to consider signals that take on complex values in this case, the total energy over the time interval  $t_{1} \\leq t \\leq t_{2}$  in a continuous- time signal  $x(t)$  is defined as",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{t_{1}}^{t_{2}}|x(t)|^{2}dt, \\tag{1.4}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "where |x| denotes the magnitude of the (possibly complex) number x. The time- averaged power is obtained by dividing eq. (1.4) by the length,  $n - t_{1}$  of the time interval. Similarly, the total energy in a discrete- time signal  $x[n]$  over the time interval  $n_{1}\\leq n\\leq n_{2}$  is defined as",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = n_{1}}^{n_{2}}|x[n]|^{2}, \\tag{1.5}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "and dividing by the number of points in the interval,  $n_{2} - n_{1} + 1$ , yields the average power over the interval. It is important to remember that the terms \"power\" and \"energy\" are used here independently of whether the quantities in eqs. (1.4) and (1.5) actually are related to physical energy. Nevertheless, we will find it convenient to use these terms in a general fashion.",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "Furthermore, in many systems we will be interested in examining power and energy in signals over an infinite time interval, i.e., for  $- \\infty < n < +\\infty$  or for  $- \\infty < n < +\\infty$ . In these cases, we define the total energy as limits of eqs. (1.4) and (1.5) as the time interval increases without bound. That is, in continuous time,",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nE_{\\infty} \\triangleq \\lim_{T \\to \\infty} \\int_{-T}^{T} |x(t)|^{2} dt = \\int_{-\\infty}^{+\\infty} |x(t)|^{2} dt, \\tag{1.6}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "and in discrete time.",
        "page_idx": 31
    },
    {
        "type": "equation",
        "text": "\n$$\nE_{\\infty} \\triangleq \\lim_{N \\to \\infty} \\sum_{n = -N}^{+N} |x[n]|^{2} = \\sum_{n = -N}^{+\\infty} |x[n]|^{2}. \\tag{1.7}\n$$\n",
        "text_format": "latex",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "Even if such a relationship does exist, eqs. (1.4) and (1.5) may have the wrong dimensions and scalings. For example, comparing eqs. (1.2) and (1.4), we see that if  $x(t)$  represents the voltage across a resistor, then eq. (1.4) must be divided by the resistance (measured, for example, in ohms) to obtain units of physical energy.",
        "page_idx": 31
    },
    {
        "type": "text",
        "text": "Note that for some signals the integral in eq. (1.6) or sum in eq. (1.7) might not converge—e.g., if  $x(t)$  or  $x[n]$  equals a nonzero constant value for all time. Such signals have infinite energy, while signals with  $E_{\\infty} < \\infty$  have finite energy.In an analogous fashion, we can define the time- averaged power over an infinite interval as",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "In an analogous fashion, we can define the time- averaged power over an infinite interval as",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nP_{\\infty} \\triangleq \\lim_{t \\to \\infty} \\frac{1}{2T} \\int_{t}^{T} |x(t)|^{2} dt \\tag{1.8}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nP_{\\infty} \\triangleq \\lim_{N \\to \\infty} \\frac{1}{2N + 1} \\sum_{n = -N}^{+N} |x[n]|^{2} \\tag{1.9}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "in continuous time and discrete time, respectively. With these definitions, we can identify three important classes of signals. The first of these is the class of signals with finite total energy, i.e., those signals for which  $E_{\\infty} < \\infty$ . Such a signal must have zero average power, since in the continuous time case, for example, we see from eq. (1.8) that",
        "page_idx": 32
    },
    {
        "type": "equation",
        "text": "\n$$\nP_{\\infty} = \\lim_{T \\to \\infty} \\frac{E_{\\infty}}{2T} = 0. \\tag{1.10}\n$$\n",
        "text_format": "latex",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "An example of a finite- energy signal is a signal that takes on the value 1 for  $0 \\leq t \\leq 1$  and 0 otherwise. In this case,  $E_{\\infty} = 1$  and  $P_{\\infty} = 0$",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "A second class of signals are those with finite average power  $P_{\\infty}$  From what we have just seen, if  $P_{\\infty} > 0$  then, of necessity,  $E_{\\infty} = \\infty$  . This, of course, makes sense, since if there is a nonzero average energy per unit time (i.e., nonzero power), then integrating or summing this over an infinite time interval yields an infinite amount of energy. For example, the constant signal  $x[n] = 4$  has infinite energy, but average power  $P_{\\infty} = 16$  There are also signals for which neither  $P_{\\infty}$  nor  $E_{\\infty}$  are finite. A simple example is the signal  $x(t) = t$  . We will encounter other examples of signals in each of these classes in the remainder of this and the following chapters.",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "1.2 TRANSFORMATIONS OF THE INDEPENDENT VARIABLE",
        "text_level": 1,
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "A central concept in signal and system analysis is that of the transformation of a signal. For example, in an aircraft control system, signals corresponding to the actions of the pilot are transformed by electrical and mechanical systems into changes in aircraft thrust or the positions of aircraft control surfaces such as the rudder or ailerons, which in turn are transformed through the dynamics and kinematics of the vehicle into changes in aircraft velocity and heading. Also, in a high- fidelity audio system, an input signal representing music as recorded on a cassette or compact disc is modified in order to enhance desirable characteristics, to remove recording noise, or to balance the several components of the signal (e.g., treble and bass). In this section, we focus on a very limited but important class of elementary signal transformations that involve simple modification of the independent variable, i.e., the time axis. As we will see in this and subsequent sections of this chapter, these elementary transformations allow us to introduce several basic properties of signals and systems. In later chapters, we will find that they also play an important role in defining and characterizing far richer and important classes of systems.",
        "page_idx": 32
    },
    {
        "type": "text",
        "text": "1.2.1 Examples of Transformations of the Independent Variable",
        "text_level": 1,
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "A simple and very important example of transforming the independent variable of a signal is a time shift. A time shift in discrete time is illustrated in Figure 1.8, in which we have two signals  $x[n]$  and  $x[n - n_{0}]$  that are identical in shape, but that are displaced or shifted relative to each other. We will also encounter time shifts in continuous time, as illustrated in Figure 1.9, in which  $x(t - t_{0})$  represents a delayed (if  $t_{0}$  is positive) or advanced (if  $t_{1}$  is negative) version of  $x(t)$ . Signals that are related in this fashion arise in applications such as radar, sonar, and seismic signal processing, in which several receivers at different locations observe a signal being transmitted through a medium (water, rock, air, etc.) In this case, the difference in propagation time from the point of origin of the transmitted signal to any two receivers results in a time shift between the signals at the two receivers.",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "A second basic transformation of the time axis is that of time reversal. For example. as illustrated in Figure 1.10, the signal  $\\lambda [- n]$  is obtained from the signal  $x[n]$  by a reflection about  $n = 0$  (i.e., by reversing the signal). Similarly, as depicted in Figure 1.11, the signal  $x(- t)$  is obtained from the signal  $x(t)$  by a reflection about  $t = 0$ . Thus, if  $x(t)$  represents an audio tape recording, then  $x(- t)$  is the same tape recording played backward. Another transformation is that of time scaling. In Figure 1.12 we have illustrated three signals.  $x(t)$ ,  $x(2t)$ , and  $x(t / 2)$ , that are related by linear scale changes in the independent variable. If we again think of the example of  $x(t)$  as a tape recording, then  $x(2t)$  is that recording played at twice the speed, and  $x(t / 2)$  is the recording played at half- speed.",
        "page_idx": 33
    },
    {
        "type": "text",
        "text": "It is often of interest to determine the effect of transforming the independent variable of a given signal  $x(t)$  to obtain a signal of the form  $x(\\alpha t + \\beta)$ , where  $\\alpha$  and  $\\beta$  are given numbers. Such a transformation of the independent variable preserves the shape of  $x(t)$ , except that the resulting signal may be linearly stretched if  $|\\alpha | < 1$ , linearly compressed if  $|\\alpha | > 1$ , reversed in time if  $\\alpha < 0$ , and shifted in time if  $\\beta$  is nonzero. This is illustrated in the following set of examples.",
        "page_idx": 33
    },
    {
        "type": "image",
        "img_path": "images/9ffee8abfe738d0d1c20c2f6fb2cde0f281b66bbbb53203177a2575a874899a8.jpg",
        "image_caption": [
            "Figure 1.8 Discrete-time signals related by a time shift. In this figure  $n > 0$ , so that  $x[n - n_{0}]$  is a delayed version of  $x[n]$  (i.e., each point in  $x[n]$  occurs later in  $x[n - n_{0}]$ )."
        ],
        "image_footnote": [],
        "page_idx": 33
    },
    {
        "type": "image",
        "img_path": "images/6de06c68d70ca82e0d73fb2bd2768d5d50d487c036cd502846b828ad6fc64f2d.jpg",
        "image_caption": [
            "Figure 1.9 Continuous-time signals related by a time shift. In this figure  $t_0 < 0$ , so that  $x(t - t_0) \\leq \\text{an advanced version of} x(t)$  (i.e., each point in  $x(t)$  occurs at an earlier time in  $x(t - t_0)$ )"
        ],
        "image_footnote": [],
        "page_idx": 34
    },
    {
        "type": "image",
        "img_path": "images/a8a3a76e01969e8180754ffeeed5e4fcdec8042dee666cf7c44b8e433f0b519d.jpg",
        "image_caption": [
            "Figure 1.10 (a) A discrete-time signal  $x(t)$ ; (b) its reflection  $x(-t)$  about  $t = 0$ ."
        ],
        "image_footnote": [],
        "page_idx": 34
    },
    {
        "type": "image",
        "img_path": "images/cfcf7f8b1c09d43baaf0e8a78be4d4077a5d8a723411593e548b77923ff42ee5.jpg",
        "image_caption": [
            "Figure 1.11 (a) A continuous-time signal  $x(t)$ ; (b) its reflection  $x(-t)$  about  $t = 0$ ."
        ],
        "image_footnote": [],
        "page_idx": 34
    },
    {
        "type": "image",
        "img_path": "images/629862e73c38a200e0449dfc142ed19028338c55b58a40263689bd68312b70c8.jpg",
        "image_caption": [
            "Figure 1.12 Continuous-time signals related by time scaling."
        ],
        "image_footnote": [],
        "page_idx": 34
    },
    {
        "type": "text",
        "text": "Example 1.1",
        "text_level": 1,
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "Given the signal  $x(t)$  shown in Figure 1.13(a), the signal  $x(t + 1)$  corresponds to an advance (shift to the left) by one unit along the  $t$  axis as illustrated in Figure 1.13(b). Specifically, we note that the value of  $x(t)$  at  $t = t_0$  occurs in  $x(t + 1)$  at  $t = t_1 - 1$ . For",
        "page_idx": 35
    },
    {
        "type": "image",
        "img_path": "images/2d47953ff05c05e6002d4f418d9bfd531d051b073cc3c9c3389909aa10ad9ceb.jpg",
        "image_caption": [
            "Figure 1.13 (a) The continuous-time signal  $x(t)$  used in Examples 1.1-1 3 to illustrate transformations of the independent variable. (bj the time-shifted signal  $x(t + 1)$ ; (c) the signal  $x(-t + 1)$  obtained by a time shift and a time reversal; (d) the time-scaled signal  $x(\\frac{3}{2} t)$ ; and (e) the signal  $x(\\frac{3}{2} t + 1)$  obtained by time-shifting and scaling."
        ],
        "image_footnote": [],
        "page_idx": 35
    },
    {
        "type": "text",
        "text": "example, the value of  $x(t)$  at  $t = 1$  is found in  $x(t + 1)$  at  $t = 1 - 1 - 0$ . Also, since  $x(t)$  is zero for  $t< 0$ , we have  $x(t + 1)$  zero for  $t< - 1$ . Similarly, since  $x(t)$  is zero for  $t > 2$ ,  $x(t + 1)$  is zero for  $t > 1$ .",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Let us also consider the signal  $x(- t + 1)$ , which may be obtained by replacing  $t$  with  $- t$  in  $x(t + 1)$ . That is,  $x(- t + 1)$  is the time reversed version of  $x(t + 1)$ . Thus,  $x(- t + 1)$  may be obtained graphically by reflecting  $x(t + 1)$  about the  $t$  axis as shown in Figure 1.13(c).",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Example 1.2",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Given the signal  $x(t)$  shown in Figure 1.13(a), the signal  $x(\\frac{3}{2} t)$  corresponds to a linear compression of  $x(t)$  by a factor of  $\\frac{2}{3}$  as illustrated in Figure 1.13(d). Specifically we note that the value of  $x(t)$  at  $t = t_{0}$  occurs in  $x(\\frac{3}{2} t)$  at  $t = \\frac{1}{t_{0}}$ . For example, the value of  $x(t)$  at  $t = 1$  is found in  $x(\\frac{3}{2} t)$  at  $t = \\frac{2}{3}$  (1) =  $\\frac{2}{3}$ . Also, since  $x(t)$  is zero for  $t< 0$ , we have  $x(\\frac{3}{2} t)$  zero for  $t< 0$ . Similarly, since  $x(t)$  is zero for  $t > 2$ ,  $x(\\frac{3}{2} t)$  is zero for  $t > \\frac{4}{3}$ .",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Example 1.3",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "Suppose that wc would like to determine the effect of transforming the independent variable of a given signal,  $x(t)$  to obtain a signal of the form  $x(\\alpha t + \\beta)$  ,where  $\\alpha$  and  $\\beta$  are given numbers. A systematic approach to doing this is to first delay or advance  $x(t)$  in accordance with the value of  $\\beta$  and then to perform time scaling and/or time reversal on the resulting signal m accordance with the value of  $\\alpha$  . The delayed or advanced signal is linear,y stretched if  $|\\alpha |< 1$  ,linearly compressed if  $|\\alpha | > 1$  and reversed in time if  $\\alpha < 0$  0 To illustrate this approach, let us show how  $x(\\frac{3}{2} t + 1)$  may be determined for the signal  $x(t)$  shown in Figure 1.13(a). Since  $\\beta = 1$  ,we first advance (shift to the left)  $x(t)$  by 1 as shown in Figure 1.13(b). Since  $|\\alpha | = \\frac{2}{3}$  , we may linearly compress the shifted signal of Figure 1.13(b) by a factor of  $\\frac{2}{3}$  to obtain the signal shown in Figure 1.13(c).",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "In addition to their use in representing physical phenomena such as the time shift in a sonar signal and the speeding up or reversal of an audiotape, transformations of the independent variable are extremely useful in signal and system analysis. In Section 1.6 and in Chapter 2, we will use transformations of the independent variable to introduce and analyze the properties of systems. These transformations are also important in defining and examining some important properties of signals.",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "1.2.2 Periodic Signals",
        "text_level": 1,
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "An important class of signals that we will encounter frequently throughout this book is the class of periodic signals. A periodic continuous- time signal  $x(t)$  has the property that there is a positive value of  $T$  for which",
        "page_idx": 36
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = x(t + T) \\tag{1.11}\n$$\n",
        "text_format": "latex",
        "page_idx": 36
    },
    {
        "type": "text",
        "text": "for all values of  $t$ . In other words, a periodic signal has the property that it is unchanged by a time shift of  $T$ . In this case, we say that  $x(t)$  is periodic with period  $T$ . Periodic continuous- time signals arise in a variety of contexts. For example, as illustrated in Problem 2.61, the natural response of systems in which energy is conserved, such as ideal  $LC$  circuits without resistive energy dissipation and ideal mechanical systems without frictional losses, are periodic and, in fact, are composed of some of the basic periodic signals that we will introduce in Section 1.3.",
        "page_idx": 36
    },
    {
        "type": "image",
        "img_path": "images/84905563b8a78491f5dcceafcb3208be8d8f0745095c7bcce5e21099994eac71.jpg",
        "image_caption": [
            "Figure 1.14 A continuous-time periodic signal"
        ],
        "image_footnote": [],
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "An example of a periodic continuous- time signal is given in Figure 1 14. From the figure or from eq. (1.11), we can readily deduce that if  $x(t)$  is periodic with period  $T_{i}$  then  $x(t) = x(t + nT)$  for all  $t$  and for any integer m. Thus,  $x(t)$  is also periodic with period 2T,3T,4T,...The fundamental period  $T_{0}$  of  $x(t)$  is the smallest positive value of  $T$  for which eq. (1.11) holds. This definition of the fundamental period works, except if  $x(t)$  is a constant. In this case the fundamental period is undefined, since  $x(t)$  is periodic for any choice of  $T$  (so there is no smallest positive value). A signal  $x(t)$  that is not periodic will be referred to as an aperiodic signal.",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "Periodic signals are defined analogously in discrete time. Specifically, a discrete- time signal  $x[n]$  is periodic with period  $N$ , where  $N$  is a positive integer, if it is unchanged by a time shift of  $N$ , i.e., if",
        "page_idx": 37
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = x[n + N] \\tag{1.12}\n$$\n",
        "text_format": "latex",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "for all values of n.If eq.1.12) holds, then  $x[n]$  is also periodic with period 2N,3A,.. The fundamental period  $N_{0}$  is the smallest positive value of  $N$  for which cq.(1.12) holds. An example of a discrete- time periodic signal with fundamental period  $N_{0} = 3$  is shown in Figure 1.15.",
        "page_idx": 37
    },
    {
        "type": "image",
        "img_path": "images/9773df2075a540ad44f1b55b5aa7a215b6f9e57820f9f53af37b2bc885ae945e.jpg",
        "image_caption": [
            "Figure 1.15 A discrete-time periodic signal with fundamental period  $N_{0} = 3$ ."
        ],
        "image_footnote": [],
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "Example 1.4",
        "text_level": 1,
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "Let us illustrate the type of problem solving that may be required in determining whether or not a given signal is periodic. The signal whose periodicity we wish to check is given by",
        "page_idx": 37
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = \\left\\{ \\begin{array}{ll}\\cos (t) & \\text{if} t < 0 \\\\ \\sin (t) & \\text{if} t \\geq 0 \\end{array} \\right. \\tag{1 13}\n$$\n",
        "text_format": "latex",
        "page_idx": 37
    },
    {
        "type": "text",
        "text": "From trigonometry, we know that cos(t + 2π) = cos(t) and sin(t + 2π) - sin(t). Thus, considering t > 0 and t < 0 separately, we see that x(t) does repeat itself over every interval of length 2π. However, as illustrated in Figure 1 16, x(t) also has a discontinuity at the time origin that does not recur at any other time. Since every feature in the shape of a periodic signal must recur periodically, we conclude that the signal x(t) is not periodic.",
        "page_idx": 37
    },
    {
        "type": "image",
        "img_path": "images/dec0931bcdfc23593fa210980c1f9dc759dca30d5761e09bda9897bc74973c37.jpg",
        "image_caption": [
            "Figure 1.16 The signal  $x(t)$  considered in Example 1.4."
        ],
        "image_footnote": [],
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "1.2.3 Even and Odd Signals",
        "text_level": 1,
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "Another set of useful properties of signals relates to their symmetry under time reversal. A signal  $x(t)$  or  $x[n]$  is referred to as an even signal if it is identical to its time- reversed counterpart, i.e., with its reflection about the origin. In continuous time a signal is even if",
        "page_idx": 38
    },
    {
        "type": "equation",
        "text": "\n$$\nx(-t) = x(t), \\tag{1.14}\n$$\n",
        "text_format": "latex",
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "while a discrete- time signal is even if",
        "page_idx": 38
    },
    {
        "type": "equation",
        "text": "\n$$\nx[-n] = x[n]. \\tag{1 15}\n$$\n",
        "text_format": "latex",
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "A signal is referred to as odd if",
        "page_idx": 38
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}{x(-t) = -x(t),}\\\\ {x[-n] = -x[n].} \\end{array} \\tag{1.16}\n$$\n",
        "text_format": "latex",
        "page_idx": 38
    },
    {
        "type": "text",
        "text": "An odd signal must necessarily be 0 at  $t = 0$  or  $n = 0$ , since eqs. (1.16) and (1.17) require that  $x(0) = - x(0)$  and  $x[0] = - x[0]$ . Examples of even and odd continuous- time signals are shown in Figure 1.17.",
        "page_idx": 38
    },
    {
        "type": "image",
        "img_path": "images/15075a44ba51aedc9de315173149e50a7ed45dfd7eb72caba8322bc64447912c.jpg",
        "image_caption": [
            "Figure 1.17 (a) An even continuous-time signal; (b) an odd continuous-time signal."
        ],
        "image_footnote": [],
        "page_idx": 38
    },
    {
        "type": "image",
        "img_path": "images/55ea71d5c277429a1d2a64fc4fdcf41d9199ebc3cc2101c939389114a58bfbe5.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 39
    },
    {
        "type": "image",
        "img_path": "images/41fd66bc581594d22cdef4edb08b18512ff1378e9dbf48ef9f89d67b7ccba91d.jpg",
        "image_caption": [
            "Figure 1.18 Example of the even-odd decomposition of a discrete-time signal."
        ],
        "image_footnote": [],
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "An important fact is that any signal can be broken into a sum of two signals, one of which is even and one of which is odd. To see this, consider the signal",
        "page_idx": 39
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta \\nu \\{x(t)\\} = \\frac{1}{2} [x(t) + x(-t)], \\tag{1.18}\n$$\n",
        "text_format": "latex",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "which is referred to as the even part of  $x(t)$ . Similarly, the odd part of  $x(t)$  is given by",
        "page_idx": 39
    },
    {
        "type": "equation",
        "text": "\n$$\n\\theta d\\{x(t)\\} = \\frac{1}{2} [x(t) - x(-t)]. \\tag{1.19}\n$$\n",
        "text_format": "latex",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "It is a simple exercise to check that the even part is in fact even, that the odd part is odd, and that  $x(t)$  is the sum of the two. Exactly analogous definitions hold in the discrete- time case. An example of the even- odd decomposition of a discrete- time signal is given in Figure 1.18.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "1.3 EXPONENTIAL AND SINUSOIDAL SIGNALS",
        "text_level": 1,
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "In this section and the next, we introduce several basic continuous- time and discrete- time signals. Not only do these signals occur frequently, but they also serve as basic building blocks from which we can construct many other signals.",
        "page_idx": 39
    },
    {
        "type": "text",
        "text": "1.3.1 Continuous-Time Complex Exponential and Sinusoidal Signals",
        "text_level": 1,
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "The continuous- time complex exponential signal is of the form",
        "page_idx": 40
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = C e^{a t}, \\tag{1.20}\n$$\n",
        "text_format": "latex",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "where  $c$  and  $\\pmb{a}$  are, in general, complex numbers. Depending upon the values of these parameters, the complex exponential can exhibit several different characteristics.",
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "Real Exponential Signals",
        "text_level": 1,
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "As illustrated in Figure 1.19, if  $c$  and  $\\pmb{a}$  are real [in which case  $\\pmb {x}(t)$  is called a real exponential], there are basically two types of behavior. If  $\\pmb{a}$  is positive, then as t increases  $\\pmb {x}(t)$  is a growing exponential, a form that is used in describing many different physical processes, including chain reactions in atomic explosions and complex chemical reactions. If  $\\pmb{a}$  is negative. then  $\\pmb {x}(t)$  is a decaying exponential, a signal that is also used to describe a wide variety of phenomena, including the process of radioactive decay and the responses of RC circuits and damped mechanical systems. In particular, as shown in Problems 2.61 and 2.62, the natural responses of the circuit in Figure 1.1 and the automobile in Figure 1.2 are decaying exponentials. Also, we note that for  $\\pmb {a} = \\pmb {0},$ $\\pmb {x}(t)$  is constant.",
        "page_idx": 40
    },
    {
        "type": "image",
        "img_path": "images/c6b90f774b82cd30dc89860c51e5ceb64f8b269df3d3166b0dbf8b1237e3d0be.jpg",
        "image_caption": [
            "Figure 1.19 Continuous-time real exponential  $x(t) = C e^{a t}$  : (a)  $a > 0$  (b)  $a< 0$"
        ],
        "image_footnote": [],
        "page_idx": 40
    },
    {
        "type": "text",
        "text": "Periodic Complex Exponential and Sinusoidal Signals",
        "text_level": 1,
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "A second important class of complex exponentials is obtained by constraining a to be purely imaginary. Specifically, consider",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = e^{j\\omega_{0}t}. \\tag{1.21}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "An important property of this signal is that it is periodic. To verify this, we recall from eq (1.11) that  $x(t)$  will be periodic with period  $\\pmb{T}$  if",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}t} = e^{j\\omega_{0}(t\\cdot T)}. \\tag{1.22}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "Or, since",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}t + T} = e^{j\\omega_{0}t}e^{j\\omega_{0}T},\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "it follows that for periodicity, we must have",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}T} = 1. \\tag{1.23}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "If  $\\omega_{0} = 0$  then  $x(t) = 1$  which is periodic for any value of  $\\pmb{T}$  If  $\\omega_{0}\\neq 0$  then the fundamental period  $T_{0}$  of  $\\pmb {x}(t)$  that is, the smallest positive value of  $\\pmb{T}$  for which eq. (1.23) holds- is",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nT_{0} = \\frac{2\\pi}{|u_{0}|}, \\tag{1.24}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "Thus, the signals  $e^{j\\omega_{0}t}$  and  $e^{- j\\omega_{0}t}$  have the same fundamental period.",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "A signal closely related to the periodic complex exponential is the sinusoidal signal",
        "page_idx": 41
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = A cos(wo + Φ), \\tag{1.25}\n$$\n",
        "text_format": "latex",
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "as illustrated in Figure 1.20. With seconds as the units of t, the units of  $\\phi$  and  $\\omega_{0}$  are radians and radians per second, respectively. It is also common to write  $\\omega_{0} = 2\\pi f_{0}$  where  $f_{\\parallel}$  has the units of cycles per second, or hertz (Hz). Like the complex exponential signal, the sinusoidal signal is periodic with fundamental period  $T_{0}$  given by eq. (1.24). Sinusoidal and",
        "page_idx": 41
    },
    {
        "type": "image",
        "img_path": "images/c367cd6269a1789ba4727f029d444f8d65ddbc97c52e78e811239acf402e0b29.jpg",
        "image_caption": [
            "Figure 1.20 Continuous-time sinusoidal signal."
        ],
        "image_footnote": [],
        "page_idx": 41
    },
    {
        "type": "text",
        "text": "complex exponential signals are also used to describe the characteristics of many physical processes- in particular, physical systems in which energy is conserved. For example, as shown in Problem 2.61, the natural response of an LC circuit is sinusoidal, as is the simple harmonic motion of a mechanical system consisting of a mass connected by a spring to a stationary support. The acoustic pressure variations corresponding to a single musical tone are also sinusoidal.",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "By using Euler's relation,² the complex exponential in eq. (1.21) can be written in terms of sinusoidal signals with the same fundamental period:",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}t} = \\cos \\omega_{0}t + j\\sin \\omega_{0}t. \\tag{1.26}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "Similarly, the sinusoidal signal of eq. (1.25) can be written in terms of periodic complex exponentials, again with the same fundamental period:",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nA\\cos (\\omega_{0}t + \\phi) = \\frac{A}{2} e^{j\\phi}e^{j\\omega_{0}t} + \\frac{A}{2} e^{-j\\phi}e^{-j\\omega_{0}t}. \\tag{1.27}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "Note that the two exponentials in eq. (1.27) have complex amplitudes. Alternatively, we can express a sinusoid in terms of a complex exponential signal as",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nA\\cos (\\omega_{0}t + \\phi) = A\\{Re\\{e^{j(\\omega_{0}t + \\phi)}\\} \\} , \\tag{1.28}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "where, if  $c$  is a complex number,  $\\{Re\\{c\\}\\}$  denotes its real part. We will also use the notation  $\\{m\\} \\{c\\}$  for the imaginary part of  $c$ , so that, for example,",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\nA\\sin (\\omega_{0}t + \\phi) = A\\{m\\{e^{j(\\omega_{0}t + \\phi)}\\} \\} . \\tag{1.29}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "From eq. (1.24), we see that the fundamental period  $T_{0}$  of a continuous- time sinusoidal signal or a periodic complex exponential is inversely proportional to  $|\\omega_{0}|$ . which we will refer to as the fundamental frequency. From Figure 1.21, we see graphically what this means. If we decrease the magnitude of  $\\omega_{0}$ , we slow down the rate of oscillation and therefore increase the period. Exactly the opposite effects occur if we increase the magnitude of  $\\omega_{0}$ . Consider now the case  $\\omega_{0} = 0$ . In this case, as we mentioned earlier,  $x(t)$  is constant and therefore is periodic with period  $T$  for any positive value of  $T$ . Thus, the fundamental period of a constant signal is undefined. On the other hand, there is no ambiguity in defining the fundamental frequency of a constant signal to be zero. That is, a constant signal has a zero rate of oscillation.",
        "page_idx": 42
    },
    {
        "type": "text",
        "text": "Periodic signals—and in particular, the complex periodic exponential signal in eq. (1.21) and the sinusoidal signal in eq. (1.25)—provide important examples of signals with infinite total energy but finite average power. For example, consider the periodic exponential signal of eq. (1.21), and suppose that we calculate the total energy and average power in this signal over one period:",
        "page_idx": 42
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}{{\\mathcal{E}_{p e n o d}=\\int_{0}^{T_{0}}\\left\\{e^{j\\omega_{0}t}\\right\\}^{2}d t}}\\\\ {{=\\int_{0}^{T_{0}}\\mathrm{i}\\cdot d t=T_{0},}}\\end{array} \\tag{1.30}\n$$\n",
        "text_format": "latex",
        "page_idx": 42
    },
    {
        "type": "image",
        "img_path": "images/38658f3afbc5074f57dc9891cf788057143c9ac6bd98ced27cc1abaaf92934a3.jpg",
        "image_caption": [
            "Figure 1.21 Relationship between the fundamental frequency and period for continuous-time sinusoidal signals; here,  $\\omega_{1} > \\omega_{2} > \\omega_{3}$ , which implies that  $T_{1} < T_{2} < T_{3}$ ."
        ],
        "image_footnote": [],
        "page_idx": 43
    },
    {
        "type": "equation",
        "text": "\n$$\nP_{\\mathrm{pertud}} = \\frac{1}{T_{0}} E_{\\mathrm{pertud}} = 1. \\tag{1 31}\n$$\n",
        "text_format": "latex",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "Since there are an infinite number of periods as  $t$  ranges from  $- \\infty$  to  $+\\infty$ , the total energy integrated over all time is infinite. However, each period of the signal looks exactly the same. Since the average power of the signal equals 1 over each period, averaging over multiple periods always yields an average power of 1. That is, the complex periodic ex-",
        "page_idx": 43
    },
    {
        "type": "text",
        "text": "potential signal has finite average power equal to",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\nP_{\\mathrm{c}} = \\lim_{T\\rightarrow \\infty}\\frac{1}{2T}\\int_{T}^{T}|e^{i\\omega t}|^{2}d t = 1. \\tag{1.32}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Problem 1.3 provides additional examples of energy and power calculations for periodic and aperiodic signals.",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Periodic complex exponentials will play a central role in much of our treatment of signals and systems, in part because they serve as extremely useful building blocks for many other signals. We will often find it useful to consider sets of harmonically related complex exponentials—that is, sets of periodic exponentials, all of which are periodic with a common period  $T_{0}$ . Specifically, a necessary condition for a complex exponential  $e^{j\\omega t}$  to be periodic with period  $T_{0}$  is that",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega T_{0}} = 1, \\tag{1.33}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "which implies that  $\\omega T_{0}$  is a multiple of  $2\\pi$ , i.e.,",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\n\\omega T_{0} = 2\\pi k, \\qquad k = 0, \\pm 1, \\pm 2, \\ldots \\tag{1.34}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Thus, if we define",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\n\\omega_{0} = \\frac{2\\pi}{T_{0}}, \\tag{1.35}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "we see that, to satisfy eq. (1.34),  $\\omega$  must be an integer multiple of  $\\omega_{0}$ . That is, a harmonically related set of complex exponentials is a set of periodic exponentials with fundamental frequencies that are all multiples of a single positive frequency  $\\omega_{0}$ :",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\n\\phi_{k}(t) = e^{j k\\omega_{k}t}, \\qquad k = 0, \\pm 1, \\pm 2, \\ldots \\tag{1.36}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "For  $k = 0$ ,  $\\phi_{k}(t)$  is a constant, while for any other value of  $k$ ,  $\\phi_{k}(t)$  is periodic with fundamental frequency  $|k|\\omega_{0}$  and fundamental period",
        "page_idx": 44
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{2\\pi}{|k|\\omega_{0}} = \\frac{T_{0}}{|k|} \\tag{1.37}\n$$\n",
        "text_format": "latex",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "The  $k$ th harmonic  $\\phi_{k}(t)$  is still periodic with period  $T_{0}$  as well, as it goes through exactly  $|k|$  of its fundamental periods during any time interval of length  $T_{0}$ .",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Our use of the term \"harmonic\" is consistent with its use in music, where it refers to tones resulting from variations in acoustic pressure at frequencies that are integer multiples of a fundamental frequency. For example, the pattern of vibrations of a string on an instrument such as a violin can be described as a superposition—i.e., a weighted sum—of harmonically related periodic exponentials. In Chapter 3, we will see that we can build a very rich class of periodic signals using the harmonically related signals of eq. (1.36) as the building blocks.",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "Example 1.5",
        "text_level": 1,
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "It is sometimes desirable to express the sum of two complex exponentials as the product of a single complex exponential and a single sinusoid. For example, suppose we wish to",
        "page_idx": 44
    },
    {
        "type": "text",
        "text": "plot the magnitude of the signal",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = e^{i2t} + e^{i3t}. \\tag{1.38}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "To do this, we first factor out a complex exponential from the right side of eq. (1.35), where the frequency of this exponential factor is taken as the average of the frequencies of the two exponentials in the sum. Doing this, we obtain",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = e^{i2t} (e^{-i\\theta} + e^{i3t}), \\tag{1.39}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "which, because of Euler's relation, can be rewritten as",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = 2e^{i2t} \\cos (0.5t). \\tag{1.40}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "From this, we can directly obtain an expression for the magnitude of  $x(t)$ :",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\n|x(t)| = 2|\\cos (0.5t)| \\tag{1.41}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "Here, we have used the fact that the magnitude of the complex exponential  $e^{i2t}$  is always unity. Thus,  $\\{x(t)\\}$  is what is commonly referred to as a full- wave rectified sinusoid, as shown in Figure 1.22.",
        "page_idx": 45
    },
    {
        "type": "image",
        "img_path": "images/1808af31fd2d01a02799155946ecb131b17ac06d35cf806d015098367bfe5ad2.jpg",
        "image_caption": [
            "Figure 1.22 The full-wave rectified sinusoid of Example 1.5."
        ],
        "image_footnote": [],
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "General Complex Exponential Signals",
        "text_level": 1,
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "The most general case of a complex exponential can be expressed and interpreted in terms of the two cases we have examined so far: the real exponential and the periodic complex exponential. Specifically, consider a complex exponential  $C e^{i\\theta}$ , where  $C$  is expressed in polar form and  $a$  in rectangular form. That is,",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nC = \\{C|e^{i\\theta}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\na = r + j\\omega_{0}.\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "Then",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nC e^{a t} = \\{C|e^{j\\theta}e^{(r + j\\omega_{0})t} = |C|e^{i\\theta}e^{j(\\omega_{0}t + \\theta)}. \\tag{1.42}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "Using Euler's relation, we can expand this further as",
        "page_idx": 45
    },
    {
        "type": "equation",
        "text": "\n$$\nC e^{a t} = \\{C|e^{r t} \\cos (\\omega_{0} t + \\theta) + j|C|e^{r t} \\sin (\\omega_{0} t + \\theta). \\tag{1.43}\n$$\n",
        "text_format": "latex",
        "page_idx": 45
    },
    {
        "type": "text",
        "text": "Thus. for  $r = 0$  the real and imaginary parts of a complex exponential are sinusoidal. For  $r > 0$  they correspond to sinusoidal signals multiplied by a growing exponential, and for  $r< 0$  they correspond to sinusoidal signals multiplied by a decaying exponential. These two cases are shown in Figure 1.23. The dashed lines in the figure correspond to the functions  $\\pm |C|e^{r t}$  From eq. (1.42), we see that  $|C|e^{r t}$  is the magnitude of the complex exponential. Thus, the dashed curves act as an envelope for the oscillatory curve in the figure in that the peaks of the oscillations just reach these curves, and in this way the envelope provides us with a convenient way to visualize the general trend in the amplitude of the oscillations.",
        "page_idx": 46
    },
    {
        "type": "image",
        "img_path": "images/c657a38ac98dafbbf72f0fd3389af0a35e9963d276734daadd531d0067f45e1e.jpg",
        "image_caption": [
            "Figure 1.23 (a) Growing sinusoidal signal  $x(t) = C e^{r t}\\cos (u_{0}t + \\theta)$ ,  $r > 0$ ; (b) decaying sinusoid  $x(t) = C e^{r t}\\cos (u_{0}t + \\theta)$ ,  $r< 0$"
        ],
        "image_footnote": [],
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "Sinusoidal signals multiplied by decaying exponentials are commonly referred to as damped sinusoids. Examples of damped sinusoids arise in the response of RLC circuits and in mechanical systems containing both damping and restoring forces, such as automotive suspension systems. These kinds of systems have mechanisms that dissipate energy (resistors, damping forces such as friction) with oscillations that decay in time. Examples illustrating such systems and their damped sinusoidal natural responses can be found in Problems 2.61 and 2.62.",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "1.3.2 Discrete-Time Complex Exponential and Sinusoidal Signals",
        "text_level": 1,
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "As in continuous time, an important signal in discrete time is the complex exponential signal or sequence, defined by",
        "page_idx": 46
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] - C\\alpha^{n}. \\tag{1.44}\n$$\n",
        "text_format": "latex",
        "page_idx": 46
    },
    {
        "type": "text",
        "text": "where  $C$  and  $\\alpha$  are, in general, complex numbers. This could alternatively be expressed in the form",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = C e^{\\beta \\pi}. \\tag{1.45}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "where",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\n\\alpha = e^{\\beta}.\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Although the form of the discrete- time complex exponential sequence given in eq. (1.45) is more analogous to the form of the continuous- time exponential, it is often more convenient to express the discrete- time complex exponential sequence in the form of eq (1.42).",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Real Exponential Signals",
        "text_level": 1,
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "If  $c$  and  $\\alpha$  are real, we can have one of several types of behavior, as illustrated in Figure 1.24. If  $|\\alpha | > 1$  the magnitude of the signal grows exponentially with n, while if  $|\\alpha |< 1$  we have a decaying exponential. Furthermore, if  $\\alpha$  is positive, all the values of  $\\cos \\pi$  are of the same sign, but if  $\\alpha$  is negative then the sign of  $x[n]$  alternates. Note also that if  $\\alpha = \\mathrm{i}$  then  $x[n]$  is a constant, whereas if  $\\alpha = - 1$ $x[n]$  alternates in value between  $- c$  and  $- c$  Real- valued discrete- time exponentials are often used to describe population growth as a function of generation and total return on investment as a function of day, month, or quarter.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Sinusoidal Signals",
        "text_level": 1,
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "Another important complex exponential is obtained by using the form given in eq. (1.45) and by constraining  $\\beta$  to be purely imaginary (so that  $|\\alpha | = 1$ ). Specifically, consider",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = e^{j\\omega_{0}n}. \\tag{1.46}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "As in the continuous- time case, this signal is closely related to the sinusoidal signal",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = A\\cos (\\omega_{0}n + \\phi). \\tag{1.47}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "If we take  $n$  to be dimensionless, then both  $\\omega_{0}$  and  $\\phi$  have units of radians. Three examples of sinusoidal sequences are shown in Figure 1.25.",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "As before, Euler's relation allows us to relate complex exponentials and sinusoids:",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}n} = \\cos \\omega_{0}n + j\\sin \\omega_{0}n \\tag{1.48}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 47
    },
    {
        "type": "equation",
        "text": "\n$$\nA\\cos (\\omega_{0}n + \\phi) = \\frac{A}{2} e^{j\\phi}e^{j\\omega_{0}n} + \\frac{A}{2} e^{-j\\phi}e^{-j\\omega_{0}n}. \\tag{1.49}\n$$\n",
        "text_format": "latex",
        "page_idx": 47
    },
    {
        "type": "text",
        "text": "The signals in eqs. (1.46) and (1.47) are examples of discrete- time signals with infinite total energy but finite average power. For example, since  $|e^{j\\omega_{0}n}|^{2} = 1$ , every sample of the signal in eq. (1.46) contributes  $j$  to the signal's energy. Thus, the total energy for  $- \\infty < n < \\infty$  is infinite, while the average power per time point is obviously equal to 1. Other examples of energy and power calculations for discrete- time signals are given in Problem 1.3.",
        "page_idx": 47
    },
    {
        "type": "image",
        "img_path": "images/9ab487018fe1612bf6ba909307e9c4aba3126ed2a30c886c98e4cd1c1978afa6.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 48
    },
    {
        "type": "image",
        "img_path": "images/701d1d5ea5fbab122cc1f03c4594f9cd82ea0be8183e63edd2838200e8015aa6.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "General Complex Exponential Signals",
        "text_level": 1,
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "The general discrete- time complex exponential can be written and interpreted in terms of real exponentials and sinusoidal signals. Specifically, if we write  $C$  and  $\\alpha$  in polar form,",
        "page_idx": 49
    },
    {
        "type": "text",
        "text": "viz.,",
        "page_idx": 50
    },
    {
        "type": "equation",
        "text": "\n$$\nC = |C|e^{j\\theta}\n$$\n",
        "text_format": "latex",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 50
    },
    {
        "type": "equation",
        "text": "\n$$\n\\alpha = |\\alpha |e^{i\\omega_{0}},\n$$\n",
        "text_format": "latex",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "then",
        "page_idx": 50
    },
    {
        "type": "equation",
        "text": "\n$$\nC\\alpha^{n} = |C||\\alpha |^{n}\\cos (\\omega_{0}n + \\theta) + j|C||\\alpha |^{n}\\sin (\\omega_{0}n + \\theta) \\tag{1.50}\n$$\n",
        "text_format": "latex",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "Thus, for  $|\\alpha | = 1$ , the real and imaginary parts of a complex exponential sequence are sinusoidal. For  $|\\alpha |< 1$  they correspond to sinusoidal sequences multiplied by a decaying exponential, while for  $|\\alpha | > 1$  they correspond to sinusoidal sequences multiplied by a growing exponential. Examples of these signals are depicted in Figure 1.26.",
        "page_idx": 50
    },
    {
        "type": "image",
        "img_path": "images/1c2215c1cfcf3b8812c623200faf075f70c1555253d92b59198bd311d57e00be.jpg",
        "image_caption": [
            "Figure 1.26 (a) Growing discrete-time sinusoidal signals; (b) decaying discrete-time sinusoid."
        ],
        "image_footnote": [],
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "1.3.3 Periodicity Properties of Discrete-Time Complex Exponentials",
        "text_level": 1,
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "While there are many similarities between continuous- time and discrete- time signals, there are also a number of important differences. One of these concerns the discrete- time exponential signal  $e^{j\\omega_{0}n}$ . In Section 1.3.1, we identified the following two properties of its",
        "page_idx": 50
    },
    {
        "type": "text",
        "text": "continuous- time counterpart  $e^{j\\omega_{0}t}$  : (1) the larger the magnitude of  $\\omega_{0}$  the higher is the rate of oscillation in the signal; and (2)  $e^{j\\omega_{0}t}$  is periodic for any value of  $\\omega_{0}$  . In this section we describe the discrete- time versions of both of these properties, and as we will see, there are definite differences between each of these and its continuous- time counterpart.",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "The fact that the first of these properties is different in discrete time is a direct consequence of another extremely important distinction between discrete- time and continuous- time complex exponentials. Specifically, consider the discrete- time complex exponential with frequency  $\\omega_{0} + 2\\pi$",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j(\\omega_{0} + 2\\pi)n} = e^{j2\\pi n}e^{j\\omega_{0}n} = e^{j\\omega_{0}n} \\tag{1.51}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "From eq. (1.51), we see that the exponential at frequency  $\\omega_{0} + 2\\pi$  is the same as that at frequency  $\\omega_{0}$ . Thus, we have a very different situation from the continuous- time case, in which the signals  $e^{j\\omega_{0}t}$  are all distinct for distinct values of  $\\omega_{0}$ . In discrete time, these signals are not distinct, as the signal with frequency  $\\omega_{0}$  is identical to the signals with frequencies  $\\omega_{0} \\pm 2\\pi$ ,  $\\omega_{0} \\pm 4\\pi$ , and so on. Therefore, in considering discrete- time complex exponentials, we need only consider a frequency interval of length  $2\\pi$  in which to choose  $\\omega_{0}$ . Although, according to eq. (1.51), any interval of length  $2\\pi$  will do, on most occasions we will use the interval  $0 \\leq \\omega_{0} < 2\\pi$  or the interval  $- \\pi \\leq \\omega_{0} < \\pi$ .",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "Because of the periodicity implied by eq. (1.51), the signal  $e^{j\\omega_{0}t}$  does not have a continually increasing rate of oscillation as  $\\omega_{0}$  is increased in magnitude. Rather, as illustrated in Figure 1.27, as we increase  $\\omega_{0}$  from 0, we obtain signals that oscillate more and more rapidly until we reach  $\\omega_{0} = \\pi$ . As we continue to increase  $\\omega_{0}$ , we decrease the rate of oscillation until we reach  $\\omega_{0} = 2\\pi$ , which produces the same constant sequence as  $\\omega_{0} = 0$ . Therefore, the low- frequency (that is, slowly varying) discrete- time exponentials have values of  $\\omega_{0}$  near  $0, 2\\pi$ , and any other even multiple of  $\\pi$ , while the high frequencies (corresponding to rapid variations) are located near  $\\omega_{0} = \\pm \\pi$  and other odd multiples of  $\\pi$ . Note in particular that for  $\\omega_{0} = \\pi$  or any other odd multiple of  $\\pi$ ,",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\pi \\pi} = (e^{j\\pi})^{n} = (-1)^{n}, \\tag{1.52}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "so that this signal oscillates rapidly, changing sign at each point in time [as illustrated in Figure 1.27(e)].",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "The second property we wish to consider concerns the periodicity of the discrete- time complex exponential. In order for the signal  $e^{j\\omega_{0}t}$  to be periodic with period  $N > 0$ , we must have",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}(n + N)} = e^{j\\omega_{0}n}, \\tag{1.53}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\omega_{0}(n)} = 1. \\tag{1.54}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "For eq. (1.54) to hold,  $\\omega_{0}N$  must be a multiple of  $2\\pi$ . That is, there must be an integer  $m$  such that",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\n\\omega_{0}N = 2\\pi m, \\tag{1.55}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 51
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{\\omega_{0}}{2\\pi} = \\frac{m}{N}. \\tag{1.56}\n$$\n",
        "text_format": "latex",
        "page_idx": 51
    },
    {
        "type": "image",
        "img_path": "images/ff8e145524ccae857d4b0a26646af05453bd2e1cdb08ce3c51999984901ac24e.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 52
    },
    {
        "type": "text",
        "text": "According to eq. (1.56), the signal  $e^{j\\omega_{0}n}$  is periodic if  $\\omega_{0} / 2\\pi$  is a rational number and is not periodic otherwise. These same observations also hold for discrete- time sinusoids. For example, the signals depicted in Figure 1.25(a) and (b) are periodic, while the signal in Figure 1.25(c) is not.",
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "Using the calculations that we have just made, we can also determine the fundamental period and frequency of discrete- time complex exponentials, where we define the fundamental frequency of a discrete- time periodic signal as we did in continuous time. That is, if  $x[n]$  is periodic with fundamental period  $N$ , its fundamental frequency is  $2\\pi /N$ . Consider, then, a periodic complex exponential  $x[n] = e^{j\\omega_{0}n}$  with  $\\omega_{0} \\neq 0$ . As we have just seen,  $\\omega_{0}$  must satisfy eq. (1.56) for some pair of integers  $m$  and  $N$ , with  $N > 0$ . In Problem 1.35, it is shown that if  $\\omega_{0} \\neq 0$  and if  $N$  and  $m$  have no factors in common, then the fundamental period of  $x[n]$  is  $N$ . Using this fact together with eq. (1.56), we find that the fundamental frequency of the periodic signal  $e^{j\\omega_{0}n}$  is",
        "page_idx": 53
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{2\\pi}{N} = \\frac{\\omega_{0}}{m}. \\tag{1.57}\n$$\n",
        "text_format": "latex",
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "Note that the fundamental period can also be written as",
        "page_idx": 53
    },
    {
        "type": "equation",
        "text": "\n$$\nN = m\\left(\\frac{2\\pi}{\\omega_{0}}\\right). \\tag{1.58}\n$$\n",
        "text_format": "latex",
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "These last two expressions again differ from their continuous- time counterparts. In Table 1.1, we have summarized some of the differences between the continuous- time signal  $e^{j\\omega_{0}n}$  and the discrete- time signal  $e^{j\\omega_{0}n}$ . Note that, as in the continuous- time case, the constant discrete- time signal resulting from setting  $\\omega_{0} = 0$  has a fundamental frequency of zero, and its fundamental period is undefined",
        "page_idx": 53
    },
    {
        "type": "table",
        "img_path": "images/3a7fe9ec843740ca0f6a0b97eaa0cf85d433b7a7251f0edb53f1bbd6a020b982.jpg",
        "table_caption": [
            "TABLE 1.1 Comparison of the signals eow and awo"
        ],
        "table_footnote": [
            "Assumes that w and N do not have any factors in common."
        ],
        "table_body": "<table><tr><td>e^w0</td><td>e^w0</td></tr><tr><td>Distinct signals for distinct values of ω0</td><td>Identical signals for values of ω0\nseparated by multiples of 2π</td></tr><tr><td>Periodic for any choice of ω0</td><td>Periodic only if ω0 = 2πm/N for some integers N &amp;gt; 0 and m</td></tr><tr><td>Fundamental frequency ω0</td><td>Fundamental frequency ω0/m</td></tr><tr><td>Fundamental period ω0 = 0: undefined ω0 ≠ 0: 2π/ω0</td><td>Fundamental period* ω0 ≠ 0: undefined ω0 ≠ 0: m(2π/ω0)</td></tr></table>",
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "To gain some additional insight into these properties, let us examine again the signals depicted in Figure 1.25. First, consider the sequence  $x[n] = \\cos (2\\pi n / 12)$ , depicted in Figure 1.25(a), which we can think of as the set of samples of the continuous- time sinusoid  $x(t) = \\cos (2\\pi t / 12)$  at integer time points. In this case,  $x(t)$  is periodic with fundamental period 12 and  $x[n]$  is also periodic with fundamental period 12. That is, the values of  $x[n]$  repeat every 12 points, exactly in step with the fundamental period of  $x(t)$ .",
        "page_idx": 53
    },
    {
        "type": "text",
        "text": "In contrast, consider the signal  $x[n] = \\cos (8\\pi /31)$  depicted in Figure 1.25(b), which we can view as the set of samples of  $x(t) = \\cos (8\\pi /31)$  at integer points in time. In this case,  $x(t)$  is periodic with fundamental period 31/4. On the other hand,  $x[n]$  is periodic with fundamental period 31. The reason for this difference is that the discrete- time signal is defined only for integer values of the independent variable. Thus, there is no sample at time  $t = 31 / 4$  when  $x(t)$  completes one period (starting from  $t = 0$ ). Similarly, there is no sample at  $t = 2$  31/4 or  $t = 3 \\cdot 31 / 4$ , when  $x(t)$  has completed two or three periods, but there is a sample at  $t = 4 \\cdot 31 / 4 = 31$ , when  $x(t)$  has completed four periods. This can be seen in Figure 1.25(b), where the pattern of  $x[n]$  values does not repeat with each single cycle of positive and negative values. Rather, the pattern repeats after four such cycles, namely, every 31 points.",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "Similarly, the signal  $x[n] = \\cos (n / 6)$  can be viewed as the set of samples of the signal  $x(t) = \\cos (t / 6)$  at integer time points. In this case, the values of  $x(t)$  at integer sample points never repeat, as the sample points never span an interval that is an exact multiple of the period,  $12\\pi$ , of  $x(t)$ . Thus,  $x[n]$  is not periodic, although the eye visually interpolates between the sample points, suggesting the envelope  $x(t)$ , which is periodic. The use of the concept of sampling to gain insight into the periodicity of discrete- time sinusoidal sequences is explored further in Problem 1.36.",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "Example 1.6",
        "text_level": 1,
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "Suppose that we wish to determine the fundamental period of the discrete- time signal",
        "page_idx": 54
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = e^{i2\\pi (3 / n)} + e^{i3\\pi (4 / n)}. \\tag{1.56}\n$$\n",
        "text_format": "latex",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "The first exponential on the right- hand side of eq. (1.59) has a fundamental period of 1. While this can be verified from eq. (1.58), there is a simpler way to obtain that answer. In particular, note that the angle  $(2\\pi /3)n$  of the first term must be incremented by a multiple of  $2\\pi$  for the values of this exponential to begin repeating. We then immediately see that if  $n$  is incremented by 3, the angle will be incremented by a single multiple of  $2\\pi$ . With regard to the second term, we see that incrementing the angle  $(3\\pi /4)n$  by  $2\\pi$  would require  $n$  to be incremented by  $8 / 3$ , which is impossible, since  $n$  is restricted to being an integer. Similarly, incrementing the angle by  $4\\pi$  would require a noninteger increment of  $16 / 3$  to  $n$ . However, incrementing the angle by  $6\\pi$  requires an increment of  $8$  to  $n$ , and thus the fundamental period of the second term is 8.",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "Now, for the entire signal  $x[n]$  to repeat, each of the terms in eq. (1.59) must go through an integer number of its own fundamental period. The smallest increment of  $n$  that accomplishes this is 24. That is, over an interval of 24 points, the first term on the right- hand side of eq. (1.59) will have gone through eight of its fundamental periods, the second term through three of its fundamental periods, and the overall signal  $x[n]$  through exactly one of its fundamental periods.",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "As in continuous time, it is also of considerable value in discrete- time signal and system analysis to consider sets of harmonically related periodic exponentials—that is, periodic exponentials with a common period  $N$ . From eq. (1.56), we know that there are precisely the signals which are at frequencies which are multiple of  $2\\pi /N$ . That is,",
        "page_idx": 54
    },
    {
        "type": "equation",
        "text": "\n$$\n\\phi_{k}[n] = e^{i k(2\\pi /N)n},\\qquad k = 0, \\pm 1, \\ldots \\tag{1.61}\n$$\n",
        "text_format": "latex",
        "page_idx": 54
    },
    {
        "type": "text",
        "text": "In the continuous- time case, all of the harmonically related complex exponentials  $e^{j k(2\\pi /T) \\eta}$ ,  $k = 0, \\pm 1, \\pm 2, \\ldots$ , are distinct. However, because of eq. (1.51), this is not the case in discrete time. Specifically,",
        "page_idx": 55
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {\\phi_{k + N}|n| = e^{j(k + N)\\chi (2\\pi /N) / n}}\\\\ & {\\qquad = e^{j k(2\\pi /N) / n}e^{j2\\pi n} = \\phi_{k}[n].} \\end{array} \\tag{1.61}\n$$\n",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "This implies that there are only  $N$  distinct periodic exponentials in the set given in eq. (1.60). For example,",
        "page_idx": 55
    },
    {
        "type": "equation",
        "text": "\n$$\n\\phi_{0}[n] = 1, \\phi_{1}[n] = e^{i2\\pi n / N}, \\phi_{2}[n] = e^{j4\\pi n / N}, \\ldots , \\phi_{N - 1}[n] = e^{j2\\pi n / N} \\quad 1 / n / N \\tag{1.62}\n$$\n",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "are all distinct, and any other  $\\phi_{k}[n]$  is identical to one of these (e.g.,  $\\phi_{\\Lambda}[n] = \\phi_{0}[n]$  and  $\\phi_{- 1}[n] = \\phi_{N - 1}[n]$ ).",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "1.4 THE UNIT IMPULSE AND UNIT STEP FUNCTIONS",
        "text_level": 1,
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "In this section, we introduce several other basic signals—specifically, the unit impulse and step functions in continuous and discrete time—that are also of considerable importance in signal and system analysis. In Chapter 2, we will see how we can use unit impulse signals as basic building blocks for the construction and representation of other signals. We begin with the discrete- time case.",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "1.4.1 The Discrete-Time Unit Impulse and Unit Step Sequences",
        "text_level": 1,
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "One of the simplest discrete- time signals is the unit impulse (or unit sample), which is defined as",
        "page_idx": 55
    },
    {
        "type": "equation",
        "text": "\n$$\n\\omega [n] = \\left\\{ \\begin{array}{ll}0, & n \\neq 0 \\\\ 1, & n = 0 \\end{array} \\right. \\tag{1.63}\n$$\n",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "and which is shown in Figure 1.28. Throughout the book, we will refer to  $\\delta [n]$  interchangeably as the unit impulse or unit sample.",
        "page_idx": 55
    },
    {
        "type": "image",
        "img_path": "images/9b91366b612846725738a4089ee863940c2eb8b27ca1a0f9fe8efe21d1840126.jpg",
        "image_caption": [
            "Figure 1.28 Discrete-time unit impulse (sample)."
        ],
        "image_footnote": [],
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "A second basic discrete- time signal is the discrete- time unit step, denoted by  $u[n]$  and defined by",
        "page_idx": 55
    },
    {
        "type": "equation",
        "text": "\n$$\nu[n] = \\left\\{ \\begin{array}{ll}0, & n < 0 \\\\ 1, & n \\geq 0 \\end{array} \\right. \\tag{1.64}\n$$\n",
        "text_format": "latex",
        "page_idx": 55
    },
    {
        "type": "text",
        "text": "The unit step sequence is shown in Figure 1.29.",
        "page_idx": 55
    },
    {
        "type": "image",
        "img_path": "images/a666db5a23364733e48aa316bd75c7832e5a089b91e08302f1e3cb3a53bb3a3e.jpg",
        "image_caption": [
            "Figure 1.29 Discrete-time unit step sequence."
        ],
        "image_footnote": [],
        "page_idx": 56
    },
    {
        "type": "image",
        "img_path": "images/23482b6233ed77e2597058c57470a7a4d2977aba0395bfb3a9daabd832285385.jpg",
        "image_caption": [
            "Figure 1.30 Running sum of eq (1.66): (a)  $n < 0$ , (b)  $n > 0$"
        ],
        "image_footnote": [],
        "page_idx": 56
    },
    {
        "type": "image",
        "img_path": "images/48316647bff9012e716d7028e1ac5c25f1dd7c37f9b40420f18c1cc3713b7c13.jpg",
        "image_caption": [
            "(b)"
        ],
        "image_footnote": [],
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "There is a close relationship between the discrete- time unit impulse and unit step. In particular, the discrete- time unit impulse is the first difference of the discrete- time step",
        "page_idx": 56
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta [n] = u[n] - u[n - 1]. \\tag{1.65}\n$$\n",
        "text_format": "latex",
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "Conversely, the discrete- time unit step is the running sum of the unit sample. That is,",
        "page_idx": 56
    },
    {
        "type": "equation",
        "text": "\n$$\nu[n] = \\sum_{m = -\\infty}^{n} \\delta [m]. \\tag{1.66}\n$$\n",
        "text_format": "latex",
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "Equation (1.66) is illustrated graphically in Figure 1.30. Since the only nonzero value of the unit sample is at the point at which its argument is zero, we see from the figure that the running sum in eq. (1.66) is 0 for  $n < 0$  and 1 for  $n \\geq 0$ . Furthermore, by changing the variable of summation from  $m$  to  $k = n - m$  in eq. (1.66), we find that the discrete- time unit step can also be written in terms of the unit sample as",
        "page_idx": 56
    },
    {
        "type": "equation",
        "text": "\n$$\nu[n] = \\sum_{k = n}^{n} \\delta [n - k].\n$$\n",
        "text_format": "latex",
        "page_idx": 56
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 56
    },
    {
        "type": "equation",
        "text": "\n$$\nu[n] = \\sum_{k = 0}^{\\infty} \\delta [n - k]. \\tag{167}\n$$\n",
        "text_format": "latex",
        "page_idx": 56
    },
    {
        "type": "image",
        "img_path": "images/3dcce73bb904c462987f891d68addf36071837028ca8d781ba71a53b3031c21c.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 57
    },
    {
        "type": "image",
        "img_path": "images/45eccd9ca3cff001e93307fed7a179a43661ef5c250f4fd5dbaa13b235faee59.jpg",
        "image_caption": [
            "Figure 1.31 Relationship given in eq. (1.67): (a)  $n< 0$ ; (b)  $n > 0$ ."
        ],
        "image_footnote": [],
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "Equation (1.67) is illustrated in Figure 1.31. In this case the nonzero value of  $\\delta [n - k]$  is at the value of  $k$  equal to  $n$ , so that again we see that the summation in eq. (1.67) is 0 for  $n< 0$  and 1 for  $n\\geq 0$ .",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "An interpretation of eq. (1.67) is as a superposition of delayed impulses; i.e., we can view the equation as the sum of a unit impulse  $\\delta [n]$  at  $n = 0$ , a unit impulse  $\\delta [n - 1]$  at  $n = 1$ , another,  $\\delta [n - 2]$ , at  $n = 2$ , etc. We will make explicit use of this interpretation in Chapter 2.",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "The unit impulse sequence can be used to sample the value of a signal at  $n = 0$ . In particular, since  $\\delta [n]$  is nonzero (and equal to 1) only for  $n = 0$ , it follows that",
        "page_idx": 57
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n]\\delta [n] = x[0]\\delta [n]. \\tag{1.68}\n$$\n",
        "text_format": "latex",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "More generally, if we consider a unit impulse  $\\delta [n - n_0]$  at  $n = n_0$ , then",
        "page_idx": 57
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n]\\delta [n - n_0] = x[n_0]\\delta [n - n_0]. \\tag{1.69}\n$$\n",
        "text_format": "latex",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "This sampling property of the unit impulse will play an important role in Chapters 2 and 7.",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "1.4.2 The Continuous-Time Unit Step and Unit Impulse Functions",
        "text_level": 1,
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "The continuous- time unit step function  $u(t)$  is defined in a manner similar to its discrete- time counterpart. Specifically,",
        "page_idx": 57
    },
    {
        "type": "equation",
        "text": "\n$$\nu(t) = \\left\\{ \\begin{array}{ll}0, & t< 0 \\\\ 1, & t > 0 \\end{array} \\right. \\tag{1.70}\n$$\n",
        "text_format": "latex",
        "page_idx": 57
    },
    {
        "type": "text",
        "text": "as is shown in Figure 1.32. Note that the unit step is discontinuous at  $t = 0$ . The continuous- time unit impulse function  $\\delta (t)$  is related to the unit step in a manner analogous",
        "page_idx": 57
    },
    {
        "type": "image",
        "img_path": "images/8f6a18c1272456a51a46776ec902bf096d1e2975599429e1ba88e0a5963641fc.jpg",
        "image_caption": [
            "Figure 1.32 Continuous-time unit step function."
        ],
        "image_footnote": [],
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "to the relationship between the discrete- time unit impulse and step functions. In particular, the continuous- time unit step is the running integral of the unit impulse",
        "page_idx": 58
    },
    {
        "type": "equation",
        "text": "\n$$\nu(t) = \\int_{\\mathbb{Z}}^{t}\\delta (\\tau)d\\tau . \\tag{1.71}\n$$\n",
        "text_format": "latex",
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "This also suggests a relationship between  $\\delta (t)$  and  $u(t)$  analogous to the expression for  $\\delta [n]$  in eq. (1.65). In particular, it follows from eq. (1.71) that the continuous- time unit impulse can be thought of as the first derivative of the continuous- time unit step:",
        "page_idx": 58
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta (t) = \\frac{d u(t)}{d t}. \\tag{1.72}\n$$\n",
        "text_format": "latex",
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "In contrast to the discrete- time case, there is some formal difficulty with this equation as a representation of the unit impulse function, since  $u(t)$  is discontinuous at  $t = 0$  and consequently is formally not differentiable. We can, however, interpret eq. (1.72) by considering an approximation to the unit step  $u_{\\Delta}(t)$ , as illustrated in Figure 1.33, which rises from the value 0 to the value 1 in a short time interval of length  $\\Delta$ . The unit step, of course, changes values instantaneously and thus can be thought of as an idealization of  $u_{\\Delta}(t)$  for  $\\Delta$  so short that its duration doesn't matter for any practical purpose. Formally,  $u(t)$  is the limit of  $u_{\\Delta}(t)$  as  $\\Delta \\rightarrow 0$ . Let us now consider the derivative",
        "page_idx": 58
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta_{\\Delta}(t) = \\frac{d u_{\\Delta}(t)}{d t}, \\tag{1.73}\n$$\n",
        "text_format": "latex",
        "page_idx": 58
    },
    {
        "type": "text",
        "text": "as shown in Figure 1.34.",
        "page_idx": 58
    },
    {
        "type": "image",
        "img_path": "images/5a1157d26b9fdae29543cd6a1c46cd6586932058c62939068143f42b36c63258.jpg",
        "image_caption": [
            "Figure 1.33 Continuous approximation to the unit step,  $u_{\\Delta}(t)$ ."
        ],
        "image_footnote": [],
        "page_idx": 58
    },
    {
        "type": "image",
        "img_path": "images/38aa152d39a96ffa3a4d39140abc117fac3a7827a40f028c390f04e8dd37d8c1.jpg",
        "image_caption": [
            "Figure 1.34 Derivative of  $u_{\\Delta}(t)$ ."
        ],
        "image_footnote": [],
        "page_idx": 58
    },
    {
        "type": "image",
        "img_path": "images/2b1a26d60c3cec18faeae560e95f7de67850b34a55a81b7e7e22b9c85798fb82.jpg",
        "image_caption": [
            "Figure 1.35 Continuous time unit impulse."
        ],
        "image_footnote": [],
        "page_idx": 59
    },
    {
        "type": "image",
        "img_path": "images/a0d7df74b179b49085ba53bb8cb1b190806f36a719a5495f446db052d3789ae1.jpg",
        "image_caption": [
            "Figure 1.36 Scaled impulse."
        ],
        "image_footnote": [],
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "Note that  $\\delta_{\\Delta}(t)$  is a short pulse, of duration  $\\Delta$  and with unit area for any value of  $\\Delta$ . As  $\\Delta \\rightarrow 0$ ,  $\\delta_{\\Delta}(t)$  becomes narrower and higher, maintaining its unit area. Its limiting form,",
        "page_idx": 59
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta (t) = \\lim_{\\Delta \\rightarrow 0}\\delta_{\\Delta}(t). \\tag{1.74}\n$$\n",
        "text_format": "latex",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "can then be thought of as an idealization of the short pulse  $\\delta_{\\Delta}(t)$  as the duration  $\\Delta$  becomes insignificant. Since  $\\delta (t)$  has, in effect, no duration but unit area, we adopt the graphical notation for it shown in Figure 1.35, where the arrow at  $t = 0$  indicates that the area of the pulse is concentrated at  $t = 0$  and the height of the arrow and the \"1\" next to the arrow are used to represent the area of the impulse. More generally, a scaled impulse  $k\\delta (t)$  will have an area  $k$ , and thus,",
        "page_idx": 59
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{-\\infty}^{t} k\\delta (\\tau) d\\tau = k u(t).\n$$\n",
        "text_format": "latex",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "A scaled impulse with area  $k$  is shown in Figure 1.36, where the height of the arrow used to depict the scaled impulse is chosen to be proportional to the area of the impulse.",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "As with discrete time, we can provide a simple graphical interpretation of the running integral of eq. (1.71), this is shown in Figure 1.37. Since the area of the continuous- time unit impulse  $\\delta (T)$  is concentrated at  $\\tau = 0$ , we see that the running integral is 0 for  $t < 0$  and 1 for  $t > 0$ . Also, we note that the relationship in eq. (1.71) between the continuous- time unit step and impulse can be rewritten in a different form, analogous to the discrete- time form in eq. (1.67), by changing the variable of integration from  $\\tau$  to  $\\sigma = t - \\tau$ :",
        "page_idx": 59
    },
    {
        "type": "equation",
        "text": "\n$$\nu(t) = \\int_{-\\infty}^{t} \\delta (\\tau) d\\tau = \\int_{\\infty}^{0} \\delta (t - \\sigma) (-d\\sigma),\n$$\n",
        "text_format": "latex",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 59
    },
    {
        "type": "equation",
        "text": "\n$$\nu(t) = \\int_{t}^{t} \\delta (t - \\sigma) d\\sigma . \\tag{1.75}\n$$\n",
        "text_format": "latex",
        "page_idx": 59
    },
    {
        "type": "text",
        "text": "The graphical interpretation of this form of the relationship between u(i) and 8(t)is given in Figure 1.38. Since in this case the area of 8(t- 0) is concentrated at the point 0= t, we again see that the integral in eq. (1.75) is 0 for t < 0 and 1 for t > 0. This type of graphical interpretation of the behavior of the unit impulse under integration will be extremely useful in Chapter 2.",
        "page_idx": 59
    },
    {
        "type": "image",
        "img_path": "images/6d6a5790d826665e5df7ffaacf763b6725389632a84369b7720e6e03133272a8.jpg",
        "image_caption": [
            "Figure 1.37 Running integral given in eq (1.71): (a)  $t < 0$ . (b)  $t > 0$ ."
        ],
        "image_footnote": [],
        "page_idx": 60
    },
    {
        "type": "image",
        "img_path": "images/e16f02632d05a615f8b4647a0d5a17d9b7b989570c0cb5d3b867349710b5a30b.jpg",
        "image_caption": [
            "Figure 1.38 Relationship given in eq (1.75): (a)  $t < 0$ . (b)  $t > 0$ ."
        ],
        "image_footnote": [],
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "As with the discrete- time impulse, the continuous- time impulse has a very important sampling property. In particular, for a number of reasons it will be important to consider the product of an impulse and more well- behaved continuous- time functions  $x(t)$ . The interpretation of this quantity is most readily developed using the definition of  $\\delta (t)$  according to eq. (1.74). Specifically, consider",
        "page_idx": 60
    },
    {
        "type": "equation",
        "text": "\n$$\nx_{1}(t) = x(t)\\delta_{\\Delta}(t).\n$$\n",
        "text_format": "latex",
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "In Figure 1.39(a) we have depicted the two time functions  $x(t)$  and  $\\delta_{\\Delta}(t)$ , and in Figure 1.39(b) we see an enlarged view of the nonzero portion of their product. By construction,  $x_{1}(t)$  is zero outside the interval  $0 \\leq t \\leq \\Delta$ . For  $\\Delta$  sufficiently small so that  $x(t)$  is approximately constant over this interval,",
        "page_idx": 60
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t)\\delta_{\\Delta}(t) \\approx x(0)\\delta_{\\Delta}(t).\n$$\n",
        "text_format": "latex",
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "Since  $\\delta (t)$  is the limit as  $\\Delta \\to 0$  of  $\\delta_{\\Delta}(t)$ , it follows that",
        "page_idx": 60
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t)\\delta (t) = x(0)\\delta (t). \\tag{176}\n$$\n",
        "text_format": "latex",
        "page_idx": 60
    },
    {
        "type": "text",
        "text": "By the same argument, we have an analogous expression for an impulse concentrated at an arbitrary point, say,  $t_{0}$ . That is,",
        "page_idx": 60
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t)\\delta (t - t_{0}) = x(t_{0})\\delta (t - t_{0}).\n$$\n",
        "text_format": "latex",
        "page_idx": 60
    },
    {
        "type": "image",
        "img_path": "images/6ac5c5cdb40096716a2983edd954374c079ca18d2271c1fa8595cb04735caf81.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 61
    },
    {
        "type": "image",
        "img_path": "images/c8ad4074cc3adcbf063e07765fb26e10e0fc77a3a65e2bf8cef7a776c505e3a2.jpg",
        "image_caption": [
            "Figure 1.39 The product  $x(t) \\delta_{\\Delta}(t)$  (a) graphs of both functions; (b) enlarged view of the nonzero portion of their product"
        ],
        "image_footnote": [],
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "Although our discussion of the unit impulse in this section has been somewhat informal, it does provide us with some important intuition about this signal that will be useful throughout the book. As we have stated, the unit impulse should be viewed as an idealization. As we illustrate and discuss in more detail in Section 2.5, any real physical system has some inertia associated with it and thus does not respond instantaneously to inputs. Consequently, if a pulse of sufficiently short duration is applied to such a system, the system response will not be noticeably influenced by the pulse's duration or by the details of the shape of the pulse, for that matter. Instead, the primary characteristic of the pulse that will matter is the net, integrated effect of the pulse—i.e., its area. For systems that respond much more quickly than others, the pulse will have to be of much shorter duration before the details of the pulse shape or its duration no longer matter. Nevertheless, for any physical system, we can always find a pulse that is \"short enough.\" The unit impulse then is an idealization of this concept—the pulse that is short enough for any system. As we will see in Chapter 2, the response of a system to this idealized pulse plays a crucial role in signal and system analysis, and in the process of developing and understanding this role, we will develop additional insight into the idealized signal.",
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "The unit impulse and other related functions (which are often collectively referred to as \"angularity functions) have been thoroughly studied in the field of mathematics under the alternative names of generalized functions and the theory of distributions For more detailed discussions of this subject, see Distribution Theory and Transform Analysis, by A. H. Zemanian (New York: McGraw- Hill Book Company, 1965). Generalised Functions, by R.F. Hrskins (New York. Halsted Press, 1999), or the more advanced text, Founer Analysis and Generalized Functions, by M. J. Lighthill (New York: Cambridge University Press, 1958) Our discussion of singularity functions in Section 2.5 is closely related in spirit to the mathematical theory described in these texts and thus provides an informal introduction to concepts that underlie this topic in mathematics.",
        "page_idx": 61
    },
    {
        "type": "text",
        "text": "Example 1.7",
        "text_level": 1,
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "Consider the discontinuous signal  $x(t)$  depicted in Figure 1.40(a). Because of the relationship between the continuous- time unit impulse and unit step, we can readily calculate and graph the derivative of this signal. Specifically, the derivative of  $x(t)$  is clearly 0, except at the discontinuities. In the case of the unit step, we have seen [eq. 11.72)] that differentiation gives rise to a unit impulse located at the point of discontinuity. Furthermore, by multiplying both sides of eq. (1.72) by any number  $k$ , we see that the derivative of a unit step with a discontinuity of size  $k$  gives rise to an impulse of area  $k$  at the point of discontinuity. This rule also holds for any other signal with a jump discontinuity, such as  $x(t)$  in Figure 1.40(a). Consequently, we can sketch its derivative  $x(t)$ , as in Figure 1.40(b), where an impulse is placed at each discontinuity of  $x(t)$ , with area equal to the size of the discontinuity. Note, for example, that the discontinuity in  $x(t)$  at  $t = 2$  has a value of 3, so that an impulse scaled by  $- 3$  is located at  $t = 2$  in the signal  $x(t)$ .",
        "page_idx": 62
    },
    {
        "type": "image",
        "img_path": "images/abcfd8cf21bebd508b7844ab090e6c0d178259600b00d5d8e64f76ac2c6dee21.jpg",
        "image_caption": [
            "Figure 1.40 (a) The discontinuous signal  $x(t)$  analyzed in Example 1.7. (b) its derivative  $x(t)$ . (c) depiction of the recovery of  $x(t)$  as the running integral of  $x(t)$ , illustrated for a value of  $t$  between 0 and 1."
        ],
        "image_footnote": [],
        "page_idx": 62
    },
    {
        "type": "text",
        "text": "As a check of our result, we can verify that we can recover x(t) from t(t). Specifically,since x(t) and x(t) are both zero for t ≤ 0,we need only check that for t > 0,",
        "page_idx": 63
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = \\int_{0}^{t}\\dot{x} (\\tau)d\\tau . \\tag{1 77}\n$$\n",
        "text_format": "latex",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "As illustrated in Figure 1.40(c), for  $t< 1$  the integral on the right- hand side of eq. (1.77) is zero, since none of the impulses that constitute  $\\dot{x} (t)$  are within the interval of integration. For  $1< t< 2$  the first impulse (located at  $t = 1$  ) is the only one within the integration interval, and thus the integral in eq. (1.77) equals 2, the area of this impulse. For  $2< t< 4$  the first two impulses are within the interval of integration, and the integral accumulates the sum of both of their areas, namely,  $2 - 3 = - 1$  . Finally, for  $t > 4$  all three impulses are within the integration interval, so that the integral equals the sum of all three areas- that is,  $2 - 3 + 2 = +1$  . The result is exactly the signal t(t) depicted in Figure 1.40(a)",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "1.5 CONTINUOUS-TIME AND DISCRETE-TIME SYSTEMS",
        "text_level": 1,
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "Physical systems in the broadest sense are an interconnection of components, devices, or subsystems. In contexts ranging from signal processing and communications to electromechanical motors, automotive vehicles, and chemical- processing plants, a system can be viewed as a process in which input signals are transformed by the system or cause the system to respond in some way, resulting in other signals as outputs. For example, a highfidelity system takes a recorded audio signal and generates a reproduction of that signal. If the hi- fi system has tone controls, we can change the total quality of the reproduced signal. Similarly, the circuit in Figure 1.1 can be viewed as a system with input voltage  $\\nu_{s}(t)$  and output voltage  $\\nu_{t}(t)$  , while the automobile in Figure 1.2 can be thought of as a system with input equal to the force  $f(t)$  and output equal to the velocity  $\\nu (t)$  of the vehicle. An image- enhancement system transforms an input image into an output image that has some desired properties, such as improved contrast.",
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "A continuous- time system is a system in which continuous- time input signals are applied and result in continuous- time output signals. Such a system will be represented pictorially as in Figure 1.41(a), where x(t) is the input and y(t) is the output. Alternatively, we will often represent the input- output relation of a continuous- time system by the notation",
        "page_idx": 63
    },
    {
        "type": "image",
        "img_path": "images/c6f7eb344726da7e282b9a98faf82e88bcb299ef6e3f6c740c96bdc53afd64ea.jpg",
        "image_caption": [
            "Figure 1.41 (a) Continuous-time system; (b) discrete-time system."
        ],
        "image_footnote": [],
        "page_idx": 63
    },
    {
        "type": "text",
        "text": "Similarly, a discrete- time system- - that is, a system that transforms discrete- time inputs into discrete- time outputs- - will be depicted as in Figure 1.41(b) and will sometimes be represented symbolically as",
        "page_idx": 64
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n]\\rightarrow y[n]. \\tag{1.79}\n$$\n",
        "text_format": "latex",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "In most of this book, we will treat discrete- time systems and continuous- time systems separately but in parallel. In Chapter 7, we will bring continuous- time and discrete- time systems together through the concept of sampling, and we will develop some insights into the use of discrete- time systems to process continuous- time signals that have been sampled.",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "1.5.1 Simple Examples of Systems",
        "text_level": 1,
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "One of the most important motivations for the development of general tools for analyzing and designing systems is that systems from many different applications have very similar mathematical descriptions. To illustrate this, we begin with a few simple examples.",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Example 1.8",
        "text_level": 1,
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Consider the RC circuit depicted in Figure 1.1. If we regard  $\\nu_{x}(t)$  as the input signal and  $\\nu_{c}(t)$  as the output signal, then we can use simple circuit analysis to derive an equation describing the relationship between the input and output. Specifically, from Ohm's law, the current  $i(t)$  through the resistor is proportional (with proportionality constant  $1 / R$ ) to the voltage drop across the resistor; i.e.,",
        "page_idx": 64
    },
    {
        "type": "equation",
        "text": "\n$$\ni(t) = \\frac{\\nu_{s}(t) - \\nu_{s}(t)}{R} \\tag{1.80}\n$$\n",
        "text_format": "latex",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Similarly, using the defining constitutive relation for a capacitor, we can relate  $i(t)$  to the rate of change with time of the voltage across the capacitor.",
        "page_idx": 64
    },
    {
        "type": "equation",
        "text": "\n$$\n\\iota (t) = C\\frac{d\\nu_{r}(t)}{dt} \\tag{1.81}\n$$\n",
        "text_format": "latex",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Equating the right- hand sides of eqs. (1.80) and (1.81), we obtain a differential equation describing the relationship between the input  $\\nu_{s}(t)$  and the output  $\\nu_{c}(t)$ :",
        "page_idx": 64
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{d\\nu_{r}(t)}{dt} + \\frac{1}{RC}\\nu_{r}(t) = \\frac{1}{RC}\\nu_{c}(t). \\tag{1.82}\n$$\n",
        "text_format": "latex",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Example 1.9",
        "text_level": 1,
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "Consider Figure 1.2, in which we regard the force  $f(t)$  as the input and the velocity  $\\nu (t)$  as the output. If we let  $m$  denote the mass of the automobile and  $mpv$  the resistance due to friction, then equating acceleration—i.e., the time derivative of velocity—with net force divided by mass, we obtain",
        "page_idx": 64
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{d\\nu(t)}{dt} = \\frac{1}{m}\\left[f(t) - \\rho \\nu (t)\\right]. \\tag{1.83}\n$$\n",
        "text_format": "latex",
        "page_idx": 64
    },
    {
        "type": "text",
        "text": "i.e.,",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{d\\nu(t)}{dt} + \\frac{\\rho}{m} \\nu (t) = \\frac{1}{m} f(t). \\tag{1.84}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Examining and comparing eqs. (1.82) and (1.84) in the above examples, we see that the input- output relationships captured in these two equations for these two very different physical systems are basically the same. In particular, they are both examples of first- order linear differential equations of the form",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{d y(t)}{d t} + a y(t) - b x(t), \\tag{1.85}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "where  $\\tau (t)$  is the input,  $y(t)$  is the output, and  $a$  and  $b$  are constants. This is one very simple example of the fact that, by developing methods for analyzing general classes of systems such as that represented by eq. (1.85), we will be able to use them in a wide variety of applications.",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Example 1.10",
        "text_level": 1,
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "As a simple example of a discrete- time system, consider a simple model for the balance in a bank account from month to month. Specifically, let y[n] denote the balance at the end of the nth month, and suppose that y[n] evolves from month to month according to the equation",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = 1.01 y[n - 1] + x[n], \\tag{1.86}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] - 1.01 y[n - 1] = x[n], \\tag{1.87}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "where  $x[n]$  represents the net deposit (i.e., deposits minus withdrawals) during the nth month and the term 1.01 y[n - 1] models the fact that we account 1% interest each month.",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Example 1.11",
        "text_level": 1,
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "As a second example, consider a simple digital simulation of the differential equation in eq (1.84) in which we resolve time into discrete intervals of length  $\\Delta$  and approximate  $d \\nu (t) / d t$  at  $t = n \\Delta$  by the first backward difference, i.e.,",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{\\nu(n \\Delta)}{\\Delta} - \\frac{\\nu(n - 1) \\Delta}{\\Delta}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "In this case, if we let  $\\nu [n] = \\nu (n \\Delta)$  and  $f[n] = f(n \\Delta)$ , we obtain the following discrete- time model relating the sampled signals  $f[n]$  and  $\\nu [n]$ :",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\n\\nu [n] - \\frac{m}{(m + \\rho \\Delta)} \\nu [n - 1] = \\frac{\\Delta}{(m + \\rho \\Delta)} f[n]. \\tag{1.88}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "Comparing eqs. (1.87) and (1.88), we see that they are both examples of the same general first- order linear difference equation, namely,",
        "page_idx": 65
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] + a y[n - 1] = b x[n]. \\tag{1.89}\n$$\n",
        "text_format": "latex",
        "page_idx": 65
    },
    {
        "type": "text",
        "text": "As the preceding examples suggest, the mathematical descriptions of systems from a wide variety of applications frequently have a great deal in common, and it is this fact that provides considerable motivation for the development of broadly applicable tools for signal and system analysis The key to doing this successfully is identifying classes of systems that have two important characteristics: (1) The systems in this class have properties and structures that we can exploit to gain insight into their behavior and to develop effective tools for their analysis; and (2) many systems of practical importance can be accurately modeled using systems in this class. It is on the first of these characteristics that most of this book focuses, as we develop tools for a particular class of systems referred to as linear, time- invariant systems. In the next section, we will introduce the prop. critie, that characterize this class, as well as a number of other very important basic system properties.",
        "page_idx": 66
    },
    {
        "type": "text",
        "text": "The second characteristic mentioned in the preceding paragraph is of obvious importance for any system analysis technique to be of value in practice. It is a well- established fact that a wide range of physical systems (including those in Examples 1.8- 1.10) can be well modeled within the class of systems on which we focus in this book. However, a critical point is that any model used in describing or analyzing a physical system represents an idealization of that system, and thus, any resulting analysis is only as good as the model itself. For example, the simple linear model of a resistor in eq. (1.80) and that of a capacitor in eq. (1.81) are idealizations. However, these idealizations are quite accurate for real resistors and capacitors in many applications, and thus, analyses employing such idealizations provide useful results and conclusions, as long as the voltages and currents remain within the operating conditions under which these simple linear models are valid. Similarly, the use of a linear retarding force to represent functional effects in eq. (1.83) is an approximation with a range of validity. Consequently, although we will not address this issue in the book, it is important to remember that an essential component of engineering practice in using the methods we develop here consists of identifying the range of validity of the assumptions that have gone into a model and ensuring that any analysis or design based on that model does not violate those assumptions.",
        "page_idx": 66
    },
    {
        "type": "text",
        "text": "1.5.2 Interconnections of Systems",
        "text_level": 1,
        "page_idx": 66
    },
    {
        "type": "text",
        "text": "An important idea that we will use throughout this book is the concept of the interconnection of systems. Many real systems are built as interconnections of several subsystems. One example is an audio system, which involves the interconnection of a radio receiver, compact disc player, or tapo deck with an amplifier and one or more speakers. Another is a digitally controlled aircraft, which is an interconnection of the aircraft, described by its equations of motion and the aerodynamic forces affecting it; the sensors, which measure various aircraft variables such as accelerations, rotation rates, and heading; a digital autopilot, which responds to the measured variables and to command inputs from the pilot (e.g., the desired course, altitude, and speed); and the aircraft's actuators, which respond to inputs provided by the autopilot in order to use the aircraft control surfaces (rudder, tail, ailerons) to change the aerodynamic forces on the aircraft. By viewing such a system as an interconnection of its components, we can use our understanding of the component",
        "page_idx": 66
    },
    {
        "type": "image",
        "img_path": "images/d4b814998848219747f783f0cda119c35b6964a952f5ef3060773cf5704ea6ac.jpg",
        "image_caption": [
            "Figure 1.42 Interconnection of two systems: (a) series (cascade) interconnection; (b) parallel interconnection, (c) series-parallel interconnection."
        ],
        "image_footnote": [],
        "page_idx": 67
    },
    {
        "type": "text",
        "text": "systems and of how they are interconnected in order to analyze the operation and behavior of the overall system. In addition, by describing a system in terms of an interconnection of simpler subsystems, we may in fact be able to define useful ways in which to synthesize complex systems out of simpler, basic building blocks.",
        "page_idx": 67
    },
    {
        "type": "text",
        "text": "While one can construct a variety of system interconnections, there are several basic ones that are frequently encountered. A series or cascade interconnection of two systems is illustrated in Figure 1.42(a). Diagrams such as this are referred to as block diagrams. Here, the output of System 1 is the input to System 2, and the overall system transforms an input by processing it first by System 1 and then by System 2. An example of a series interconnection is a radio receiver followed by an amplifier. Similarly, one can define a series interconnection of three or more systems.",
        "page_idx": 67
    },
    {
        "type": "text",
        "text": "A parallel interconnection of two systems is illustrated in Figure 1.42(b). Here, the same input signal is applied to Systems 1 and 2. The symbol \" $\\# \\mathbb{P}^{\\prime \\prime}$ \" in the figure denotes addition, so that the output of the parallel interconnection is the sum of the outputs of Systems 1 and 2. An example of a parallel interconnection is a simple audio system with several microphones feeding into a single amplifier, and speaker system. In addition to the simple parallel interconnection in Figure 1.42(b), we can define parallel interconnections of more than two systems, and we can combine both cascade and parallel interconnections",
        "page_idx": 67
    },
    {
        "type": "image",
        "img_path": "images/86d0b39c7245556992ef8936f077bb583aa2b7b63ff1944d41eea42f7148a360.jpg",
        "image_caption": [
            "Figure 1.43 Feedback interconnection."
        ],
        "image_footnote": [],
        "page_idx": 68
    },
    {
        "type": "text",
        "text": "to obtain more complicated interconnections. An example of such an interconnection is given in Figure 1.42(c).4",
        "page_idx": 68
    },
    {
        "type": "text",
        "text": "Another important type of system interconnection is a feedback interconnection, an example of which is illustrated in Figure 1.43. Here, the output of System 1 is the input to System 2, while the output of System 2 is fed back and added to the external input to produce the actual input to System 1. Feedback systems arise in a wide variety of applications. For example, a cruise control system on an automobile senses the vehicle's velocity and adjusts the fuel flow in order to keep the speed at the desired level. Similarly, a digitally controlled aircraft is most naturally thought of as a feedback system in which differences between actual and desired speed, heading, or altitude are fed back through the autopilot in order to correct these discrepancies. Also, electrical circuits are often usefully viewed as containing feedback interconnections. As an example, consider the circuit depicted in Figure 1.44(a). As indicated in Figure 1.44(b), this system can be viewed as the feedback interconnection of the two circuit elements.",
        "page_idx": 68
    },
    {
        "type": "image",
        "img_path": "images/88d48cda0b4a16f9de38c06ecd046a9bfb313ca4c2d7a766428bb3a176bbb74f.jpg",
        "image_caption": [
            "Figure 1.44 (a) Simple electrical circuit, (b) Block diagram 1r which the circuit is depicted as the feedback interconnection of two circuit elements."
        ],
        "image_footnote": [],
        "page_idx": 68
    },
    {
        "type": "text",
        "text": "4On occasion, we will also use the symbol  $\\mathfrak{S}$  in our pictorial representation of systems to denote the operation of multiplying two signals (see, for example, Figure 4.26)",
        "page_idx": 68
    },
    {
        "type": "text",
        "text": "1.6 BASIC SYSTEM PROPERTIES",
        "text_level": 1,
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "In this section we introduce and discuss a number of basic properties of continuous- time and discrete- time systems. These properties have important physical interpretations and relatively simple mathematical descriptions using the signals and systems language that we have begun to develop.",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "1.6.1 Systems with and without Memory",
        "text_level": 1,
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "A system is said to be memoryless if its output for each value of the independent variable at a given time is dependent only on the input at that same time. For example, the system specified by the relationship",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = (2x[n] - x^{2}[n])^{2} \\tag{1.90}\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "is memoryless, as the value of  $y[n]$  at any particular time  $n_{0}$  depends only on the value of  $x[n]$  at that time. Similarly, a resistor is a memoryless system; with the input  $x(t)$  taken as the current and with the voltage taken as the output  $y(t)$ , the input- output relationship of a resistor is",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = R x(t), \\tag{1.91}\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "where  $R$  is the resistance. One particularly simple memoryless system is the identity system, whose output is identical to its input. That is, the input- output relationship for the continuous- time identity system is",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(t),\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "and the corresponding relationship in discrete time is",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[n].\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "An example of a discrete- time system with memory is an accumulator or summer",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\sum_{k = -\\infty}^{n} x[k], \\tag{1.92}\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "and a second example is a delay",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[n - 1]. \\tag{1.93}\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "A capacitor is an example of a continuous- time system with memory, since if the input is taken to be the current and the output is the voltage, then",
        "page_idx": 69
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = \\frac{1}{C} \\int_{-\\infty}^{1} x(\\tau) d\\tau , \\tag{1.94}\n$$\n",
        "text_format": "latex",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "where  $C$  is the capacitance.",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "Roughly speaking, the concept of memory in a system corresponds to the presence of a mechanism in the system that retains or stores information about input values at times",
        "page_idx": 69
    },
    {
        "type": "text",
        "text": "other than the current time. For example, the delay in eq. (1.93) must retain or store the preceding value of the input. Similarly, the accumulator in eq. (1.92) must \"remember\" or store information about past inputs. In particular, the accumulator computes the running sum of all inputs up to the current time, and thus, at each instant of time, the accumulator must add the current input value to the preceding value of the running sum. In other words, the relationship between the input and output of an accumulator can be described as",
        "page_idx": 70
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\sum_{k = -\\infty}^{n - 1}x[k] + x[n], \\tag{1.95}\n$$\n",
        "text_format": "latex",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "or equivalently,",
        "page_idx": 70
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = y[n - 1] + x[n]. \\tag{1.96}\n$$\n",
        "text_format": "latex",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "Represented in the latter way, to obtain the output at the current time  $n$ , the accumulator must remember the running sum of previous input values, which is exactly the preceding value of the accumulator output.",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "In many physical systems, memory is directly associated with the storage of energy. For example, the capacitor in eq. (1.94) stores energy by accumulating electrical charge, represented as the integral of the current. Thus, the simple RC circuit in Example 1.8 and Figure 1.1 has memory physically stored in the capacitor. Similarly, the automobile in Figure 1.2 has memory stored in its kinetic energy. In discrete- time systems implemented with computers or digital microprocessors, memory is typically directly associated with storage registers that retain values between clock pulses.",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "While the concept of memory in a system would typically suggest storing past input and output values, our formal definition also leads to our referring to a system as having memory if the current output is dependent on future values of the input and output. While systems having this dependence on future values might at first seem unnatural, they in fact form an important class of systems, as we discuss further in Section 1.6.3.",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "1.6.2 Invertibility and Inverse Systems",
        "text_level": 1,
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "A system is said to be invertible if distinct inputs lead to distinct outputs. As illustrated in Figure 1.45(a) for the discrete- time case, if a system is invertible, then an inverse system exists that, when cascaded with the original system, yields an output  $w[n]$  equal to the input  $x[n]$  to the first system. Thus, the series interconnection in Figure 1.45(a) has an overall input- output relationship which is the same as that for the identity system.",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "An example of an invertible continuous- time system is",
        "page_idx": 70
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = 2x(t), \\tag{1.97}\n$$\n",
        "text_format": "latex",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "for which the inverse system is",
        "page_idx": 70
    },
    {
        "type": "equation",
        "text": "\n$$\nw(t) = \\frac{1}{2} y(t). \\tag{1.98}\n$$\n",
        "text_format": "latex",
        "page_idx": 70
    },
    {
        "type": "text",
        "text": "This example is illustrated in Figure 1.45(b). Another example of an invertible system is the accumulator of eq. (1.92). For this system, the difference between two successive",
        "page_idx": 70
    },
    {
        "type": "image",
        "img_path": "images/3616c93b166f44f341b3d65877564af840c310723ec48a2015653154645b7784.jpg",
        "image_caption": [
            "Figure 1.45 Concept of an inverse system for: (a) a general invertible system, (b) the invertible system described by eq. (1.97); (c) the invertible system defined in eq. (1.92)."
        ],
        "image_footnote": [],
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "values of the output is precisely the last input value. Therefore, in this case, the inverse system is",
        "page_idx": 71
    },
    {
        "type": "equation",
        "text": "\n$$\nw[n] = y[n] - y[n - 1], \\tag{1.99}\n$$\n",
        "text_format": "latex",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "as illustrated in Figure 1.45(c). Examples of noninvertible systems are",
        "page_idx": 71
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = 0, \\tag{1 100}\n$$\n",
        "text_format": "latex",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "that is, the system that produces the zero output sequence for any input sequence, and",
        "page_idx": 71
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x^{2}(t), \\tag{1.101}\n$$\n",
        "text_format": "latex",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "in which case we cannot determine the sign of the input from knowledge of the output.",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "The concept of invertibility is important in many contexts. One example arises in systems for encoding used in a wide variety of communications applications. In such a system, a signal that we wish to transmit is first applied as the input to a system known as an encoder. There are many reasons for doing this, ranging from the desire to encrypt the original message for secure or private communication to the objective of providing some redundancy in the signal (for example, by adding what are known as parity bits) so that any errors that occur in transmission can be detected and, possibly, corrected. For lossless coding, the input to the encoder must be exactly recoverable from the output; i.e., the encoder must be invertible.",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "1.6.3 Causality",
        "text_level": 1,
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "A system is causal if the output at any time depends only on values of the input at the present time and in the past. Such a system is often referred to as being nonanticipative, as",
        "page_idx": 71
    },
    {
        "type": "text",
        "text": "the system output does not anticipate future values of the input. Consequently, if two inputs to a causal system are identical up to some point in time  $t_0$  or  $n_0$ , the corresponding outputs must also be equal up to this same time. The RC circuit of Figure 1.1 is causal, since the capacitor voltage responds only to the present and past values of the source voltage. Similarly, the motion of an automobile is causal, since it does not anticipate future actions of the driver. The systems described in eqs. (1.92) - (1.94) are also causal, but the systems defined by",
        "page_idx": 72
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[n] - x[n + 1] \\tag{1.102}\n$$\n",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 72
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(t + 1) \\tag{1.103}\n$$\n",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "are not. All memoryless systems are causal, since the output responds only to the current value of the input.",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Although causal systems are of great importance, they do not by any means constitute the only systems that are of practical significance. For example, causality is not often an essential constraint in applications in which the independent variable is not time, such as in image processing. Furthermore, in processing data that have been recorded previously, as often happens with speech, geophysical, or meteorological signals, to name a few, we are by no means constrained to causal processing. As another example, in many applications, including historical stock market analysis and demographic studies, we may be interested in determining a slowly varying trend in data that also contain high- frequency fluctuations about that trend. In this case, a commonly used approach is to average data over an interval in order to smooth out the fluctuations and keep only the trend. An example of a noncausal averaging system is",
        "page_idx": 72
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\frac{1}{2M + 1} \\sum_{k = -M}^{+M} x[n - k]. \\tag{1.104}\n$$\n",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Example 1.12",
        "text_level": 1,
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "When checking the causality of a system, it is important to look carefully at the input- output relation. To illustrate some of the issues involved in doing this, we will check the causality of two particular systems.",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "The first system is defined by",
        "page_idx": 72
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[-n]. \\tag{1.105}\n$$\n",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "Note that the output  $y[n_0]$  at a positive time  $n_0$  depends only on the value of the input signal  $x[- n_0]$  at time  $(- n_0)$ , which is negative and therefore in the past of  $n_0$ . We may be tempted to conclude at this point that the given system is causal. However, we should always be careful to check the input- output relation for all times. In particular, for  $n < 0$ ,  $c.g. n = - 4$ , we see that  $y[- 4] = x[4]$ , so that the output at this time depends on a future value of the input. Hence, the system is not causal.",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "It is also important to distinguish carefully the effects of the input from those of any other functions used in the definition of the system. For example, consider the system",
        "page_idx": 72
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(t) \\cos (t + 1). \\tag{1.106}\n$$\n",
        "text_format": "latex",
        "page_idx": 72
    },
    {
        "type": "text",
        "text": "In this system, the output at any time t equals the input at that same time multiplied by a number that vanes with time. Specifically, we can rewnte eq. (1.106) as",
        "page_idx": 73
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(t)g(t).\n$$\n",
        "text_format": "latex",
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "where  $g(t)$  is a time- varying function, namely  $g(t) = \\cos (t + 1)$  Thus, only the current value of the input  $x(t)$  influences the current value of the output  $y(t)$  and we conclude that this system is causal (and, in fact, memoryless).",
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "1.6.4 Stability",
        "text_level": 1,
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "Stability is another important system property. Informally, a stable system is one in which small inputs lead to responses that do not diverge. For example, consider the pendulum in Figure 1.46(a), in which the input is the applied force  $x(t)$  and the output is the angular deviation  $y(t)$  from the vertical. In this case, gravity applies a restoring force that tends to return the pendulum to the vertical position, and frictional losses due to drag tend to slow it down. Consequently, if a small force  $x(t)$  is applied, the resulting deflection from vertical will also be small. In contrast, for the inverted pendulum in Figure 1.46(b), the effect of gravity is to apply a force that tends to increase the deviation from vertical. Thus, a small applied force leads to a large vertical deflection causing the pendulum to topple over, despite any rewarding forces due to friction.",
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "The system in Figure 1.46(a) is an example of a stable system, while that in Figure 1.46(b) is unstable. Models for chain reactions or for population growth with unlimited food supplies and no predators are examples of unstable systems, since the system response grows without bound in response to small inputs. Another example of an unstable system is the model for a bank account balance in eq. 01.86), since if an initial deposit 1s made (i.e., d0] = a positive amount) and there are no subsequent withdrawals, then that deposit will grow each month without bound. because of the compounding effect of interest payments.",
        "page_idx": 73
    },
    {
        "type": "image",
        "img_path": "images/765461d72c93c3b52980107224cbf331d77207cef4f8dd0586ad0fd44e9a8c90.jpg",
        "image_caption": [
            "Figure 1.46 (a) A stable pendulum; (b) an unstable inverted pendulum"
        ],
        "image_footnote": [],
        "page_idx": 73
    },
    {
        "type": "text",
        "text": "There are also numerous examples of stable systems. Stability of physical systems generally results from the presence of mechanisms that dissipate energy. For example, assuming positive component values in the simple RC circuit of Example 1.8, the resistor dissipates energy and this circuit is a stable system. The system in Example 1 9 is also stable because of the dissipation of energy through friction.",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "The preceding examples provide us with an intuitive understanding of the concept of stability. More formally, if the input to a stable system is bounded (i.e., if its magnitude does not grow without bound), then the output must also be bounded and therefore cannot diverge. This is the definition of stability that we will use throughout this book. For exam. plc, consider applying a constant force  $f(t) = F$  to the automobile in Figure 1 2. with the vehicle initially at rest. In this case the velocity of the car will increase, but not without bound, since the retarding frictional force also increases with velocity. In fact, the velocity will continue to increase until the frictional force exactly balances the applied force: so, from eq. (1.84), we see that this terminal velocity value  $V$  must satisfy",
        "page_idx": 74
    },
    {
        "type": "equation",
        "text": "\n$$\n\\rho_{m}V = \\frac{1}{m} F, \\tag{1.107}\n$$\n",
        "text_format": "latex",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "i.e.,",
        "page_idx": 74
    },
    {
        "type": "equation",
        "text": "\n$$\nV = \\frac{F}{\\rho}. \\tag{1 108}\n$$\n",
        "text_format": "latex",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "As another example, consider the discrete- time system defined by eq. (1.104), and suppose that the input  $x[n]$  is bounded in magnitude by some number, say,  $\\beta$ , for all values of  $n$ . Then the largest possible magnitude for  $y[n]$  is also  $\\beta$ , because  $y[n]$  is the average of a finite set of values of the input. Therefore,  $y[n]$  is bounded and the system is stable. On the other hand, consider the accumulator described by eq. (1.92). Unlike the system in eq. (1.104), this system sums all of the past values of the input rather than just a finite set of values, and the system is unstable, since the sum can grow continually even if  $x[n]$  is bounded. For example, if the input to the accumulator is a unit step  $u[n]$ , the output will be",
        "page_idx": 74
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\sum_{k = -\\infty}^{n} u[k] = (n + 1)u[n].\n$$\n",
        "text_format": "latex",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "That is,  $y[0] = 1$ ,  $y[1] = 2$ ,  $y[2] = 3$ , and so on, and  $y[n]$  grows without bound.",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "Example 1.13",
        "text_level": 1,
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "If we suspect that a system is unstable, then a useful strategy to verify this is to look for a specific bounded input that leads to an unbounded output. Finding one such example enables us to conclude that the given system is unstable. If such an example does not exist or is difficult to find, we must check for stability by using a method that does not utilize specific examples of input signals. To illustrate this approach, let us check the stability of two systems,",
        "page_idx": 74
    },
    {
        "type": "equation",
        "text": "\n$$\nS_{1}: y(t) = t x(t) \\tag{1.109}\n$$\n",
        "text_format": "latex",
        "page_idx": 74
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 75
    },
    {
        "type": "equation",
        "text": "\n$$\nS_{2}:y(t) = e^{x(t)}, \\tag{1.110}\n$$\n",
        "text_format": "latex",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "In seeking a specific counterexample in order to disprove stability, we might try simple bounded inputs such as a constant or a unit step. For system  $S_{1}$  in eq. (1.109), a constant input  $x(t) = 1$  yields  $y(t) = t$ , which is unbounded, since no matter what finite constant we pick,  $|y(t)|$  will exceed that constant for some  $t$ . We conclude that system  $S_{1}$  is unstable.",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "For system  $S_{2}$ , which happens to be stable, we would be unable to find a bounded input that results in an unbounded output. So we proceed to verify that all bounded inputs result in bounded outputs. Specifically, let  $B$  be an arbitrary positive number, and let  $x(t)$  be an arbitrary signal bounded by  $B$ ; that is, we are making no assumption about  $x(t)$  except that",
        "page_idx": 75
    },
    {
        "type": "equation",
        "text": "\n$$\n|x(t)|< B, \\tag{1.111}\n$$\n",
        "text_format": "latex",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "or",
        "page_idx": 75
    },
    {
        "type": "equation",
        "text": "\n$$\n-B< x(t)< B, \\tag{1.112}\n$$\n",
        "text_format": "latex",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "for all  $t$ . Using the definition of  $S_{2}$  in eq. (1.110), we then see that if  $x(t)$  satisfies eq. (1.111), then  $y(t)$  must satisfy",
        "page_idx": 75
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{-H}< |y(t)|< e^{H}. \\tag{1 113}\n$$\n",
        "text_format": "latex",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "We conclude that if any input to  $S_{2}$  is bounded by an arbitrary positive number  $B$ , the corresponding output is guaranteed to be bounded by  $e^{H}$ . Thus,  $S_{2}$  is stable.",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "The system properties and concepts that we have introduced so far in this section are of great importance, and we will examine some of these in more detail later in the book. There remain, however, two additional properties- time invariance and linearity- - that play a particularly central role in the subsequent chapters of the book, and in the remainder of this section we introduce and provide initial discussions of these two very important concepts.",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "1.6.5 Time Invariance",
        "text_level": 1,
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "Conceptually, a system is time invariant if the behavior and characteristics of the system are fixed over time. For example, the RC circuit of Figure 1.1 is time invariant if the resistance and capacitance values  $R$  and  $c$  are constant over time: We would expect to get the same results from an experiment with this circuit today as we would if we ran the identical experiment tomorrow. On the other hand, if the values of  $R$  and  $c$  are changed or fluctuate over time, then we would expect the results of our experiment to depend on the time at which we run it. Similarly, if the frictional coefficient  $b$  and mass  $m$  of the automobile in Figure 1.2 are constant, we would expect the vehicle to respond identically independently of when we drive it. On the other hand, if we load the auto's trunk with heavy suitcase one day, thus increasing  $m$ , we would expect the car to behave differently than at other times when it is not so heavily loaded.",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "The property of time invariance can be described very simply in terms of the signals and systems language that we have introduced. Specifically, a system is time invariant if",
        "page_idx": 75
    },
    {
        "type": "text",
        "text": "a time shift in the input signal results in an identical time shift in the output signal. That is, if y[n] is the output of a discrete- time, time- invariant system when x[n] is the input, then y[n- n] is the output when x[n- n] is applied. In continuous time with y(t) the output corresponding to the input x(t), a time- invariant system will have y(t- n) as the output when x(t- n) is the input.",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "To see how to determine whether a system is time invariant or not, and to gain some insight into this property, consider the following examples:",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Example 1.14",
        "text_level": 1,
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Consider the continuous- time system defined by",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = \\sin |x(t)|. \\tag{1 114}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "To check that this system is time invariant, we must determine whether the time- invariance property holds for any input and any time shift  $t_0$ . Thus, let  $x_1(t)$  be an arbitrary input to this system, and let",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{1}(t) = \\sin |x_{1}(t)| \\tag{1.115}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "be the corresponding output. Then consider a second input obtained by shifting  $x_1(t)$  in time:",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\n\\ldots , \\ldots , t = x_1(t - t_0). \\tag{1.116}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "The output corresponding to this input is",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\ny_2(t) = \\sin |x_2(t)| = \\sin |x_1(t - t_0)|. \\tag{1.117}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Similarly, from eq. (1.115),",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{1}(t - t_{0}) = \\sin |x_{1}(t - t_{0})|. \\tag{1 118}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Comparing eqs. (1.117) and (1.118), we see that  $y_2(t) = y_1(t - t_0)$ , and therefore, this system is time invariant.",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Example 1.15",
        "text_level": 1,
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "As a second example, consider the discrete- time system",
        "page_idx": 76
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = n x[n]. \\tag{1.119}\n$$\n",
        "text_format": "latex",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "This is a time- varying system, a fact that can be verified using the same formal procedure as that used in the preceding example (see Problem 1.28). However, when a system is suspected of being time varying, an approach to showing this that is often very useful is to seek a counterexample—i.e., to use our intuition to find an input signal for which the condition of time invariance is violated. In particular, the system in this example represents a system with a time- varying gain. For example, if we know that the current input value is 1, we cannot determine the current output value without knowing the current time.",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "Consequently, consider the input signal  $x_{1}[n] = \\delta [n]$  which yields an output  $y_{1}[n]$  that is identically 0 (since  $n\\delta [n] = 0$ ). However, the input  $x_{2}[n] = \\delta [n - 1]$  yields the output  $y_{2}[n] = n\\delta [n - 1] = \\delta [n - 1]$ . Thus, while  $x_{2}[n]$  is a shifted version of  $x_{1}[n]$ ,  $y_{2}[n]$  is not a shifted version of  $y_{1}[n]$",
        "page_idx": 76
    },
    {
        "type": "text",
        "text": "While the system in the preceding example has a time- varying gain and as a result is a time- varying system, the system in eq. (1.97) has a constant gain and, in fact, is time invariant. Other examples of time- invariant systems are given by eqs. (1.91)- (1.104). The following example illustrates a time- varying system.",
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "Example 1.16",
        "text_level": 1,
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "Consider the system",
        "page_idx": 77
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(2t). \\tag{1.120}\n$$\n",
        "text_format": "latex",
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "The system represents a time scaling. That is,  $y(t)$  is a time- compressed (by a factor of 2) version of  $x(t)$ . Intuitively, then, any time shift in the input will also be compressed by a factor of 2, and it is for this reason that the system is not time invariant. To demonstrate this by counterexample, consider the input  $x_{1}(t)$  shown in Figure 1.47(a) and the resulting output  $y_{1}(t)$  depicted in Figure 1.47(b). If we then shift the input by 2- 1 e. consider  $x_{2}(t) - x_{1}(t - 2)$ , as shown in Figure 1.47(c)—we obtain the resulting output",
        "page_idx": 77
    },
    {
        "type": "image",
        "img_path": "images/78b712425f92436b8b7445f6a1e66640378dd4ac75e186627ed246d779d23498.jpg",
        "image_caption": [
            "Figure 1.47 (a) The input  $x_{1}(t)$  to the system in Example 1 '6; (b) the output  $y_{1}(t)$  corresponding to  $x_{1}(t)$ ; (c) the shifted input  $x_{2}(t) = x_{1}(t - 2)$ ; (d) the output  $y_{2}(t)$  corresponding to  $x_{2}(t)$ ; (e) the shifted signal  $y_{1}(t - 2)$ . Note that  $y_{2}(t) \\neq y_{1}(t - 2)$ , showing that the system is not time invariant"
        ],
        "image_footnote": [],
        "page_idx": 77
    },
    {
        "type": "text",
        "text": "$y_{2}(t) = x_{2}(2t)$  shown in Figure 1.47(d). Comparing Figures 1.47(d) and (e), we see that  $y_{2}(t) \\neq y_{1}(t - 2)$ . So that the system is not time invariant. (In fact,  $y_{2}(t) = y_{1}(t - 1)$ . So that the output time shift is only half as big as it should be for time invariance, due to the time compression imparted by the system.)",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "1.6.6 Linearity",
        "text_level": 1,
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "A linear system, in continuous time or discrete time, is a system that possesses the important property of superposition: If an input consists of the weighted sum of several signals, then the output is the superposition- that is, the weighted sum- of the responses of the system to each of those signals. More precisely, let  $y_{1}(t)$  be the response of a continuous- . time system to an input  $x_{1}(t)$  and let  $y_{2}(t)$  be the output corresponding to the input  $x_{2}(t)$  Then the system is linear if:",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "1. The response to  $x_{1}(t) + x_{2}(t)$  is  $y_{1}(t) + y_{2}(t)$ .",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "2. The response to  $a x_{1}(t)$  is  $a y_{1}(t)$ , where  $a$  is any complex constant.",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "The first of these two properties is known as the additivity property; the second is known as the scaling or homogeneity property. Although we have written this description using continuous- time signals, the same definition holds in discrete time. The systems specified by eqs. (1.91)- (1.100), (1.102)- (1.104), and (1.119) are linear, while those defined by eqs. (1.101) and (1.114) are nonlinear. Note that a system can be linear without being time invariant, as in eq. (1.119), and it can be time invariant without being linear, as in eqs. (1.101) and (1.114).",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "The two properties defining a linear system can be combined into a single statement",
        "page_idx": 78
    },
    {
        "type": "equation",
        "text": "\n$$\n\\mathbf{\\sigma}_{\\mathrm{discrete~time:}}a_{X_{1}}[n] + b_{X_{2}}[n]\\rightarrow a_{Y_{1}}[n] + b_{Y_{2}}[n]. \\tag{1.122}\n$$\n",
        "text_format": "latex",
        "page_idx": 78
    },
    {
        "type": "equation",
        "text": "\n$$\na_{X_{1}}[n] + b_{X_{2}}[n]\\rightarrow a_{Y_{1}}[n] + b_{Y_{2}}[n]. \\tag{1.122}\n$$\n",
        "text_format": "latex",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "Here,  $a$  and  $b$  are any complex constants. Furthermore, it is straightforward to show from the definition of linearity that if  $x_{k}[n]$ ,  $k = 1, 2, 3, \\ldots$ , are a set of inputs to a discrete- time linear system with corresponding outputs  $y_{k}[n]$ ,  $k = 1, 2, 3, \\ldots$ , then the response to a linear combination of these inputs given by",
        "page_idx": 78
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = \\sum_{k} a_{k} x_{k}[n] = a_{1} x_{1}[n] + a_{2} x_{2}[n] + a_{3} x_{3}[n] + \\ldots \\tag{1.123}\n$$\n",
        "text_format": "latex",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "is",
        "page_idx": 78
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\sum_{k} a_{k} y_{k}[n] = a_{1} y_{1}[n] + a_{2} y_{2}[n] + a_{3} y_{3}[n] + \\ldots \\tag{1.124}\n$$\n",
        "text_format": "latex",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "This very important fact is known as the superposition property, which holds for linear systems in both continuous and discrete time.",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "A direct consequence of the superposition property is that, for linear systems, an input which is zero for all time results in an output which is zero for all time. For example, if  $x[n] \\rightarrow y[n]$ , then the homogeneity property tells us that",
        "page_idx": 78
    },
    {
        "type": "equation",
        "text": "\n$$\n0 = 0 \\cdot x[n] \\rightarrow 0 \\cdot y[n] = 0. \\tag{1.125}\n$$\n",
        "text_format": "latex",
        "page_idx": 78
    },
    {
        "type": "text",
        "text": "In the following examples we illustrate how the linearity of a given system can be checked by directly applying the definition of linearity.",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Example 1.17",
        "text_level": 1,
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Consider a system  $S$  whose input  $x(t)$  and output  $y(t)$  are related by",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = t\\times t)\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "To determine whether or not  $S$  is linear, we consider two arbitrary inputs  $x_{1}(t)$  and  $x_{2}(t)$ .",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}x_{1}(t) \\leftrightarrow y_{1}(t) = t x_{1}(t) \\\\ x_{2}(t) \\rightarrow y_{2}(t) = t x_{2}(t) \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Let  $x_{1}(t)$  be a linear combination of  $x_{1}(t)$  and  $x_{2}(t)$ . That is,",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\nx_{3}(t) = a x_{1}(t) + b x_{2}(t)\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "where  $a$  and  $b$  are arbitrary scalars. If  $x_{1}(t)$  is the input to  $S$ , then the corresponding output may be expressed as",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {v_{1}(t) = t x_{3}(t)}\\\\ & {\\qquad = t(a x_{1}(t) - b x_{2}(t))}\\\\ & {\\qquad = a t x_{1}(t) + b t x_{2}(t)}\\\\ & {\\qquad = a y_{1}(t) + b y_{2}(t)} \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "We conclude that the system  $S$  is linear.",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Example 1.18",
        "text_level": 1,
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Let us apply the linearity- checking procedure of the previous example to another system  $S$  whose input  $x(t)$  and output  $y(t)$  are related by",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x^{2}(t)\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Defining  $x_{1}(t), x_{2}(t)$ , and  $x_{3}(t)$  as in the previous example, we have",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}x_{1}(t) \\rightarrow y_{1}(t) = x_{1}^{2}(t) \\\\ x_{2}(t) \\rightarrow y_{2}(t) = x_{2}^{2}(t) \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 79
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l} & {x_{3}(t)\\rightarrow y_{1}(t) = x_{1}^{2}(t)}\\\\ & {\\qquad = (a x_{1}(t) + b x_{2}(t))^{2}}\\\\ & {\\qquad = a^{2}x_{1}^{2}(t) + b^{2}x_{2}^{2}(t) + 2a b x_{1}(t)x_{2}(t)}\\\\ & {\\qquad = a^{2}y_{1}(t) + b^{2}y_{2}(t) + 2a b x_{1}(t)x_{2}(t)} \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Clearly, we can specify  $x_{1}(t), x_{2}(t), a$  and  $b$  such that  $y_{1}(t)$  is not the same as  $a x_{1}(t) + b y_{2}(t)$ . For example, if  $x_{1}(t) = 1, x_{2}(t) = 0, a = 2$ , and  $b = 0$ , then  $y_{1}(t) = (2x_{1}(t))^{2} = 4$ , but  $2y_{1}(t) = 2(x_{1}(t))^{2} = 2$ . We conclude that the system  $S$  is not linear.",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "Example 1.19",
        "text_level": 1,
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "In checking the linearity of a system, it is important to remember that the system must satisfy both the additivity and homogeneity properties and that the signals, as well as any scaling constants, are allowed to be complex. To emphasize the importance of these",
        "page_idx": 79
    },
    {
        "type": "text",
        "text": "points, consider the system specified by",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\mathcal{R}e[\\lambda [n]]. \\tag{1.126}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "As shown in Problem 1.29, this system is additive: however, it does not satisfy the homogeneity property, as we now demonstrate. Let",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = r[n] + j s[n] \\tag{1.127}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "be an arbitrary complex input with real and imaginary parts  $r[n]$  and  $s[n]$ , respectively. So that the corresponding output is",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\n\\mathbf{v}_{1}[n] = r[n]. \\tag{1.128}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Now, consider scaling  $x_{1}[n]$  by a complex number, for example,  $a = j$ . i.e., consider the input",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}x_{2}[n] = j x_{1}[n] = j(r[n] + j s[n]) \\\\ = -s[n] + j r[n]. \\end{array} \\tag{1.129}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "The output corresponding to  $x_{2}[n]$  is",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{2}[n] = \\mathcal{R}e\\{x_{2}[n]\\} = -s[n], \\tag{1.130}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "which is not equal to the scaled version of  $y_{1}[n]$",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\na y_{1}[n] = j r[n]. \\tag{1.131}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "We conclude that the system violates the homogeneity property and hence is not linear.",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Example 1.20",
        "text_level": 1,
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "Consider the system",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\n\\gamma [n] = 2x[n] + 3. \\tag{1.132}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "This system is not linear, as can be verified in several ways. For example, the system violates the additivity property: If  $x_{1}[n] = 2$  and  $x_{2}[n] = 3$ , then",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r}x_{1}[n] \\rightarrow y_{1}[n] = 2x_{1}[n] + 3 = 7, \\\\ x_{2}[n] \\rightarrow y_{2}[n] = 2x_{2}[n] + 3 = 9. \\end{array} \\tag{1.134}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "However, the response to  $x_{3}[n] = x_{1}[n] + x_{2}[n]$  is",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{3}[n] = 2[x_{1}[n] + x_{2}[n]] + 3 = 13, \\tag{1.135}\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "which does not equal  $y_{1}[n] + y_{2}[n] = 16$ . Alternatively, since  $y[n] = 3$  if  $x[n] = 0$ , we see that the system violates the \"zero- in/zero- out\" property of linear systems given in eq. (1.125).",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "It may seem surprising that the system in the above example is nonlinear, since eq. (1.132) is a linear equation. On the other hand, as depicted in Figure 1.48, the output of this system can be represented as the sum of the output of a linear system and another signal equal to the zero- input response of the system. For the system in eq. (1.132), the linear system is",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n]\\rightarrow 2x[n],\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "text",
        "text": "and the zero- input response is",
        "page_idx": 80
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{0}[n] = 3.\n$$\n",
        "text_format": "latex",
        "page_idx": 80
    },
    {
        "type": "image",
        "img_path": "images/c1129526730c20ef1f6830aac4953a5a239c2c95e9cf1a59730627e8b06f8bca.jpg",
        "image_caption": [
            "Figure 1.48 Structure of an incrementally linear system. Here,  $y_{0}[n]$  is the zero-input response of the system."
        ],
        "image_footnote": [],
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "There are, in fact, large classes of systems in both continuous and discrete time that can be represented as in Figure 1.48- - i.e. for which the overall system output consists of the superposition of the response of a linear system with a zero- input response As shown in Problem 1.47, such systems correspond to the class of int renmentally linear system- - i.e., systems in continuous or discrete time that respond linearly to changes in the input. In other words, the difference between the responses to any two inputs to an incrementally linear system is a linear (i.e., additive and homogencous) function of the difference between the two inputs. For example, if  $x_{1}[n]$  and  $x_{2}[n]$  are two inputs to the system specified by eq. (1.132), and if  $y_{1}[n]$  and  $y_{2}[n]$  are the corresponding outputs, then",
        "page_idx": 81
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{1}[n] - y_{2}[n] = 2x_{1}[n] + 3 - \\{2x_{2}[n] + 3\\} = 2\\{x_{1}[n] - x_{2}[n]\\} ; \\tag{1.136}\n$$\n",
        "text_format": "latex",
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "1.7 SUMMARY",
        "text_level": 1,
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "In this chapter, we have developed a number of basic concepts related to continuous- time and discrete- time signals and systems. We have presented both an intuitive picture of what signals and systems are through several examples and a mathematical representation for signals and systems that we will use throughout the book. Specifically, we introduced graphical and mathematical representations of signals and used these representations in performing transformations of the independent variable. We also defined and examined several basic signals, both in continuous time and in discrete time. These included complex exponential signals, sinusoidal signals, and unit impulse and step functions. In addition, we investigated the concept of periodicity for continuous- time and discrete- time signals.",
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "In developing some of the elementary ideas related to systems, we introduced block diagrams to facilitate our discussions concerning the interconnection of systems, and we defined a number of important properties of systems, including causality, stability, time invariance, and linearity.",
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "The primary focus in most of this book will be on the class of linear, time- invariant (LTI) systems, both in continuous time and in discrete time. These systems play a particularly important role in system analysis and design, in part due to the fact that many systems encountered in nature can be successfully modeled as linear and time invariant. Furthermore, as we shall see in the following chapters, the properties of linearity and time invariance allow us to analyze in detail the behavior of LTI systems.",
        "page_idx": 81
    },
    {
        "type": "text",
        "text": "Basic problems emphasize the mechanics of using concepts and methods in a manner similar to that illustrated in the examples that are solved in the text",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "Advanced problems explore and elaborate upon the foundations and practical implications of the textual material.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "The first section of problems belongs to the basic category, and the answers are provided in the back of the book. The next two sections contain problems belonging to the basic and advanced categories, respectively. A final section. Mathematical Review, provides practice problems on the fundamental ideas of complex arithmetic and algebra.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "BASIC PROBLEMS WITH ANSWERS",
        "text_level": 1,
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.1. Express each of the following complex numbers in Cartesian form \\((x + j y)\\) \\(\\frac{1}{2} e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\pi}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(i\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{i\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\)\\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\( e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\delta}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\(e^{j\\sigma}\\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}}\\\\ & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{\\mathrm{~\\lambda~}}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*} \\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}}} \\end{array} \\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{\\mathrm{~\\lambda~}}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*} \\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}} \\end{array} \\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{\\mathrm{\\lambda~}}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}\\mathrm{\\lambda~}^{*}} \\end{array} \\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{\\mathrm{~\\lambda~}}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}} \\end{array} \\) \\( \\begin{array}{r l} & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}\\mathrm{~\\lambda~~}^{*}}\\\\ & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~~\\lambda~}^{*}}\\\\ & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}}\\\\ & {\\mathrm{~\\lambda~}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\\\ & {\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{-}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*}\\mathrm{~\\lambda~}^{*\n\\]",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.2. Express each of the following complex numbers in polar form  $\\{r e^{\\prime \\beta}$  ,with  $\\pi <$ $\\theta = \\pi_{1} - 5, - 2, - 3j,\\frac{1}{2} - j_{2}^{\\cdot \\cdot \\cdot},1 + j,(1 - j)^{2},j(1 - j),(1 + j) / (1\\quad j),(v\\cdot \\overline{{2}} +j\\cdot \\overline{{2}} / 2)$ $(1 + j\\sqrt{3})$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.3. Determine the values of  $P$  ,and  $F_{\\mathrm{w}}$  for each of the following signals:",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x_{1}(t) = e^{-\\pi}u(t)$  \n(b)  $x_{2}(t) = e^{j(2t + \\pi /4)}$  \n(c)  $x_{3}(t) = \\cos (t)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(d)  $x_{1}[n] = (\\frac{1}{2})^{n}u[n]$  \n(e)  $x_{2}[n] = e^{i(\\pi /2n + \\pi /8)}$  \n(f)  $x_{3}[n] = \\cos (\\frac{\\pi}{2} n)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.4. Let  $\\lambda [n]$  be a signal with  $x[n] = 0$  for  $n = - 2$  and  $n > 4$  . For each signal given below, determine the values of  $n$  for which it is guaranteed to be zero.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x[n - 3]$  \n(b)  $x[n + 4]$  \n(c)  $x[-n]$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(d)  $x[-n + 2]$  \n(e)  $x[-n - 2]$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.5. Let  $x(t)$  be a signal with  $x(t) = 0$  for  $t = 3$  . For each signal given below, determine the values of  $t$  for which it is guaranteed to be zero.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x(1 - t)$  \n(b)  $x(1 - t) + x(2 - t)$  \n(c)  $x(1 - t)x(2 - t)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(d)  $x(3t)$  \n(e)  $x(t / 3)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.6. Determine whether or not each of the following signals is periodic:",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x_{1}(t) = 2e^{j(t + \\pi /4)}u(t)$  \n(b)  $x_{2}[n] = u[n] + u[-n]$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(c)  $x_{3}[n] = \\sum_{k = -\\infty}^{\\infty}\\delta [n - 4k] - \\delta [n - 1 - 4k]$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.7. For each signal given below, determine all the values of the independent variable at which the even part of the signal is guaranteed to be zero.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x_{1}[n] = u[n] - u[n - 4]$  \n(b)  $x_{2}(t) = \\sin (\\frac{1}{2} t)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(c)  $x_{3}[n] = (\\frac{1}{2})^{n}u[n - 3]$  \n(d)  $x_{4}(t) = e^{-\\delta^{2}u(t + 2)}$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.8. Express the real part of each of the following signals in the form  $A e^{- a t}\\cos (\\omega t + \\phi)$  where  $A, a, \\omega$  ,and  $\\phi$  are real numbers with  $A > 0$  and  $- \\pi < \\phi \\leq \\pi$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x_{1}(t) = -2$  \n(b)  $x_{2}(t) = \\sqrt{2e^{j\\pi / 4}}\\cos (3t + 2\\pi)$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(c)  $x_{3}(t) = e^{-t}\\sin (3t + \\pi)$  \n(d)  $x_{4}(t) = j e^{(-2 + j100)t}$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.9. Determine whether or not each of the following signals is periodic. If a signal is periodic, specify its fundamental period.",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(a)  $x_{1}(t) = je^{j10t}$  \n(b)  $x_{2}(t) = e^{(-1 + \\frac{1}{2})t}$  \n(c)  $x_{3}[n] = e^{j7\\pi n}$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "(d)  $x_{4}[n] = 3e^{j3\\pi (n + 1 / 2t)}$  \n(e)  $x_{5}[n] = 3e^{j3\\pi (n + 1 / 2)}$",
        "page_idx": 82
    },
    {
        "type": "text",
        "text": "1.10. Determine the fundamental period of the signal  $x(t) = 2\\cos (10t + 1) - \\sin (4t - 1)$ . 1.11. Determine the fundamental period of the signal  $x[n] = 1 + e^{j4\\pi n\\pi} - e^{j2\\pi n\\pi /5}$ .",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "1.12. Consider the discrete- time signal",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = 1 - \\sum_{k = 1}^{\\infty}\\delta [n - 1 - k].\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "Determine the values of the integers  $M$  and  $n_0$  so that  $x[n]$  may be expressed as",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = u[Mn - n_0]\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "1.13. Consider the continuous- time signal",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = \\delta (t + 2) - \\delta (t - 2).\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "Calculate the value of  $E_{\\infty}$  for the signal",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = \\int_{-\\infty}^{t}x(\\tau)d\\tau .\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "1.14. Consider a periodic signal",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = \\left\\{ \\begin{array}{ll}1, & 0\\leq t\\leq 1 \\\\ -2, & 1< t< 2 \\end{array} \\right.\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "with period  $T = 2$ . The derivative of this signal is related to the \"impulse train\"",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\ng(t) = \\sum_{k = -\\infty}^{\\infty}\\delta (t - 2k)\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "with period  $T = 2$ . It can be shown that",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{dx(t)}{dt} = A_1g(t - t_1) + A_2g(t - t_2).\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "Determine the values of  $A_1, t_1, A_2$ , and  $t_2$ .",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "1.15. Consider a system S with input  $x[n]$  and output  $y[n]$  . This system is obtained through a series interconnection of a system  $S_{1}$  followed by a system  $S_{2}$  . The input- output relationships for  $s_{1}$  and  $s_{2}$  are",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{r l}{S_{1}:} & {\\quad y_{1}[n] = 2x_{1}[n] + 4x_{1}[n - 1],}\\\\ {S_{2}:} & {\\quad y_{2}[n] = x_{2}[n - 2] + \\frac{1}{2} x_{2}[n - 3],} \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "where  $x_1[n]$  and  $x_2[n]$  denote input signals.",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "(a) Determine the input-output relationship for system  $S$ .",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "(b) Does the input-output relationship of system  $S$  change if the order in which  $S_1$  and  $S_2$  are connected in series is reversed (i.e., if  $S_2$  follows  $S_1$ )?",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "1.16. Consider a discrete- time system with input  $x[n]$  and output  $y[n]$ . The input- output relationship for this system is",
        "page_idx": 83
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[n]x[n - 2].\n$$\n",
        "text_format": "latex",
        "page_idx": 83
    },
    {
        "type": "text",
        "text": "(a) Is the system memoryless?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(b) Determine the output of the system when the input is  $A\\delta [n]$ , where  $A$  is any real or complex number.",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(c) Is the system invertible?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.17. Consider a continuous- time system with input  $x(t)$  and output  $y(t)$  related by",
        "page_idx": 84
    },
    {
        "type": "equation",
        "text": "\n$$\ny(t) = x(\\sin (t)).\n$$\n",
        "text_format": "latex",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a) Is this system causal?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(b) Is this system linear?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.18. Consider a discrete- time system with input  $x[n]$  and output  $y[n]$  related by",
        "page_idx": 84
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\sum_{k = n - n_{0}}^{n + n_{0}}x[k],\n$$\n",
        "text_format": "latex",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "where  $n_{0}$  is a finite positive integer.",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a) Is this system linear?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a) Is this system time-invariant?",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(c) If  $x[n]$  is known to be bounded by a finite integer  $B$  (i.e.,  $|x[n]|< B$  for all  $n$ ), it can be shown that  $y[n]$  is bounded by a finite number  $C$ . We conclude that the given system is stable. Express  $C$  in terms of  $B$  and  $n_{0}$ .",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.19. For each of the following input- output relationships, determine whether the corresponding system is linear, time invariant or both.",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a)  $y(t) = t^{2}x(t - 1)$  \n(b)  $y[n] = x[n - 2]$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(c)  $y[n] = x[n + 1] - x[n - 1]$  \n(d)  $y[n] = \\delta \\delta \\{x(t)\\}$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.20. A continuous- time linear system  $S$  with input  $x(t)$  and output  $y(t)$  yields the following input- output pairs:",
        "page_idx": 84
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}{{x(t)=e^{j2t}\\xrightarrow{S}y(t)=e^{j3t},}}\\\\ {{x(t)=e^{-j2t}\\xrightarrow{S}y(t)=e^{-j3t}.}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a) If  $x_{1}(t) = \\cos (2t)$ , determine the corresponding output  $y_{1}(t)$  for system  $S$ .",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(b) If  $x_{2}(t) = \\cos (2(t - \\frac{1}{2}))$ , determine the corresponding output  $y_{2}(t)$  for system  $S$ .",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "BASIC PROBLEMS",
        "text_level": 1,
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.21. A continuous- time signal  $x(t)$  is shown in Figure P1.21. Sketch and label carefully each of the following signals:",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a)  $x(t - 1)$  \n(b)  $x(2 - t)$  \n(c)  $x(2t + 1)$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(d)  $x(4 - \\frac{1}{2})$  \n(e)  $[x(t) + x(-t)]u(t)$  \n(f)  $x(t)[\\delta (t + \\frac{3}{2}) - \\delta (t - \\frac{3}{2})]$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "1.22. A discrete- time signal is shown in Figure P1.22. Sketch and label carefully each of the following signals:",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(a)  $x[n - 4]$  \n(b)  $x[3 - n]$  \n(c)  $x[3n]$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(d)  $x[3n + 1]$  \n(e)  $x[n]u[3 - n]$  \n(f)  $x[n - 2]\\delta [n - 2]$",
        "page_idx": 84
    },
    {
        "type": "text",
        "text": "(g)  $\\frac{1}{2} x[n] + \\frac{1}{2} (-1)^{n}x[n]$  \n(h)  $x[(n - 1)^{2}]$",
        "page_idx": 84
    },
    {
        "type": "image",
        "img_path": "images/ac23730999a1a872f28c2147430ba806d550d7311171b5adc6c15d8a0b1ca555.jpg",
        "image_caption": [
            "Figure P1.21"
        ],
        "image_footnote": [],
        "page_idx": 85
    },
    {
        "type": "image",
        "img_path": "images/9356bb83f58ba9d02278607a586bb0d3dd89524767bd350c20a8cd5b788cdd2f.jpg",
        "image_caption": [
            "Figure P1.22"
        ],
        "image_footnote": [],
        "page_idx": 85
    },
    {
        "type": "text",
        "text": "1.23. Determine and sketch the even and odd parts of the signals depicted in Figure P1.23 Label your sketches carefully.",
        "page_idx": 85
    },
    {
        "type": "image",
        "img_path": "images/2f8c96aaf9354e4a19e49c2e68c4950f6ac54ee6f2187d1ce25ad7025ba2c407.jpg",
        "image_caption": [
            "Figure P1.23"
        ],
        "image_footnote": [],
        "page_idx": 85
    },
    {
        "type": "text",
        "text": "1.24. Determine and sketch the even and odd parts of the signals depicted in Figure P1.24 Label your sketches carefully.",
        "page_idx": 85
    },
    {
        "type": "image",
        "img_path": "images/8b2af193c599a6eb5e3bd3807242a4adf4d8d4c69857e1094ecec40d62b4cb1a.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "1.25. Determine whether or not each of the following continuous- time signals is periodic If the signal is periodic, determine its fundamental period.",
        "page_idx": 86
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l l}{{x(t)=3\\cos(4t+\\frac{\\pi}{3})}}&{{\\qquad(\\mathbf{b})\\ x(t)=e^{j(\\pi t-1)}}}\\\\ {{x(t)=[\\cos(2t-\\frac{\\pi}{3})]^{2}}}&{{\\qquad(\\mathbf{d})\\ x(t)=\\delta v\\{\\cos(4\\pi t)u(t)\\}}}\\\\ {{x(t)=\\delta v\\{\\sin(4\\pi t)u(t)\\}}}&{{\\qquad(\\mathbf{f})\\ x(t)=\\sum_{n=-\\infty}^{\\infty}e^{-\\left(2t-n\\right)}}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "1.26. Determine whether or not each of the following discrete- time signals is periodic. If the signal is periodic, determine its fundamental period.",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "(a)  $\\begin{array}{r}{x[n] = \\sin (\\frac{\\theta\\pi}{2} n + 1)} \\end{array}$  \n(b)  $\\begin{array}{r}{x[n] = \\cos (\\frac{\\pi}{8} -\\pi)} \\end{array}$  \n(c)  $\\begin{array}{r}{x[n] = \\cos (\\frac{\\pi}{8} n^{2})} \\end{array}$  \n(d)  $\\begin{array}{r}{x[n] = \\cos (\\frac{\\pi}{2} n)\\cos (\\frac{\\pi}{4} n)} \\end{array}$  \n(e)  $\\begin{array}{r}{x[n] = 2\\cos (\\frac{\\pi}{4} n) + \\sin (\\frac{\\pi}{8} n) - 2\\cos (\\frac{\\pi}{2} n + \\frac{\\pi}{6})} \\end{array}$",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "1.27. In this chapter, we introduced a number of general properties of systems. In particular, a system may or may not be",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "(1) Mercury (2) Time invariant (3) Linear (4) Causal (5) Stable",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "Determine which of these properties hold and which do not hold for each of the following continuous- time systems. Justify your answers. In each example,  $y(t)$  denotes the system output and  $x(t)$  is the system input.",
        "page_idx": 86
    },
    {
        "type": "text",
        "text": "(a)  $y(t) = x(t - 2) + x(2 - t)$  \n(b)  $y(t) = [\\cos (3t)]x(t)$  \n(c)  $y(t) = \\int_{-2\\pi}^{2t}x(\\tau)d\\tau$  \n(d)  $y(t) = \\left\\{ \\begin{array}{l l}{0,} & {t< 0}\\\\ {x(t) + x(t - 2),} & {t\\geq 0} \\end{array} \\right.$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(e)  $y(t) = \\left\\{ \\begin{array}{l l}{0,}\\\\ {x(t) + x(t - 2),}\\\\ {x(t) = \\frac{d x(t)}{d t}} \\end{array} \\right.$  \n(f)  $y(t) = x(t / 3)$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(g) y(t) = d",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "1.28. Determine which of the properties listed in Problem 1.27 hold and which do not hold for each of the following discrete- time systems. Justify your answers. In each example,  $y[n]$  denotes the system output and  $x[n]$  is the system input.",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(a)  $y[n] = x[-n]$  \n(b)  $y[n] = x[n - 2] - 2x[n - 8]$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(c)  $y[n] = nx[n]$  \n(d)  $y[n] = \\delta \\mathbf{e}\\{x[n - 1]\\}$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(e)  $y[n] = \\left\\{ \\begin{array}{l l}{x[n],} & {n\\geq 1}\\\\ {0,} & {n = 0}\\\\ {x[n + 1],} & {n\\leq -1} \\end{array} \\right.$  \n(f)  $y[n] = \\left\\{ \\begin{array}{l l}{x[n],} & {n\\geq 1}\\\\ {0,} & {n = 0}\\\\ {x[n],} & {n\\leq -1} \\end{array} \\right.$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(g)  $y[n] = x[4n + 1]$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "1.29. (a) Show that the discrete- time system whose input  $x[n]$  and output  $y[n]$  are related by  $y[n] = \\{R e\\{x[n]\\}$  is additive. Does this system remain additive if its inputoutput relationship is changed to  $y[n] = \\{R e\\{e^{j\\pi n / 4}x[n]\\} \\} ?$  (Do not assume that  $x[n]$  is real in this problem.)",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(b) In the text, we discussed the fact that the property of linearity for a system is equivalent to the system possessing both the additivity property and homogeneity property. Determine whether each of the systems defined below is additive and/or homogeneous. Justify your answers by providing a proof for each property if it holds or a counterexample if it does not.",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "\\(\\begin{array}{r}{\\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\mathbf{\\cdot}\\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\nabla \\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla} \\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla}\\cdot \\mathbf{\\nabla\\cdot}\\mathbf{\\nabla}\\cdot \\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\mathbf{\\nabla\\cdot}\\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot\\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \\cdot \n\\]",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "1.30. Determine if each of the following systems is invertible. If it is, construct die inverse system. If it is not, find two input signals to the system that have the same output.",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(a)  $y(t) = x(t - 4)$  \n(b)  $y(t) = \\cos [x(t)]$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(c)  $y[t] = n x[n]$  \n(d)  $y(t) = \\int_{-x}^{t}x(\\tau)d\\tau$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(e)  $y[n] = \\left\\{ \\begin{array}{l l}{x[n - 1],} & {n\\geq 1}\\\\ {0,} & {n = 0}\\\\ {x[n],} & {n\\leq -1} \\end{array} \\right.$  \n(f)  $y[n] = x[n]x[n - 1]$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(g)  $y[n] = x[1 - n]$  \n(b)  $y(t) = \\int_{-a}^{t}e^{-t - \\tau \\tau}x(\\tau)d\\tau$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(i)  $\\begin{array}{r}{y[t] = \\sum_{k = -\\infty}^{n}(\\frac{1}{2})^{t - k}x[k]} \\end{array}$  \n(j)  $y(t) = \\frac{d x(t)}{d t}$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(k)  $y[n] = \\left\\{ \\begin{array}{l l}{x[n + 1],} & {n\\geq 0}\\\\ {x[n],} & {n\\leq -1} \\end{array} \\right.$  \n(l)  $y(t) = x(2t)$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "(m)  $y[n] = x[2n]$  \n(n)  $y[n] = \\left\\{ \\begin{array}{l l}{x[n / 2],} & {\\quad n\\mathrm{even}}\\\\ {0,} & {\\quad n\\mathrm{odd}} \\end{array} \\right.$",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "1.31. In this problem, we illustrate one of the most important consequences of the properties of linearity and time invariance. Specifically, once we know the response of a linear system or a linear time- invariant (LTI) system to a single input or the responses to several inputs, we can directly compute the responses to many other",
        "page_idx": 87
    },
    {
        "type": "text",
        "text": "input signals. Much of the remainder of this book deals with a thorough exploitation of this fact in order to develop results and techniques for analyzing and synthesizing LTI systems.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(a) Consider an LTI system whose response to the signal  $x_{1}(t)$  in Figure P1.31(a) is the signal  $y_{1}(t)$  illustrated in Figure P1.31(b). Determine and sketch carefully the response of the system to the input  $x_{2}(t)$  depicted in Figure P1.31(c).",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(b) Determine and sketch the response of the system considered in part \n(a) to the input  $x_{3}(t)$  shown in Figure P1.31(d).",
        "page_idx": 88
    },
    {
        "type": "image",
        "img_path": "images/8d6b43ea4971bca5c9b78833564b58ade608d945c8fbf924ecd4aa7920e552e3.jpg",
        "image_caption": [
            "(a)"
        ],
        "image_footnote": [],
        "page_idx": 88
    },
    {
        "type": "image",
        "img_path": "images/f37e3a152472d31e1891668085e7a73dea825fb8e7af77d6bd1328a3346b326d.jpg",
        "image_caption": [
            "(b)"
        ],
        "image_footnote": [],
        "page_idx": 88
    },
    {
        "type": "image",
        "img_path": "images/bf21718c8731dbebcb206153c4aeb87b1b3716364981ec24bfbb18a4732c5d10.jpg",
        "image_caption": [
            "(c)"
        ],
        "image_footnote": [],
        "page_idx": 88
    },
    {
        "type": "image",
        "img_path": "images/931f4e4a38db68d01787b1eec9da4cf0f46a606b456920061f7b772eaacb11ad.jpg",
        "image_caption": [
            "(d) Figure P1.31"
        ],
        "image_footnote": [],
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "ADVANCED PROBLEMS",
        "text_level": 1,
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "1.32. Let  $x(t)$  be a continuous- time signal, and let",
        "page_idx": 88
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{1}(t) = x(2t) \\text{and} y_{2}(t) = x(t / 2).\n$$\n",
        "text_format": "latex",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "The signal  $y_{1}(t)$  represents a speeded up version of  $x(t)$  in the sense that the duration of the signal is cut in half. Similarly,  $y_{2}(t)$  represents a slowed down version of  $x(t)$  in the sense that the duration of the signal is doubled. Consider the following statements:",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(1) If  $x(t)$  is periodic, then  $y_{1}(t)$  is periodic.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(2) If  $y_{1}(t)$  is periodic, then  $x(t)$  is periodic.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(3) If  $x(t)$  is periodic, then  $y_{2}(t)$  is periodic.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "(4) If  $y_{2}(t)$  is periodic, then  $x(t)$  is periodic.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "For each of these statements, determine whether it is true, and if so, determine the relationship between the fundamental periods of the two signals considered in the statement. If the statement is not true, produce a counterexample to it.",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "1.33. Let  $x[n]$  be a discrete- time signal, and let",
        "page_idx": 88
    },
    {
        "type": "equation",
        "text": "\n$$\ny_{1}[n] = x[2n] \\text{and} y_{2}[n] = \\begin{cases} x[n / 2], & n \\text{even} \\\\ 0, & n \\text{odd} \\end{cases}\n$$\n",
        "text_format": "latex",
        "page_idx": 88
    },
    {
        "type": "text",
        "text": "The signals  $y_{1}[n]$  and  $y_{2}[n]$  respectively represent in some sense the speeded up and slowed down versions of  $x[n]$ . However, it should be noted that the discrete- time notions of speeded up and slowed down have subtle differences with respect to their continuous- time counterparts. Consider the following statements:",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(1) If  $x[n]$  is periodic, then  $y_{1}[n]$  is periodic.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(2) If  $y_{1}[n]$  is periodic, then  $x[n]$  is periodic.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(3) If  $x[n]$  is periodic, then  $y_{2}[n]$  is periodic.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(4) If  $y_{2}[n]$  is periodic, then  $x[n]$  is periodic.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "For each of these statements, determine whether it is true, and if so, determine the relationship between the fundamental periods of the two signals considered in the statement. If the statement is not true, produce a counterexample to it.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "1.34. In this problem, we explore several of the properties of even and odd signals.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(a) Show that if  $x[n]$  is an odd signal, then",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = -\\infty}^{+\\infty}x[n] = 0.\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(b) Show that if  $x_{1}[n]$  is an odd signal and  $x_{2}[n]$  is an even signal, then  $x_{1}[n]x_{2}[n]$  is an odd signal.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(c) Let  $x[n]$  be an arbitrary signal with even and odd parts denoted by",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\nx_{e}[n] = \\mathcal{E}v[x[n]]\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "and",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\nx_{\\sigma}[n] = \\mathcal{O}d[x[n]].\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "Show that",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = -\\infty}^{+\\infty}x^{2}[n] = \\sum_{n = -\\infty}^{+\\infty}x^{2}[n] + \\sum_{n = -\\infty}^{+\\infty}x_{\\sigma}^{2}[n].\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "(d) Although parts \n(a)-(c) have been stated in terms of discrete-time signals, the analogous properties are also valid in continuous time. To demonstrate this, show that",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{-\\infty}^{+\\infty}x^{2}(t)d t = \\int_{-\\infty}^{+\\infty}x_{\\sigma}^{2}(t)d t + \\int_{-\\infty}^{+\\infty}x_{\\sigma}^{2}(t)d t,\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "where  $x_{\\sigma}(t)$  and  $x_{\\sigma}(t)$  are, respectively, the even and odd parts of  $x(t)$ .",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "1.35. Consider the periodic discrete- time exponential time signal",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = e^{j\\pi (2\\pi /N)t}.\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "Show that the fundamental period of this signal is",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\nN_{0} = N / \\mathrm{gcd}(m,N),\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "where gcd(m,N) is the greatest common divisor of m and N- - that is. the largest integer that divides both m and N an integral number of times. For example,",
        "page_idx": 89
    },
    {
        "type": "equation",
        "text": "\n$$\n\\gcd (2,3) = 1,\\gcd (2,4) = 2,\\gcd (8,12) = 4.\n$$\n",
        "text_format": "latex",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "Note that  $N_{0} = N$  if  $m$  and  $N$  have no factors in common.",
        "page_idx": 89
    },
    {
        "type": "text",
        "text": "1.36. Let  $x(t)$  be the continuous- time complex exponential signal",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t) = e^{j\\omega_{0}t}\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "with fundamental frequency  $\\omega_{0}$  and fundamental period  $T_{0} = 2\\pi i\\omega_{0}$ . Consider the discrete- time signal obtained by taking equally spaced samples of  $x(t)$ —that is,",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\nx[n] = x(nT) = e^{j\\omega_{0}nT}.\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(a) Show that  $x[n]$  is periodic if and only if  $T / T_{0}$  is a rational number—that is, if and only if some multiple of the sampling interval exactly equals a multiple of the period of  $x(t)$ .",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(b) Suppose that  $x[n]$  is periodic—that is, that",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\n\\frac{T}{T_{0}} = \\frac{p}{q}, \\tag{P}\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "where  $p$  and  $q$  are integers. What are the fundamental period and fundamental frequency of  $x[n]$ ? Express the fundamental frequency as a fraction of  $\\omega_{0}T$ .",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(c) Again assuming that  $T / T_{0}$  satisfies eq. (P1.36-1), determine precisely how many periods of  $x(t)$  are needed to obtain the samples that form a single period of  $x[n]$ .",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "1.37. An important concept in many communications applications is the correlation between two signals. In the problems at the end of Chapter 2, we will have more to say about this topic and will provide some indication of how it is used in practice. For now, we content ourselves with a brief introduction to correlation functions and some of their properties.",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "Let  $x(t)$  and  $y(t)$  be two signals; then the correlation function is defined as",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\n\\phi_{xy}(t) = \\int_{-x}^{\\infty}x(t + \\tau)y(t)dt.\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "The function  $\\phi_{xx}(t)$  is usually referred to as the autocorrelation function of the signal  $x(t)$ , while  $\\phi_{xy}(t)$  is often called a cross- correlation function.",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(a) What is the relationship between  $\\phi_{xy}(t)$  and  $\\phi_{yy}(t)$ ?",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(b) Compute the odd part of  $\\phi_{xx}(t)$ .",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(c) Suppose that  $y(t) = x(t + T)$ . Express  $\\phi_{xy}(t)$  and  $\\phi_{yy}(t)$  in terms of  $\\phi_{xx}(t)$ .",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "1.38. In this problem, we examine a few of the properties of the unit impulse function. (a) Show that",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\n\\delta (2t) = \\frac{1}{2}\\delta (t).\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "Hint: Examine  $\\delta_{\\Delta}(t)$ . (See Figure 1.34. )",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "(b) In Section 1.4, we defined the continuous-time unit impulse as the limit of the signal  $\\delta_{\\Delta}(t)$ . More precisely, we defined several of the properties of  $\\delta (t)$  by examining the corresponding properties of  $\\delta_{\\Delta}(t)$ . For example, since the signal",
        "page_idx": 90
    },
    {
        "type": "equation",
        "text": "\n$$\nu_{\\Delta}(t) = \\int_{-x}^{t}\\delta_{\\Delta}(\\tau)dt\n$$\n",
        "text_format": "latex",
        "page_idx": 90
    },
    {
        "type": "text",
        "text": "converges to the unit step",
        "page_idx": 91
    },
    {
        "type": "equation",
        "text": "\n$$\n\\mathfrak{u}(t) = \\lim_{\\Delta \\to 0}\\mathfrak{u}_{\\Delta}(t), \\tag{P1.38-1}\n$$\n",
        "text_format": "latex",
        "page_idx": 91
    },
    {
        "type": "text",
        "text": "we could interpret  $\\delta (t)$  through the equation",
        "page_idx": 91
    },
    {
        "type": "equation",
        "text": "\n$$\nu(t) = \\int_{\\infty}^{t}\\delta (t)d\\tau\n$$\n",
        "text_format": "latex",
        "page_idx": 91
    },
    {
        "type": "text",
        "text": "or by viewing  $\\delta (t)$  as the formal derivative of  $u(t)$ .",
        "page_idx": 91
    },
    {
        "type": "text",
        "text": "This type of discussion is important, as we are in effect trying to define  $\\delta (t)$  through its properties rather than by specifying its value for each  $t$ , which is not possible. In Chapter 2, we provide a very simple characterization of the behavior of the unit impulse that is extremely useful in the study of linear time- invariant systems. For the present, however, we concentrate on demonstrating that the important concept in using the unit impulse is to understand how it behaves. To do this, consider the six signals depicted in Figure P1.38. Show",
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/fb19b247596a7106a050ec5d7dbd9852bcd4cb62e607d41d51c1d5c0ef1d2bf6.jpg",
        "image_caption": [
            "(a)"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/70f900aaa08d0ae275ad33e2a4459b14600fc2f7c3a9bdb44b54388ad2c508e4.jpg",
        "image_caption": [
            "(b)"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/76796059f92d5a79772554d1fda0ce5d1165355550807ce452b0d3d40393e117.jpg",
        "image_caption": [
            "(c)"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/e1303221034479be6e95817163bdcc14402c7335dfa51b8d324a51651a616410.jpg",
        "image_caption": [
            "(d)"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/adf1bcbd3c138e17536d1a5072fcaf7c9b26e384dd71309df6c6caf0b5132ab0.jpg",
        "image_caption": [
            "(e)"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "image",
        "img_path": "images/d2d9d4a616fc5bb59db9fa188f03d7f101456f5bd0dafc348e0a04524bc9f464.jpg",
        "image_caption": [
            "(f) Figure P1.38"
        ],
        "image_footnote": [],
        "page_idx": 91
    },
    {
        "type": "text",
        "text": "that each \"behaves like an impulse\" as  $\\Delta \\rightarrow 0$  in that, if we let",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\nu_{\\Delta}^{i}(t) = \\int_{-\\infty}^{t}r_{\\Delta}^{i}(\\tau)d\\tau ,\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "then",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\n\\lim_{\\Delta \\to 0}u_{\\Delta}^{i}(t) = u(t).\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "In each case, sketch and label carefully the signal  $u_{\\Delta}^{i}(t)$ . Note that",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\nr_{\\Delta}^{2}(0) = r_{\\Delta}^{4}(0) = 0 \\text{for all} \\Delta .\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "Therefore. it is not enough to define or to think of  $\\delta (t)$  as being zero for  $t \\neq 0$  and infinite for  $t = 0$ . Rather, it is properties such as eq. (P1.38- 1) that define the impulse. In Section 2.5 we will define a whole class of signals known as singularity functions, which are related to the unit impulse and which are also defined in terms of their properties rather than their values.",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "1.39. The role played by  $u(t), \\delta (t)$ , and other singularity functions in the study of linear time- invariant systems is that of an idealization of a physical phenomenon, and, as we will see, the use of these idealizations allows us to obtain an exceedingly important and very simple representation of such systems. In using singularity functions, we need, however, to be careful. In particular, we must remember that they are idealizations, and thus, whenever we perform a calculation using them, we are implicitly assuming that this calculation represents an accurate description of the behavior of the signals that they are intended to idealize. To illustrate, consider the equation",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t)\\delta (t) = x(0)\\delta (t). \\tag{P1.39-1}\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "This equation is based on the observation that",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\nx(t)\\delta_{\\Delta}(t) = x(0)\\delta_{\\Delta}(t). \\tag{P1.39-2}\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "Taking the limit of this relationship then yields the idealized one given by eq. (P1.39- 1). However, a more careful examination of our derivation of eq. (P1.39- 2) shows that that equation really makes sense only if  $x(t)$  is continuous at  $t = 0$ . If it is not, then we will not have  $x(t) \\approx x(0)$  for  $t$  small.",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "To make this point clearer, consider the unit step signal  $u(t)$  . Recall from eq. (1.70) that  $u(t) = 0$  for  $t< 0$  and  $u(t) = 1$  for  $t > 0$  but that its value at  $\\pmb {\\tau} = \\pmb{0}$  is not defined. (Note, for example, that  $u_{\\Delta}(0) = 0$  for all  $\\Delta$  , while  $\\begin{array}{r}{\\mu_{\\Delta}^{1}(0) = \\frac{1}{2}} \\end{array}$  (from Problem 1.38(b).] The fact that  $u(0)$  is not defined is not particularly bothersome, as long as the calculations we perform using  $u(t)$  do not rely on a specific choice for  $u(0)$  . For example, if  $f(t)$  is a signal that is continuous at  $\\pmb {\\mathscr{t}} = \\pmb{0}$  then the value of",
        "page_idx": 92
    },
    {
        "type": "equation",
        "text": "\n$$\n\\int_{-\\infty}^{+\\infty}f(\\sigma)u(\\sigma)d\\sigma\n$$\n",
        "text_format": "latex",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "does not depend upon a choice for  $u(0)$ . On the other hand, the fact that  $u(0)$  is undefined is significant in that it means that certain calculations involving singularity functions are undefined. Consider trying to define a value for the product  $u(t) \\delta (t)$ .",
        "page_idx": 92
    },
    {
        "type": "text",
        "text": "To see that this cannot be defined, show that",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\n\\lim_{\\Delta \\to 0}[u_{\\Delta}(t)\\delta (t)] = 0,\n$$\n",
        "text_format": "latex",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "but",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\n\\lim_{\\Delta \\to 0}[u_{\\Delta}(t)\\delta_{\\Delta}(t)] = \\frac{1}{2}\\delta (t).\n$$\n",
        "text_format": "latex",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "In general, we can define the product of two signals without any difficulty, as long as the signals do not contain singularities (discontinuities, impulses, or the other singularities introduced in Section 2.5) whose locations coincide. When the locations do coincide, the product is undefined. As an example, show that the signal",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\ng(t) = \\int_{-\\infty}^{+\\infty}u(\\tau)\\delta (t - \\tau)d\\tau\n$$\n",
        "text_format": "latex",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "is identical to  $u(t)$ ; that is, it is 0 for  $t< 0$ , it equals 1 for  $t > 0$ , and it is undefined for  $t = 0$ .",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "1.40. (a) Show that if a system is either additive or homogeneous, it has the property that if the input is identically zero, then the output is also identically zero.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(b) Determine a system (either in continuous or discrete time) that is neither additive nor homogeneous but which has a zero output if the input is identically zero.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(c) From part \n(a), can you conclude that if the input to a linear system is zero between times  $t_{1}$  and  $t_{2}$  in continuous time or between times  $n_{1}$  and  $n_{2}$  in discrete time, then its output must also be zero between these same times? Explain your answer.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "1.41. Consider a system  $S$  with input  $x[n]$  and output  $y[n]$  related by",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = x[n]g[n] + g[n - 1]\\} .\n$$\n",
        "text_format": "latex",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(a) If  $g[n] = 1$  for all  $n$ , show that  $S$  is time invariant.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(b) If  $g[n] = n$ , show that  $S$  is not time invariant.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(c) If  $g[n] = 1 + (-1)^{n}$ , show that  $S$  is time invariant.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "1.42. (a) Is the following statement true or false?",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "The series interconnection of two linear time- invariant systems is itself a linear, time- invariant system.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "Justify your answer.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(b) Is the following statement true or false?",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "The series nthereconnection of two nonlinear systems is itself nonlinear.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "Justify your answer.",
        "page_idx": 93
    },
    {
        "type": "text",
        "text": "(c) Consider three systems with the following input-output relationships:",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\left\\{ \\begin{array}{l l}{x[n / 2],} & {\\quad n\\mathrm{~even}}\\\\ {0,} & {\\quad n\\mathrm{~odd}} \\end{array} \\right.,\n$$\n",
        "text_format": "latex",
        "page_idx": 93
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l l}{{y[n]=x[n]+\\frac{1}{2}x[n-1]+\\frac{1}{4}x[n-2],}}\\\\ {{y[n]=x[2n].}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "Suppose that these systems are connected in series as depicted in Figure P1.42. Find the input- output relationship for the overall interconnected system. Is this system linear? Is it time invariant?",
        "page_idx": 94
    },
    {
        "type": "image",
        "img_path": "images/35b03e663028b0665011da70abeb8676ef2a34053ab1399cf3aa7215f9f16217.jpg",
        "image_caption": [
            "Figure P1.42"
        ],
        "image_footnote": [],
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "1.43. (a) Consider a time- invariant system with input  $x(t)$  and output  $y(t)$ . Show that if  $x(t)$  is periodic with period  $T$ , then so is  $y(t)$ . Show that the analogous result also holds in discrete time.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(b) Give an example of a time-invariant system and a nonperiodic input signal  $x(t)$  such that the corresponding output  $y(t)$  is periodic.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "1.44. (a) Show that causality for a continuous- time linear system is equivalent to the following statement:",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "For any time  $t_0$  and any input  $x(t)$  such that  $x(t) = 0$  for  $t < t_0$ , the corresponding output  $y(t)$  must also be zero for  $t < t_0$ .",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "The analogous statement can be made for a discrete- time linear system.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(b) Find a nonlinear system that satisfies the foregoing condition but is not causal.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(c) Find a nonlinear system that is causal but does not satisfy the condition",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(d) Show that invertibility for a discrete-time linear system is equivalent to the following statement:",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "The only input that produces  $y[n] = 0$  for all  $a$  is  $x[n] = 0$  for all  $a$ .",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "The analogous statement is also true for a continuous- time linear system.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(e) Find a nonlinear system that satisfies the condition of part \n(d) but is not invertible.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "1.45. In Problem 1.37, we introduced the concept of correlation functions. It is often important in practice to compute the correlation function  $\\phi_{h_{\\tau}}(t)$ , where  $h(t)$  is a fixed given signal, but where  $x(t)$  may be any of a wide variety of signals. In this case, what is done is to design a system  $S$  with input  $x(t)$  and output  $\\phi_{h_{\\tau}}(t)$ .",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(a) Is  $S$  linear? Is  $S$  time invariant? Is  $S$  causal? Explain your answers.",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(b) Do any of your answers to part \n(a) change if we take as the output  $\\phi_{\\tau_{\\tau}}(t)$  rather than  $\\phi_{\\tau_{\\tau}}(t)$ ?",
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "1.46. Consider the feedback system of Figure P1.46. Assume that  $y[n] = 0$  for  $n < 0$ .",
        "page_idx": 94
    },
    {
        "type": "image",
        "img_path": "images/a3496b49740b5bd44728aab962ac3d302ebca3131045885789e2bf63691faf18.jpg",
        "image_caption": [
            "Figure P1.46"
        ],
        "image_footnote": [],
        "page_idx": 94
    },
    {
        "type": "text",
        "text": "(a) Sketch the output when  $x[n] = \\delta [n]$ .",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "(b) Sketch the output when  $x[n] = u[n]$ .",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "1.47. (a) Let S denote an incrementally linear system, and let x[n] be an arbitrary input signal to S with corresponding output y[n]. Consider the system illustrated in Figure P1.47(a). Show that this system is linear and that, in fact, the overall input- output relationship between x[n] and y[n] does not depend on the particular choice of x[n].",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "(b) Use the result of part \n(a) to show that  $S$  can be represented in the form shown in Figure 1.48.",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "(c) Which of the following systems are incrementally linear? Justify your answers, and if a system is incrementally linear, identify the linear system  $L$  and the zero-input response  $y_{0}[n]$  or  $y_{0}(t)$  for the representation of the system as shown in Figure 1.48.",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "(i)  $y[n] = n + x[n] + 2x[n + 4]$",
        "page_idx": 95
    },
    {
        "type": "text",
        "text": "n even (ii) y[n] = (n- 1)/2+ x[k], n odd",
        "page_idx": 95
    },
    {
        "type": "image",
        "img_path": "images/c427b8d11030c3c564b1cc35345d516d86f70f4c04b78ebb44de3c076d21b5e6.jpg",
        "image_caption": [],
        "image_footnote": [],
        "page_idx": 95
    },
    {
        "type": "image",
        "img_path": "images/fb4344e7e459e0c23f490858feef18a6281c9423e523395f626eea7300700c30.jpg",
        "image_caption": [
            "(b)"
        ],
        "image_footnote": [],
        "page_idx": 95
    },
    {
        "type": "image",
        "img_path": "images/951469e123d9341b50193c9f4342b8654e2a35d21e8369e48688cd6599e99c29.jpg",
        "image_caption": [
            "Figure P1.47"
        ],
        "image_footnote": [],
        "page_idx": 95
    },
    {
        "type": "equation",
        "text": "\n$$\ny[n] = \\left\\{ \\begin{array}{ll}x[n] - x[n - 1] + 3, & \\text{if} x[0] \\geq 0 \\\\ x[n] - x[n - 1] - 3, & \\text{if} x[0] < 0 \\end{array} \\right.\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "(iv) The system depicted in Figure P1.47(b).",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "(v) The system depicted in Figure P1.47(c).",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "(d) Suppose that a particular incrementally linear system has a representation as in Figure 1.48, with  $L$  denoting the linear system and  $y_{0}[n]$  the zero-input response. Show that  $S$  is time invariant if and only if  $L$  is a time-invariant system and  $y_{0}[n]$  is constant.",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "MATHEMATICAL REVIEW",
        "text_level": 1,
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "The complex number  $z$  can be expressed in several ways. The Cartesian or rectangular form for  $z$  is",
        "page_idx": 96
    },
    {
        "type": "equation",
        "text": "\n$$\nz = x + j y,\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "where  $j = \\sqrt{- 1}$  and  $x$  and  $y$  are real numbers referred to respectively as the real part and the imaginary part of  $z$ . As we indicated earlier, we will often use the notation",
        "page_idx": 96
    },
    {
        "type": "equation",
        "text": "\n$$\nx = \\Re e\\{z\\} , y = \\Im m\\{z\\} .\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "The complex number  $z$  can also be represented in polar form as",
        "page_idx": 96
    },
    {
        "type": "equation",
        "text": "\n$$\nz = r e^{j\\theta},\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "where  $r > 0$  is the magnitude of  $z$  and  $\\theta$  is the angle or phase of  $z$ . These quantities will often be written as",
        "page_idx": 96
    },
    {
        "type": "equation",
        "text": "\n$$\nr = |z| \\cdot \\theta = x z.\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "The relationship between these two representations of complex numbers can be determined either from Euler's relation,",
        "page_idx": 96
    },
    {
        "type": "equation",
        "text": "\n$$\ne^{j\\theta} = \\cos \\theta + j \\sin \\theta ,\n$$\n",
        "text_format": "latex",
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "or by plotting z in the complex plane, as shown in Figure P1.48, in which the coordinate axes are Re{z) along the horizontal axis and 8m{z) along the vertical axis. With respect to this graphical representation, x and y are the Cartesian coordinates of z, and r and 8 are its polar coordinates.",
        "page_idx": 96
    },
    {
        "type": "image",
        "img_path": "images/d4a2679741cca06098748cc48147ee7a3fcfe6ee24bf45c385d9ae742b576a0f.jpg",
        "image_caption": [
            "Figure P1.48"
        ],
        "image_footnote": [],
        "page_idx": 96
    },
    {
        "type": "text",
        "text": "1.48. Let  $\\mathbf{\\delta z}_{0}$  be a complex number with polar coordinates  $(r_{0},\\theta_{0})$  and Cartesian coordinates  $(x_{0},y_{0})$  Determine expressions for the Cartesian coordinates of the following complex numbers in terms of  $\\pmb{x_{0}}$  and  $\\pmb{y_{0}}$  Plot the points  $z_{0},z_{1},z_{2},z_{3},z_{4}$  and  $z_{5}$  in the complex plane when  $r_{1} = 2$  and  $\\theta_{0} = \\pi /4$  and when  $r_{0} = 2$  and  $\\theta_{0} = \\pi /2$  Indicate on your plots the real and imaginary parts of each point.",
        "page_idx": 97
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l l l}{{z_{1}~=~r_{0}e^{-j\\theta_{0}}}}&{{\\qquad(\\mathbf{b})~z_{2}~=~r_{0}}}&{{\\qquad(\\mathbf{c})~z_{3}~=~r_{0}e^{j(\\theta_{0}-2\\pi)}}}\\\\ {{z_{4}~=~r_{0}e^{j(\\theta_{0}-\\theta_{0}+\\pi)}}}&{{\\qquad(\\mathbf{e})~z_{5}~=~r_{0}e^{j(\\theta_{0}-2\\pi)}}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "1.49. Express each ot the following complex numbers in polar form, and plot them in the complex plane, indicating the magnitude and angle of each number:",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(a)  $1 + j\\sqrt{3}$  \n(b) -5 \n(c) -5 - 5j \n(d)  $3 + 4j$  \n(e)  $(1 - j\\sqrt{3})^{3}$  \n(f)  $(1 + j)^{3}$  \n(g)  $(\\sqrt{3} +j^{3})(1 - j)$  \n(h)  $\\frac{2\\cdot\\mu(6\\sqrt{3})}{2\\cdot\\mu(6\\sqrt{3})}$  \n(i)  $\\frac{1 + j\\sqrt{3}}{\\sqrt{3} + j}$  \n(j)  $j(1 + j)e^{j\\pi /6}$  \n(k)  $(\\sqrt{3} +j)2\\sqrt{2} e^{-j\\pi /4}$  \n(l)  $\\frac{e^{j\\pi / 4}}{1 + j\\sqrt{3}}$",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "1.50. (a) Using Euler's relationship or Figure P1.48, determine expressions for x and y in terms of  $\\pmb{r}$  and  $\\pmb{\\theta}$",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(b) Determine expressions for  $\\pmb{r}$  and  $\\pmb{\\theta}$  in terms of  $\\pmb{x}$  and  $\\pmb{y}$",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(c) If we are given only  $\\pmb{r}$  and tan  $\\pmb{\\theta}$  , can we uniquely determine  $\\pmb{x}$  and  $\\pmb{y}^{\\pmb{\\mathscr{P}}}$  Explain your answer.",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "1.51. Using Euler's relation, derive the following relationships:",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(a) cos  $\\begin{array}{r}{\\theta = \\frac{1}{2} (e^{j\\theta} + e^{-j\\theta})} \\end{array}$  \n(b) sin  $\\begin{array}{r}{\\theta = \\frac{1}{2} (e^{j\\theta} - e^{-j\\theta})} \\end{array}$  \n(c)  $\\cos^{2}\\theta = \\frac{1}{2} (1 + \\cos 2\\theta)$  \n(d)  $(\\sin \\theta)(\\sin \\phi) = \\frac{1}{2}\\cos (\\theta -\\phi) - \\frac{1}{2}\\cos (\\theta +\\phi)$  \n(e)  $\\sin (\\theta +\\phi) = \\sin \\theta \\cos \\phi +\\cos \\theta \\sin \\phi$",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "1.52. Let z denote a complex variable: that is,",
        "page_idx": 97
    },
    {
        "type": "equation",
        "text": "\n$$\nz = x + jy = re'θ.\n$$\n",
        "text_format": "latex",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "The complex conjugate of z is",
        "page_idx": 97
    },
    {
        "type": "equation",
        "text": "\n$$\nz^{\\prime} = x - j y = r e^{-j\\theta}.\n$$\n",
        "text_format": "latex",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "Derive each of the following relations, where z, z1, and z2 are arbitrary complex numbers.",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(a)  $z z^{\\star} = e^{2\\theta}$  \n(b)  $\\frac{z}{z} = e^{2\\theta}$  \n(c)  $z + z^{\\star} = 2\\theta \\mathbf{e}\\{z\\}$  \n(d)  $z - z^{\\star} = 2j\\theta m\\{z\\}$  \n(e)  $(z_{1} + z_{2})^{\\star} = z_{1}^{\\star} + z_{2}^{\\star}$  \n(f)  $(a z_{1}z_{2})^{\\star} = a z_{1}^{\\star}z_{2}^{\\star}$  where a is any real number \n(g)  $(\\frac{z_{1}}{z_{2}})^{\\star} = \\frac{z_{1}}{z_{2}}$ $(\\mathbf{h}) \\mathcal{R}\\mathbf{e}\\{z_{1}^{\\star}\\} = \\frac{1}{2} [\\frac{z_{1}z_{2}^{\\star} + z_{1}^{\\star}z_{2}}{z_{2}z_{2}^{\\star}} ]$",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "1.53. Derive the following relations, where z, z1, and z2 are arbitrary complex numbers:",
        "page_idx": 97
    },
    {
        "type": "text",
        "text": "(a)  $(e^{z})^{*} = e^{z^{*}}$  \n(b)  $z_{1}z_{2}^{*} + z_{1}^{*}z_{2} = 2\\mathbb{R}e\\{z_{1}z_{2}^{*}\\} = 2\\mathbb{R}e\\{z_{1}^{*}z_{2}\\}$",
        "page_idx": 97
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l}{|z| = |z^{*}|}\\\\ {|z_{1}z_{2}| = |z_{1}||z_{2}|}\\\\ {|\\Re_{\\mathbf{c}}(z)\\leq |z|,\\left.\\delta m(z)\\leq |z|}\\\\ {|z_{1}z_{2}^{*} + z_{1}^{*}|z_{2}|\\leq 2|z z_{2}|}\\\\ {|z_{1}| - |z_{2}|)^{2}\\leq |z_{1} + z_{2}|^{2}\\leq (|z_{1}^{*} + |z_{2}|)^{2}} \\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "1.54. The relations considered in this problem are used on many occasions throughout the book.",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "(a) Prove the validity of the following expression:",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = 0}^{N - 1}\\alpha^{n} = \\left\\{ \\begin{array}{l l}{N_{1}} & {\\qquad \\alpha = 1}\\\\ {\\frac{1 - \\alpha^{n}}{1 - \\alpha},} & {\\qquad \\mathrm{for~any~complex~number~}\\alpha \\neq 1} \\end{array} \\right.\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "This is often referred to as the finite sum formula.",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "(b) Show that if  $|a|< 1$  ,then",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum \\limits_{n = 0}^{\\infty}\\alpha^{n} = \\frac{1}{1 - \\alpha}.\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "This is often referred to as the infinite sum formula.",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "(c) Show also if  $|a|< 1$  ,then",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum_{n = 0}^{\\infty}n\\alpha^{n} = \\frac{\\alpha}{(1 - \\alpha)^{2}}.\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "(d) Evaluate",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\sum \\limits_{n = k}^{\\infty}\\alpha^{n},\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "assuming that  $|a|< 1$",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "1.55. Using the results from Problem 1 54, evaluate each of the following sums and express your answer in Cartesian (rectangular) form:",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l l}{{\\sum_{n=0}^{9}e^{j\\pi n/2}}}&{{\\qquad(\\mathbf{b})\\sum_{n=-2}^{7}e^{j\\pi n/2}}}\\\\ {{\\sum_{n=0}^{9}(\\frac{1}{2})^{n}e^{j\\pi n/2}}}&{{\\qquad(\\mathbf{d})\\sum_{n=2}^{7}(\\frac{1}{2})^{n}e^{j\\pi n/2}}}\\\\ {{\\sum_{n=0}^{9}e^{(n+\\frac{\\pi}{2})n}}}&{{\\qquad(\\mathbf{f})\\sum_{n=0}^{7}(\\frac{1}{2})^{n}\\cos(\\frac{\\pi}{2}n)}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    },
    {
        "type": "text",
        "text": "1.56. Evaluate each of the following integrals, and express your answer in Cartesian (rectangular) form:",
        "page_idx": 98
    },
    {
        "type": "equation",
        "text": "\n$$\n\\begin{array}{l l}{{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\in\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~\\bf~\\lambda~}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\bf~\\lambda~}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{{\\bf~\\lambda~}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf~\\lambda~}}\\\\ {{\\mathrm{~{\\bf~\\lambda~}}}}&{\\mathrm{~\\bf~\\lambda~}}\\mathrm{~\\bf}}\\end{array}\n$$\n",
        "text_format": "latex",
        "page_idx": 98
    }
]