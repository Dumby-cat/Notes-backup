## 概率论的基本概念
### 随机事件与随机变量
#### 随机试验与随机事件
*随机试验的特点：*
- 同条件重复
- 可知所有可能结果
- 不可预知出现哪个结果

**事件**：写作 $A$
**必然事件**：写作 $\Omega$
**不可能事件**：写作 $\Phi$ 或 $\varnothing$


#### 样本空间与随机变量
**基本事件**：
	在随机试验中必发生一个且仅发生一个的最简单事件；
	对应仅含一个元素的单点集 $\{\omega\}$。
**复合事件**：
	若干基本事件组合。
**样本空间**：
	全体基本事件所对应的全部元素所组成的集合；
	任一事件为样本空间子集。


#### 事件的关系和运算
**包含关系**：  
	$A \subset B$，即事件 $A$ 发生必然导致事件 $B$ 发生，称**事件 $B$ 包含事件 $A$**；
	两事件相互包含则两事件相等。
**和事件**：
	$A \cup B$，即 $A$ 和 $B$ 中至少有一个发生；
	$\bigcup_{k = 1}^{n} A_{k}$ 为 $n$ 个事件 $A_{1}, A_{2}, \dots , A_{n}$ 的和事件。
**积事件**：
	$A \cap B$，即 $A$ 和 $B$ 同时发生，也可记为 $AB$；
	$\bigcap_{k = 1}^{n} A_{k} = A_{1} A_{2} \dots A_{k}$ 为 $n$ 个事件 $A_{1}, A_{2}, \dots , A_{n}$ 的积事件。
**互不相容事件（互斥事件）**：
	$A\cap B = \emptyset$，即事件 $A$ 与 $B$ 不能同时发生；
	同一试验的基本事件互不相容。
**对立事件（逆事件）**：
	$A\cap B = \emptyset$ 且 $A\cup B = \Omega$，即事件 $A$ 与 $B$ 必有一个发生，且仅有一个发生；
	事件 $A$ 的对立事件记为 $\overline{{A}}$。
**差事件**：
	 $A - B = \{\omega \mid \omega \in A$  且  $\omega \notin B\}=A\overline{B}$，即$A$ 发生而同时 $B$ 不发生。

*运算律*：
德摩根律（对偶律）：
	$\overline{{A\cup B}} = \overline{{A}}\cap \overline{{B}}$
	$\overline{{A\cap B}} = \overline{{A}}\cup \overline{{B}}$
吸收律：
	若 $A\subset B$，则 $A B = A$，$A\cup B = B$
交换律、结合律、分配律（差事件没有分配律）


### 概率
> 概率是对随机事件发生可能性大小的一个客观度量。

#### 频率
> 设在相同条件下,进行  $n$  次试验,事件  $A$  发生了  $m$  次,称比值
> $$f_{n}(A) = \frac{m}{n}$$
> 为事件  $A$  发生的频率。

#### 古典概率
> 仅有有限个基本事件且每个基本事件发生的可能性相等的随机试验叫**古典概型试验**。

$$
P(A) = \frac{A\text{所含基本事件个数}}{\text{基本事件总数}}
$$
所确定的概率称为事件  $A$  的**古典概率**。

*性质*：
1. 对任意事件 $A, 0 \leqslant P(A) \leqslant 1$；
2. $P(\Omega) = 1$；
3. 若 $A_{1}, A_{2}, \dots , A_{m}$ 互不相容, 则
$$
P\Big(\bigcup_{i = 1}^{m}A_{i}\Big) = \sum_{i = 1}^{m}P\big(A_{i}\big).
$$
#### 概率的公理化定义与性质
设随机试验 $E$ 的样本空间为 $\Omega$，若对于 $E$ 的每一事件 $A$ 都对应一个实数 $P(A)$，其对应规则满足以下三条：
1. （非负性）对任一事件 $A$，有 $0\leqslant P(A)\leqslant 1$
2. （规范性） $P(\Omega) = 1$
3. （可列可加性）对  $E$  的互不相容事件列  $A_{1},A_{2},\dots$  ,有
$$
P\Big(\bigcup_{i = 1}^{\infty}A_{i}\Big) = \sum_{i = 1}^{\infty}P(A_{i})
$$
则称 $P(A)$ 是事件 $A$ 的概率。

*性质*：
1.  $P(\varnothing) = 0$（逆不真）
2. （有限可加性）若试验 $E$ 的事件组 $A_{1},A_{2},\dots ,A_{n}$ 互不相容,则有
$$
P\Big(\bigcup_{i = 1}^{m}A_{i}\Big) = \sum_{i = 1}^{m}P(A_{i});
$$
3. 对任何事件 $A$ 有 $P(A) + P(\overline{{A}}) = 1$
4. （单调性）若事件 $A$ 和 $B$ 满足 $A\subset B$，则 $P(A)\leqslant P(B)$ 和 $P(B - A) = P(B) - P(A)$ 成立.

*概率加法定理*：
对试验  $E$  的任意两个事件  $A$  和  $B$ , 有
$$
P(A\cup B) = P(A) + P(B) - P(AB)
$$


### 条件概率
> 设  $A,B$  是随机试验  $E$  的两个随机事件,且  $P(B) > 0$  ,称$$P(A\mid B) = \frac{P(AB)}{P(B)}$$
> 为在事件  $B$  发生的条件下,事件  $A$  发生的条件概率。

#### 乘法公式
设  $P(B) > 0$ ,则有
$$
P(AB) = P(B)P(A\mid B);
$$

设  $A_{1},A_{2},\dots ,A_{n}$  是试验  $E$  的  $n$  个事件,若  $P(A_{1}A_{2}\dots A_{n - 1}) > 0$ ,则
$$
P(A_{1}A_{2}\dots A_{n}) = P(A_{1})P(A_{2}\mid A_{1})P(A_{3}\mid A_{1}A_{2})\dots P(A_{n}\mid A_{1}A_{2}\dots A_{n - 1})
$$

#### 全概率公式
> 设随机试验  $E$  的样本空间为  $\Omega , A \subset \Omega , B_{1}, B_{2}, \dots , B_{n}$  为  $\Omega$  的一个有限划分, 且  $P(B_{i}) > 0, i = 1, 2, \dots , n$ , 则有
> $$P(A) = \sum_{i = 1}^{n} P(B_{i}) P(A \mid B_{i})$$

$B_{i} \cap B_{j} = \emptyset , i \neq j$ 且 $B_{1} \cup B_{2} \cup \dots \cup B_{n} = \Omega$ 则称  $B_{1}, B_{2}, \dots , B_{n}$  为  $\Omega$  的一个**有限划分**。

#### 贝叶斯公式
> 设随机试验  $E$  的样本空间为  $\Omega ,A\subset \Omega ,B_{i}(i = 1,2,\dots ,n)$  是  $\Omega$  的一个有限划分,而且  $P(A) > 0,P(B_{i}) > 0$  ,则有
> $$P(B_{i}\mid A) = \frac{P(B_{i})P(A\mid B_{i})}{\sum_{j = 1}^{n}P(B_{j})P(A\mid B_{j})}$$

### 事件的独立性
满足：
$$
P(A B) = P(A\mid B)P(B) = P(A)P(B).
$$
则称事件  $A$  与  $B$  相互独立。
$A$ 和 $B$ 相互独立则 $A$ 与 $\overline{B}$， $\overline{A}$ 与 $B$， $\overline{A}$ 与 $\overline{B}$ 也分别相互独立。

若下面四个等式同时成立
$$
\left\{ \begin{array}{l}P(AB) = P(A)P(B), \\ P(AC) = P(A)P(C), \\ P(BC) = P(B)P(C), \\ P(ABC) = P(A)P(B)P(C), \end{array} \right.
$$
则称  $A, B, C$  所组成的事件组相互独立。若仅有前三个等式同时成立,则称此事件组是两两独立的。

若对任意的  $s(1< s\leqslant n)$  及  $1\leqslant$ $i_{1}< i_{2}< \dots < i_{s}\leqslant n$  ,有
$$
P(A_{i_{1}}A_{i_{2}}\dots A_{i_{s}}) = P(A_{i_{1}})P(A_{i_{2}})\dots P(A_{i_{s}})
$$
则称事件组  $A_{1},A_{2},\dots ,A_{n}$  相互独立。

若  $n$  个事件  $A_{1},A_{2},\dots ,A_{n}$  相互独立，则将  $A_{1},A_{2},\dots ,A_{n}$  中的任意多个事件换成它们的对立事件，所得的  $n$  个事件仍然相互独立。


## 随机变量的分布
### 随机变量分布函数
设  $\Omega$  是随机试验  $E$  的样本空间,若对于每一个样本点  $\omega \in \Omega$  ,都有唯一的实数  $X(\omega)$  与之对应,且对于任意实数  $x$  ,都有确定的概率  $P\{X(\omega)\leqslant x\}$  与之对应,则称  $X(\omega)$  为随机变量r.v.，简记为  $X.$
$$r.v. \quad X(\omega):\Omega \to R$$

设  $\Omega$  是随机试验  $E$  的样本空间,  $x$  是任意实数,称函数
$$
F(x) = P\{X\leqslant x\} = P\{\omega \mid X(\omega)\leqslant x\}
$$
为随机变量  $X$  的分布函数,  $F(x)$  也可记为  $F_{X}(x)$ .
分布函数是**概率**。

分布函数性质：
1. 单调不降；
2. 有界，即 $\lim_{x\to +\infty}F(x)=1,\quad \lim_{x\to -\infty}F(x)=0$；
3. 右连续：$\lim_{x\to x_{0}^{+}}F(x) = F(x_{0})$ 。

### 离散型随机变量
> 如果随机变量  $X$  只取有限个或可列无穷多个数值:  $x_{1}, x_{2}, \dots , x_{n}, \dots$ , 记  $P\{X = x_{i}\} = p_{i}$ , 它满足 $p_{i} \geqslant 0$ 和 $\sum_{i = 1}^{\infty} p_{i} = 1$，则称  $X$  为离散型随机变量, 并称
> $$
P\{X = x_{i}\} = p_{i}, i = 1, 2, \dots
$$为  $X$  的分布律

#### 伯努利试验和二项分布
> 将一个试验在相同条件下重复进行  $n$  次,如果在每次试验中,任一事件出现的概率与其他各次试验结果无关,则称这  $n$  次试验是  $n$  次重复独立的试验。 $n$  次重复独立的伯努利试验称为  $n$  重伯努利试验,或称伯努利概型

在  $n$  重伯努利试验中,事件  $A$  在每次试验中发生的概率为  $p,0< p< 1$  则  $A$  恰好发生  $k$  次的概率为
$$
P_{n}(k) = \mathrm{C}_{n}^{k}p^{k}(1 - p)^{n - k}
$$

若随机变量  $X$  的分布律为
$$
P\{X = k\} = P_{n}(k) = \mathrm{C}_{n}^{k}p^{k}(1 - p)^{n - k}, \quad k = 0,1,2,\dots ,n,
$$
则称  $X$  服从**二项分布**,记为  $X\sim B(n,p)$，期望为 $E(x)=np$。
特别若  $X\sim B(1,p)$，则  $X$  服从 **(0-1)分布**。

#### 泊松分布
> 设随机变量  $X$  的分布律为
> $$
P\left\{X = k\right\} = \frac{\lambda^{k}}{k!} \mathrm{e}^{-\lambda}, \quad k = 0,1,2,\dots , \quad \lambda > 0,
$$
> 则称随机变量  $X$  服从参数为  $\lambda$  的泊松(Poisson)分布,记为  $X \sim P(\lambda)$

*泊松定理*：
	设随机变量序列  $X_{n},n = 1,2,\dots ,$  有  $X_{n}\sim B\left(n,p_{n}\right)$  ,即$$
P\{X_{n} = k\} = \mathrm{C}_{n}^{k}p_{n}^{k}(1 - p_{n})^{n - k},\quad k = 0,1,2,\dots ,n
$$若满足$$
\lim_{n\to \infty}n p_{n} = \lambda >0,
$$则有$$
\lim_{n\to \infty}P\left\{X_{n} = k\right\} = \frac{\lambda^{k}}{k!}\mathrm{e}^{-\lambda}
$$
当事件  $A$  在每次试验中  $P(A) = p$  很小（即稀有事件），试验的次数  $n$  又很大时（即稀有事件发生的次数），可用泊松定理近似计算二项分布的概率其中 $\lambda = n p$（近似）。


### 连续型随机变量
> 设  $F(x)$  是随机变量  $X$  的分布函数,若存在非负函数  $f(x)$ ,对任意实数  $x$ ,有
> $$F(x) = \int_{-\infty}^{x}f(u)\mathrm{d}u$$
> 则称  $X$  是连续型随机变量,称  $f(x)$  为  $X$  的概率密度.

*概率密度函数性质*：
1. $f(t)\geq 0$
2. $\int_{-\infty}^{+\infty}f(t)\mathrm{d}t=1$

*分布函数性质*：
1. 连续型随机变量 $X$ 的分布函数是连续函数；
2. 设  $X$  为连续型随机变量,则对任一指定实数  $x_{0}$，有 $P\{X = x_{0}\} = 0,\quad x_{0}\in \mathbf{R}$；
3. $P\left\{x_{1}< X \leqslant x_{2}\right\} = P\left\{x_{1}\leqslant X < x_{2}\right\}$；
4. $P\left\{x_{1}< X \leqslant x_{2}\right\} = \int_{x_{1}}^{x_{2}}f(x)\mathrm{d}x$。

#### 均匀分布
连续型随机变量  $X$  具有概率密度
$$
f(x) = \left\{ \begin{array}{ll} \frac{1}{b - a}, & a< x< b, \\ 0, & \text{其他}, \end{array} \right.
$$
则称  $X$  在区间  $(a,b)$  上服从均匀分布,记为  $X\sim U(a,b)$。
随机变量 $X$ 落在 $(a,b)$ 的子区间上概率与位置无关，仅与长度有关。

#### 指数分布
连续型随机变量  $X$  具有概率密度
$$
f(x) = \left\{ \begin{array}{ll} \lambda \mathrm{e}^{-\lambda x}, & x > 0, \\ 0, & x \leqslant 0 \end{array} \right. \quad (\lambda > 0)
$$
则称随机变量  $X$  服从参数为  $\lambda$  的指数分布。

$$
\lim_{h\to 0}\frac{1}{h}P\{t<T\le t+h\mid T>t\}=\lambda
$$
$t$ 时刻还正常工作的条件下，瞬时失效率 $\lambda$ （即概率密度公式 $\lambda e^{-\lambda x}$ 中的 $\lambda$）为常数。

*无后效性（无记忆性）*：
设随机变量  $X$  服从参数为  $\lambda$  的指数分布, 对任意  $s > 0$  和  $t > 0$ , 有
$$
P\{X > t + s \mid X > t\} = P\{X > s\} .
$$

#### 正态分布（高斯分布）
若连续型随机变量  $X$  的概率密度为
$$
\phi (x;\mu ,\sigma^{2}) = \frac{1}{\sigma\sqrt{2\pi}}e^ {-\frac{(x - \mu)^2 }{ 2\sigma^{2}}} ,x\in \mathbf{R}
$$
$$
\phi(x)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^{2}}{2}}
$$
其中  $\mu ,\sigma$  均为实数,且  $\sigma >0$，则称  $X$  服从参数为  $\mu ,\sigma^{2}$  的正态分布，记为 $X\sim N(\mu ,\sigma^{2})$。

*标准正态分布*：$X\sim N(0,1)$。

令  $y = \frac{t - \mu}{\sigma}$  有  $\mathrm{d}t = \sigma \mathrm{d}y$，则
$$
\Phi \left(x;\mu ,\sigma^{2}\right) = \frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\frac{x - \mu}{\sigma}}\mathrm{e}^{-\frac{y^{2}}{2}}\mathrm{d}y = \Phi \left(\frac{x - \mu}{\sigma}\right)
$$
$$
\Phi(x)=\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{x}e^{-\frac{x^{2}}{2}}\mathrm{d}x
$$
标准化：$\frac{x - \mu}{\sigma}$

*性质*：
1. $\phi (x;\mu ,\sigma^{2})$  关于直线  $x = \mu$  是对称的；
2. 曲线在  $x = \mu$  达到最大值  $\frac{1}{\sigma\sqrt{2\pi}}$，固定 $\mu$，$\sigma^2$ 越大，曲线越平坦。

常用计算公式：
1. $\Phi (-x) = 1 - \Phi (x)$
2. 若随机变量  $X\sim N(0,1)$，则$P\left\{a< X\leqslant b\right\} = \Phi \left(b\right) - \Phi \left(a\right)$
3. 若随机变量  $X\sim N(\mu ,\sigma^{2})$，则$P\left\{x_{1}< X\leqslant x_{2}\right\} = \Phi \left(\frac{x_{2} - \mu}{\sigma}\right) - \Phi \left(\frac{x_{1} - \mu}{\sigma}\right)$


## 多维随机变量
### 二维随机变量及其分布
#### 联合分布函数
设随机试验  $E$  的样本空间为  $\Omega$，$X_{1}(\omega), X_{2}(\omega), \dots , X_{n}(\omega)$  是定义在  $\Omega$ 上的  $n$  个随机变量,则将它们构成的有序组  $(X_{1}, X_{2}, \dots , X_{n})$  称为  $n$ 维随机变量,或称  $n$  维随机向量。

二维随机变量  $(X, Y)$  中的  $X, Y$  是定义在同一样本空间  $\Omega$  上的随机变量,将它们的分布函数分别记为
$$
F_{x}(x) = P\{X \leqslant x\} , \quad F_{y}(y) = P\{Y \leqslant y\}
$$
设  $(X, Y)$  是二维随机变量, $(x, y)$  是任意实数对,记
$$
\{X \leqslant x, Y \leqslant y\} = \{X \leqslant x\} \cap \{Y \leqslant y\} ,
$$
称二元函数
$$
F(x, y) = P\{X \leqslant x, Y \leqslant y\}
$$
为  $(X, Y)$  的联合分布函数;  $X$  与  $Y$  的分布函数  $F_{x}(x)$  和  $F_{y}(y)$  分别称为  $(X, Y)$  关于  $X, Y$  的边缘分布函数。
$$
F_{x}(x) = \lim_{y \to +\infty} F(x, y), \quad F_{y}(y) = \lim_{x \to +\infty} F(x, y)
$$

随机点落入矩形内，得：
$$
P\{x_{1}< X\leqslant x_{2},y_{1}< Y\leqslant y_{2}\} = F(x_{2},y_{2}) - F(x_{2},y_{1}) - F(x_{1},y_{2}) + F(x_{1},y_{1})
$$

*联合分布函数性质*：
1. 单调不降：$F(x,y)$  分别对  $x,y$  单调不降；
2. 右连续：$\lim_{x\to x_{0}^{+}}F(x,y) = F(x_{0},y)$  ,对一切  $y\in \mathbf{R}$  成立，对 $y$ 同理；
3. 非负有界： $0\leqslant F(x,y)\leqslant 1$，$\lim_{x\to -\infty}F(x,y) = 0,\quad \lim_{x\to +\infty}F(x,y) = 1$，对 $y$ 同理；
4. 相容性：对于任意实数  $x_{1}\leqslant x_{2},y_{1}\leqslant y_{2}$  ,有$$F(x_{2},y_{2}) - F(x_{2},y_{1}) - F(x_{1},y_{2}) + F(x_{1},y_{1})\geqslant 0$$

$n$  维随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的联合分布函数定义为
$$
F(x_{1}, x_{2}, \dots , x_{n}) = P\{X_{1} \leqslant x_{1}, X_{2} \leqslant x_{2}, \dots , X_{n} \leqslant x_{n}\}
$$
由  $(X_{1}, X_{2}, \dots , X_{n})$  的联合分布函数可确定其中任意  $k$  个  $(1 \leqslant k \leqslant n)$  分量的联合分布函数，称为  $k$  维边缘分布函数，例如
$$
F_{x_{1}}(x_{1}) = F(x_{1}, +\infty , \dots , +\infty), F_{x_{1}, x_{2}}(x_{1}, x_{2}) = F(x_{1}, x_{2}, +\infty , \dots , +\infty)
$$
是  $(X_{1}, X_{2}, \dots , X_{n})$  分别关于  $X_{1}$，$(X_{1}, X_{2})$  的边缘分布函数。


#### 联合分布律
二维随机变量  $(X, Y)$  所有可能取值为有限对或可列无穷对:  $(x_{i}, y_{j})$ ,  $i, j = 1, 2, \dots$ , 记
$$
P\{X = x_{i}, Y = y_{j}\} = p_{ij} \quad (i, j = 1, 2, \dots) \tag{3.1.5}
$$
满足条件 $p_{ij} \geqslant 0 (i, j = 1, 2, \dots)$ 和 $\sum_{i = 1}^{\infty} \sum_{j = 1}^{\infty} p_{ij} = 1$，则称  $(X, Y)$  为二维离散型随机变量。称上式为  $(X, Y)$  的联合分布律。

联合分布函数：$F(x, y) = \sum_{x_{i} \leqslant x} \sum_{y_{j} \leqslant y} p_{ij}$
边缘分布律：$P\{X=x_i\}=p_{i\cdot}=\sum^{+\infty}_{j=1}p_{ij}$，$P\{Y = y_{j}\} = p_{\cdot j} = \sum_{i = 1}^{\infty}p_{i j}$

#### 联合概率密度
> 二维随机变量  $(X,Y)$  的联合分布函数为  $F(x,y)$ ,如果存在函数  $f(x,y)\geqslant 0$ ,使得对于任意实数对  $(x,y)$  有
> $$F(x,y) = \int_{-\infty}^{x}\int_{-\infty}^{y}f(u,v)\mathrm{d}u\mathrm{d}v$$
> 则称  $(X,Y)$  是**连续型的二维随机变量**，函数  $f(x,y)$  称为  $(X,Y)$  的**联合概率密度**。

*性质*：
1. 非负性；
2. 归一性；
3. 若  $G \subset \mathbf{R}^{2}$ ,则有$P\left\{\left(X,Y\right)\in G\right\} = \iint_{G}f(x,y)\mathrm{d}\sigma$；
4. **边缘概率密度**：$f_{X}(x) = \int_{-\infty}^{+\infty} f(x,y) \mathrm{d}y, \quad x \in \mathbf{R}$。

#### 二维均匀分布（几何概率）
> 设  $G \subset \mathbf{R}^{2}$ ,其面积记为  $S(G)$ ,若二维随机变量  $(X,Y)$  的联合概率密度为
> $$f(x,y) = \left\{ \begin{array}{ll} \frac{1}{S(G)}, & (x,y) \in G, \\ 0, & (x,y) \notin G, \end{array} \right.$$
> 则称  $(X,Y)$  在  $G$  上服从均匀分布

$$
P\left\{(X,Y) \in D\right\} = \iint_{D} \frac{1}{S(G)} \mathrm{d}\sigma = \frac{1}{S(G)} \iint_{D} \mathrm{d}\sigma = \frac{S(D)}{S(G)}
$$

#### 二维正态分布
> 二维随机变量  $(X, Y)$  的联合概率密度为
> $$\frac{1}{2 \pi \sigma_{1} \sigma_{2} \sqrt{1 - \rho^{2}}} \exp \left\{-\frac{1}{2(1 - \rho^{2})} \left[ \frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}} - 2 \rho \frac{(x - \mu_{1})(y - \mu_{2})}{\sigma_{1} \sigma_{2}} + \frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}} \right] \right\} , x \in \mathbf{R}, y \in \mathbf{R}$$
> 式中  $\mu_{1}, \mu_{2}, \sigma_{1}, \sigma_{2}, \rho$  均为常数，且  $\sigma_{1} > 0, \sigma_{2} > 0, - 1 < \rho < 1$ ，则称  $(X, Y)$  服从二维正态分布，记为  $(X, Y) \sim N(\mu_{1}, \sigma_{1}^{2}; \mu_{2}, \sigma_{2}^{2}; \rho)$

若二维随机变量  $(X,Y)\sim N(\mu_{1},\sigma_{1}^{2};\mu_{2},\sigma_{2}^{2};\rho)$  ,则  $X\sim N(\mu_{1},\sigma_{1}^{2}),Y\sim$ $N(\mu_{2},\sigma_{2}^{2})$



### 随机变量的独立性
> 设  $(X,Y)$  是二维随机变量,若**对于任意实数  $x$  和  $y$**,有
> $$P\{X\leqslant x,Y\leqslant y\} = P\{X\leqslant x\} P\{Y\leqslant y\}$$
> 成立,则称随机变量  $X$  和  $Y$  相互独立

上式等价于：
$$
F(x,y) = F_{x}(x)F_{y}(y)
$$
对于离散随机变量：
$$
P\{X＝x_i,Y=y_j\} = P\{X=x_i\} P\{Y=y_j\}
$$
对于连续随机变量：
$$
f(x,y) = f_{x}(x)f_{y}(y)
$$

若随机变量  $X$  和  $Y$  相互独立,则有
$$
P\{x_{1}< X\leqslant x_{2},y_{1}< Y\leqslant y_{2}\} = P\{x_{1}< X\leqslant x_{2}\} P\{y_{1}< Y\leqslant y_{2}\}
$$
成立。

设  $n$  维随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  的联合分布函数为  $F(x_{1}, x_{2}, \dots , x_{n})$ , 若对所有实数组  $(x_{1}, x_{2}, \dots , x_{n})$  均有
$$
F(x_{1}, x_{2}, \dots , x_{n}) = F_{1}(x_{1}) F_{2}(x_{2}) \dots F_{n}(x_{n})
$$
成立, 式中  $F_{k}(x_{k})$  是关于  $X_{k}$  的边缘分布函数, 则称  $X_{1}, X_{2}, \dots , X_{n}$  相互独立。

若  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  相互独立,则
1. 其中任意  $m(2\leqslant m\leqslant n)$  个随机变量  $X_{k_{1}},X_{k_{2}},\dots ,X_{k_{m}}$  也相互独立；
2. 若随机变量的函数  $g_{1}\left(X_{1}\right),g_{2}\left(X_{2}\right),\dots ,g_{n}\left(X_{n}\right)$  是随机变量,则它们也相互独立；
3. $(X_{1},X_{2},\dots ,X_{m})$  与  $(X_{m + 1},X_{m + 2},\dots ,X_{n})$  相互独立,而且  $h,g$  是连续函数,则  $h(X_{1},X_{2},\dots ,X_{m})$  和  $g(X_{m + 1},X_{m + 2},\dots ,X_{n})$  也相互独立。


### 条件分布
#### 条件分布律
> 设  $(X,Y)$  是离散型随机变量,对固定的  $j$  若  $P\{Y = y_{j}\} >0$  ,则称
> $$P\{X = x_{i}\mid Y = y_{j}\} = \frac{p_{ij}}{p_{\cdot j}}\quad (i = 1,2,\dots)$$
> 为在  $Y = y_{j}$  的条件下,随机变量  $X$  的条件分布律


#### 条件概率密度
> 对于给定的实数  $y$  及任意的  $\Delta y > 0$ ,若  $P\left\{y< Y\leqslant y + \Delta y\right\} >0$ ,且对任意实数  $x$ ,极限
> $$\lim_{\Delta y\to 0^{+}}P\left\{X\leqslant x\mid y< Y\leqslant y + \Delta y\right\} = \lim_{\Delta y\to 0^{+}}\frac{P\left\{X\leqslant x,y< Y\leqslant y + \Delta y\right\}}{P\left\{y< Y\leqslant y + \Delta y\right\}}$$
> 存在,则称此极限为在"  $Y = y$  "的条件下,随机变量  $X$  的条件分布函数,记为  $F_{X}\mid_{Y}(x\mid y)$

对二维离散型随机变量  $(X,Y)$ , 若  $P\{Y = y_{j}\} >0$ , 则在"  $Y = y_{j}$ "的条件下, 随机变量  $X$  的条件分布函数为
$$
F_{X}\mid_{Y}(x\mid y) = \sum_{x_{i}\leqslant x}P\{X = x_{i}\mid Y = y_{j}\} = \sum_{x_{i}\leqslant x}\frac{p_{i j}}{p_{\cdot j}}
$$
设  $(X,Y)$  是连续型随机变量, 其联合概率密度为  $f(x,y)$：
$$
F_{X}\mid_{Y}(x\mid y) = \lim_{\Delta y\to 0^{+}}\frac{\int_{-\infty}^{x}\int_{y}^{y + \Delta y}f(u,v)\mathrm{d}u\mathrm{d}v}{\int_{y}^{y + \Delta y}f_{y}(v)\mathrm{d}v}.
$$
> 若记  $f_{X}\mid_{Y}(x\mid y)$  为在"  $Y = y$  "的条件下, 随机变量  $X$  的条件概率密度, 则
> $$f_{X}\mid_{Y}(x\mid y) = F_{X}^{\prime}\mid_{Y}(x\mid y) = \frac{f(x,y)}{f_{Y}(y)}$$



### 随机变量的函数及其分布
#### 离散型随机变量的函数及其分布律
 离散型随机变量  $X$  的分布律为
$$
P\left\{X = x_{i}\right\} = p_{i}\quad (i = 1,2,\dots),
$$
若它的函数  $Y = g(X)$  仍是离散型随机变量,则其分布律为
$$
P\left\{Y = y_{j}\right\} = P\left\{g(X) = y_{j}\right\} = \sum_{x_{i}\in S_{j}}P\left\{X = x_{i}\right\} \quad (j = 1,2,\dots), \tag{3.4.1}
$$
其中  $S_{j} = \{x_{i}\mid g(x_{i}) = y_{j}\}$

$X + Y$  服从参数为  $\lambda_{1} + \lambda_{2}$  的泊松分布，即两个相互独立的泊松分布随机变量之和仍服从泊松分布，而且其参数为相应的参数之和。称泊松分布具有可加性(再生性)。

二项分布（要求 p 相等）、泊松分布和正态分布均有可加性。


#### 连续型随机变量的函数及其分布律
考虑两种情形:
1. $X$  是连续型随机变量,函数  $Y = g\left(X\right)$  也是连续型随机变量,求其概率密度;
2. $(X, Y)$  是连续型随机变量,函数  $Z = G\left(X, Y\right)$  是一维连续型随机变量,求其概率密度。

设  $X$  的概率密度为  $f_{X}\left(x\right)$ ,则  $Y = g\left(X\right)$  的分布函数为
$$
F_{Y}(y) = P\left\{g(X) \leqslant y\right\} = \int_{\left|x\right| \in \left(x\right) \leqslant y} f_{X}(x) \mathrm{d}x
$$
$Y$  的概率密度为
$$
f_{Y}(y) = \left\{ \begin{array}{ll}F_{Y}^{\prime}(y), & \text { 在 } f_{Y}(y) \text { 的连续点,} \\ 0, & \text { 其他.} \end{array} \right.
$$

设  $(X, Y)$  的联合概率密度是  $f(x, y)$ ,则  $Z = G\left(X, Y\right)$  的分布函数为
$$
F_{Z}(z) = P\left\{G\left(X, Y\right) \leqslant z\right\} = \iint_{\left|\left(x, y\right) \mid G\left(x, y\right) \leqslant z\right|} f(x, y) \mathrm{d}x \mathrm{d}y, \tag{3.4.5}
$$
$Z$  的概率密度为
$$
f_{Z}(z) = \left\{ \begin{array}{ll}F_{Z}^{\prime}(z), & \text { 在 } f_{Z}(z) \text { 的连续点,} \\ 0, & \text { 其他.} \end{array} \right.
$$

#### 特殊函数分布
当 $X\sim N(\mu,\sigma^2)$，则 $X$ 的线性函数 $Y=aX+b(a\ne 0)$ 服从正态分布 $N(a\mu+b,a^2\sigma^2)$。
当 $X\sim N(\mu_1,\sigma_1^2),\quad X\sim N(\mu_2,\sigma_2^2)$，$X$ 和 $Y$ 相互独立，则 $aX+bY$ 服从正态分布 $N(a\mu_1+b\mu_2,a^2\sigma_1^2+b^2\sigma_2^2)$。
当 $Y=g(x)$ 单调：$f_Y(y)=f_x(g^{-1}(y))\cdot |[g^{-1}(y)]'|$。

##### 极值分布
$X$ 和 $Y$ 相互独立，则
$$
\begin{align*}F_{z_{1}}(z)& = P\{\max \{X,Y\} \leqslant z\} \\&= P\{X\leqslant z,Y\leqslant z\}= P\{X\leqslant z\} P\{Y\leqslant z\} \\&= F_{x}(z)F_{y}(z),\quad z\in \mathbf{R}\end{align*}
$$
$$
\begin{align}F_{z_{2}}(z) &= P\{\min \{X,Y\} \leqslant z\} = 1 - P\{\min \{X,Y\} >z\} \\&= 1 - P\{X > z,Y > z\}= 1 - P\{X > z\} P\{Y > z\} \\&= 1 - [1 - P\{X\leqslant z\} ][1 - P\{Y\leqslant z\} ]\\&= 1 - [1 - F_{x}(z)][1 - F_{y}(z)],\quad z\in \mathbf{R}\end{align}
$$

##### 和的分布
设  $(X, Y)$  的联合概率密度是  $f(x, y)$ ,则和  $Z = X + Y$  的分布函数是
$$
\begin{align}F_{z}(z) &= P\{X + Y \leqslant z\} = \iint_{x + y \leqslant z} f(x, y) \mathrm{d}x \mathrm{d}y\\&= \int_{-\infty}^{+\infty} \left[ \int_{-\infty}^{z - y} f(x, y) \mathrm{d}x \right] \mathrm{d}y\\&=\int_{-\infty}^{+\infty}\left[\int_{-\infty}^{z}f(u-y,y)\mathrm{d}u\right]\mathrm{d}y\\&=\int_{-\infty}^{z}\left[\int_{-\infty}^{+\infty}f(u-y,y)\mathrm{d}y\right]\mathrm{d}u \end{align}
$$
$$
f_{z}(z) = F_{z}^{\prime}(z) = \int_{-\infty}^{+\infty} f(z - y, y) \mathrm{d}y = \int_{-\infty}^{+\infty} f(x, z - x) \mathrm{d}x
$$

##### 商的分布
设  $(X,Y)$  的联合概率密度为  $f(x,y)$ ,则它们的商  $Z = \frac{X}{Y}$  的分布函数是
$$
F_{z}(z) = P\{Z\leqslant z\} = \iint_{x / y\leqslant z}f(x,y)\mathrm{d}x\mathrm{d}y = \iint_{G_{1}}f(x,y)\mathrm{d}x\mathrm{d}y + \iint_{G_{2}}f(x,y)\mathrm{d}x\mathrm{d}y
$$
$$
f_{z}(z) = \int_{-\infty}^{+\infty}\left|y\right|f(z y,y)\mathrm{d}y
$$

## 随机变量的数字特征
### 数学期望
#### 随机变量的数学期望
> 设离散型随机变量  $X$  的分布律为 $P\{X = x_{i}\} = p_{i}\quad (i = 1,2,\dots)$，若  $\sum_{i = 1}^{\infty}\mid x_{i}\mid p_{i}< +\infty$  ,则称
> $$E(X) = \sum_{i = 1}^{\infty}x_{i}p_{i}$$
> 为随机变量  $X$  的数学期望或均值。
> 
> 设连续型随机变量 $X$ 的概率密度为 $f(x)$，若  $\int_{- \infty}^{+\infty}\left|x\right|f(x)\mathrm{d}x< +\infty$ ，则称
> $$E(X) = \int_{-\infty}^{+\infty}x f(x)\mathrm{d}x$$
> 为随机变量  $X$  的数学期望或均值。

*几种常见分布的数学期望*：
- $X\sim P(\lambda)$，则 $E(X)=\lambda$；
- $X\sim B(n,p)$，则 $E(X)=np$；
- $X\sim N(\mu,\sigma^2)$，则 $E(X)=\mu$；
- 两点分布：$E(X)=p$；
- $X\sim EXP(\lambda)$，$E(X)=\frac{1}{\lambda}$


#### 随机变量函数的数学期望
设  $Y$  是随机变量  $X$  的函数  $Y = g(X) (g(x)$  是连续函数)。
1. 若  $X$  是离散型随机变量, 其分布律为
$$
P\{X = x_{i}\} = p_{i} \quad (i = 1,2, \dots)
$$
	若  $\sum_{i = 1}^{\infty} g(x_{i}) p_{i}$  绝对收敛, 则有
$$
E(Y) = E[g(X)] = \sum_{i = 1}^{\infty} g(x_{i}) p_{i}
$$
2. 若  $X$  是连续型随机变量, 其概率密度是  $f_{X}(x)$ , 若
$$
\int_{-\infty}^{+\infty} \left|g(x)\right| f_{X}(x) \mathrm{d}x < +\infty
$$
	则
$$
E(Y) = E[g(X)] = \int_{-\infty}^{+\infty} g(x) f_{X}(x) \mathrm{d}x
$$

设  $(X,Y)$  是二维随机变量,  $Z = G(X,Y)$  也是随机变量.
1. 若  $(X,Y)$  是离散型随机变量,其联合分布律为
$$
P\{X = x_{i},Y = y_{j}\} = p_{ij} \quad (i = 1,2,\dots ;j = 1,2,\dots)
$$
	则当  $\sum_{i = 1}^{\infty} \sum_{j = 1}^{\infty} |G(x_{i},y_{j})| p_{ij}< +\infty$  时,
$$
E(Z) = E[G(X,Y)] = \sum_{i = 1}^{\infty} \sum_{j = 1}^{\infty} G(x_{i},y_{j}) p_{ij}
$$
2. 若  $(X,Y)$  是连续型随机变量,其联合概率密度为  $f(x,y)$ ,则当
$$
\int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} |G(x,y)| f(x,y) \mathrm{d}x \mathrm{d}y< +\infty ,
$$
	有
$$
E(Z) = E[G(X,Y)] = \int_{-\infty}^{+\infty} \int_{-\infty}^{+\infty} G(x,y)f(x,y) \mathrm{d}x \mathrm{d}y
$$

#### 数学期望的性质
$$
E([X-E(X)]^2)=E(X^2)-E^2(X)
$$
$X,Y$ 相互独立，则 $E(XY)=E(X)E(Y)$。

1. 设  $c$  是常数,则有  $E(C) = C$
2. 设  $X$  是随机变量,  $c$  是常数,则有  $E(C X) = C E(X)$
3. 设  $X,Y$  是两个随机变量,则有  $E(X + Y) = E(X) + E(Y)$， $E\left(\sum_{i = 1}^{n}X_{i}\right) = \sum_{i = 1}^{n}E(X_{i})$
4. $E(aX+b)=aE(X)+b$
5. 设  $X,Y$  是相互独立的随机变量,则有  $E(X Y) = E(X)E(Y)$，$E\left(\prod_{i = 1}^{n}X_{i}\right) = \prod_{i = 1}^{n}E(X_{i})$。


### 方差
设  $X$  是随机变量,若  $E[X - E(X)]^{2}$  存在,则称
$$
D(X) = E[X - E(X)]^{2}
$$
为  $X$  的方差,称  $\sigma (X) = \sqrt{D(X)}$  为  $X$  的标准差(或均方差)
$$
D(X) = E(X^{2}) - [E(X)]^{2}
$$
*性质*：
- $E(c)=c,D(c)=0$，其中 $c$ 为常数；
- $E(cX)=cE(X),D(cX)=c^2D(X)$；
- $\scriptstyle D(\sum^{n}_{i=1}X_i)=\sum^{n}_{i=1}D(X_i)+2\sum^{n}_{i=1,j>i}E\{[X_i-E(X_i)][X_j-E(X_j)]\}$，独立情况下 $D(\sum^{n}_{i=1}X_i)=\sum^{n}_{i=1}D(X_i)$
- $D(X\pm Y)=D(X)+D(Y)\pm 2E\{[X-E(X)][Y-E(Y)]\}$

*几种常见分布的方差*：
- $X\sim P(\lambda)$，则 $E(X)=\lambda,D(X)=\lambda$；
- $X\sim B(n,p)$，则 $E(X)=np,D(X)=np(1-p)$；
- $X\sim N(\mu,\sigma^2)$，则 $E(X)=\mu,D(X)=\sigma^2$；
- $X\sim U(a,b)$，则 $E(X)=\frac{b+a}{2},D(X)=\frac{(b-a)^2}{12}$；
- $X\sim EXP(\lambda)$，则 $E(X)=\frac{1}{\lambda},D(X)=\frac{1}{\lambda^2}$。

*标准化随机变量*：
	$X^*$ 称为 $X$ 的标准化随机变量，$X^*=\frac{X-E(X)}{\sqrt{D(X)}}$。

#### 切比雪夫（Chebyshev）不等式
> 设随机变量  $X$  的数学期望  $E(X)$  和方差  $D(X)$  存在,则对任意常数  $\epsilon >0$  ,不等式
> $$P\{ \mid X - E(X)\mid \geqslant \epsilon \} \leqslant \frac{D(X)}{\epsilon^{2}}$$
> 或
> $$P\{ \mid X - E(X)\mid < \epsilon \} \geqslant 1 - \frac{D(X)}{\epsilon^{2}}$$
> 成立。


### 协方差
若关于随机变量  $(X,Y)$  的数学期望  $E\{[X - E(X)][Y - E(Y)]\}$  存在,则称
$$
\operatorname {cov}(X,Y) = E\{[X - E(X)][Y - E(Y)]\}
$$
为随机变量  $X$  与  $Y$  的协方差。

则有
$$
D(X) = \operatorname {cov}(X,X)
$$
$$
D(X\pm Y) = D(X) + D(Y)\pm 2\operatorname {cov}(X,Y).
$$
$$
\operatorname {cov}(X,Y) = E(X Y) - E(X)E(Y)
$$

*性质*：
1. 对称性：$\operatorname {cov}(X,Y) = \operatorname {cov}(Y,X)$；
2. 线性性：$\operatorname {cov}(a X,b Y) = a b\operatorname {cov}(X,Y)$，$a,b$ 是常数；
3. 可加性：$\operatorname {cov}(X_{1} + X_{2},Y) = \operatorname {cov}(X_{1},Y) + \operatorname {cov}(X_{2},Y)$。

#### 协方差矩阵
设  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的协方差 $C_{ij}=Cov(X_i,X_j)$ 均存，称矩阵
$$
C = \left[ \begin{array}{cccc}C_{11} & C_{12} & \dots & C_{1n} \\ C_{21} & C_{22} & \dots & C_{2n} \\ \vdots & \vdots & & \vdots \\ C_{n1} & C_{n2} & \dots & C_{nn} \end{array} \right]
$$
为  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的协方差矩阵

协方差矩阵  $C = (C_{ij})_{n\times n}$  满足:
1. $C_{i i} = D(X_{i}),\quad i = 1,2,\dots ,n$；
2. $C_{i j} = C_{j i},\quad i\neq j,\quad i,j = 1,2,\dots ,n$；
3. C 是非负定矩阵；
4. $C^2_{ij}\leq C_{ii}\cdot C_{jj}$


### 相关系数
若随机变量  $(X,Y)$  的协方差及方差均存在,而且  $D(X) > 0,D(Y) > 0$  则称
$$
\rho_{\small{X Y}} = \frac{\operatorname{cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}
$$
为随机变量  $X$  与  $Y$  的相关系数，$\rho_{X Y}$  是量纲为1的量。
标准化 $X^*=\frac{X-E(X)}{\sqrt{D(X)}}$，则上式可写成 $X$ 和 $Y$ 相应的标准化随机变量的协方差：
$$
\rho_{X Y} = E\bigg[\frac{X - E(X)}{\sqrt{D(X)}}\cdot \frac{Y - E(Y)}{\sqrt{D(Y)}}\bigg] = E(X^{*}Y^{*}) = \operatorname {cov}(X^{*},Y^{*})
$$

设  $X$  与  $Y$  两个随机变量的相关系数  $\rho_{XY}$  存在,则有
1. $\left|\rho_{XY}\right| \leqslant 1$；
2. $\left|\rho_{XY}\right| = 1$  的充要条件是  $X$  与  $Y$  依概率为1线性相关,即存在常数  $b$  和  $a \neq 0$ ,使
$$
P\left\{Y = a X + b\right\} = 1.
$$
若随机变量  $(X,Y)$  相关系数存在,且  $\rho_{X Y} = 0$  ,则称  $X,Y$  不相关（不线性相关）；若  $\rho_{X Y}$ $= 1$，则称  $X,Y$  正相关；若  $\rho_{X Y} = - 1$  ,则称  $X,Y$  负相关。

如果随机变量  $X$  与  $Y$  相互独立，则  $X$  与  $Y$  不相关（此定理的逆定理不存在，当服从二维正态分布时两者能互推）。

### 矩
设  $X$  为随机变量, 若有  $E(|X|^{k}) < +\infty$ , 则
$$
\gamma_{k} = E(X^{k}) \quad (k = 1, 2, \dots)
$$
为  $X$  的  $k$  阶原点矩，随机变量  $X$  的数学期望即一阶原点矩；
$$
\alpha_{k} = E(|X|^{k}) \quad (k = 1, 2, \dots)
$$
为  $X$  的  $k$  阶绝对原点矩。

设随机变量 $X$ 的数学期望  $E(X)$  存在, 且  $E(|X - E(X)|^{k}) < +\infty$ , 则
$$
\mu_{k} = E\left\{\left[X - E(X)\right]^{k}\right\} \quad (k = 1, 2, \dots)
$$
为  $X$  的  $k$  阶中心矩；
$$
\beta_{k} = E\left\{|X - E(X)|^{k}\right\} \quad (k = 1, 2, \dots)
$$
为  $X$  的  $k$  阶绝对中心矩。


### 多维正态随机变量
#### 二维正态概率密度的矩阵表示
二维随机变量  $(X,Y) \sim N(\mu_{1},\sigma_{1}^{2};\mu_{2},\sigma_{2}^{2};\rho)$ ,其联合概率密度为
$$
\scriptstyle\phi \left(x,y\right) = \frac{1}{2\pi\sigma_{1}\sigma_{2}\sqrt{1 - \rho^{2}}}e^{-\frac{1}{2(1 - \rho^{2})}\left[\frac{(x - \mu_{1})^{2}}{\sigma_{1}^{2}} -2\rho \frac{(x - \mu_{1})(y - \mu_{2})}{\sigma_{1}\sigma_{2}} +\frac{(y - \mu_{2})^{2}}{\sigma_{2}^{2}}\right]} ,\quad 
x\in \mathbf{R},y\in \mathbf{R}
$$
引入矩阵记号
$$
X = \left[ \begin{array}{c}x \\ y \end{array} \right], \quad \mu = \left[ \begin{array}{c}\mu_{1} \\ \mu_{2} \end{array} \right], \quad C = \left[ \begin{array}{cc}\sigma_{1}^{2} & \rho \sigma_{1}\sigma_{2} \\ \rho \sigma_{1}\sigma_{2} & \sigma_{2}^{2} \end{array} \right],
$$
$$
C^{-1} = \frac{1}{\operatorname*{det}C}\left[ \begin{array}{cc}\sigma_{2}^{2} & -\rho \sigma_{1}\sigma_{2} \\ -\rho \sigma_{1}\sigma_{2} & \sigma_{1}^{2} \end{array} \right].
$$
二维正态随机变量  $(X,Y)$  的联合概率密度可用矩阵形式表示为
$$
\phi (x,y) = \frac{1}{2\pi|C|^{\frac{1}{2}}}\exp \left\{-\frac{1}{2} (X - \mu)^{\mathrm{T}}C^{-1}(X - \mu)\right\} 
$$
其中矩阵  $C$  是  $(X,Y)$  的协方差矩阵,它是一个正定对称矩阵。
$\rho=1,|C| = 0$  时,无法写出其概率密度,则称  $(X,Y)$  服从退化正态分布或奇异正态分布。

#### n维正态随机变量
设  $n$  维随机变量  $(X_{1},X_{2},\dots ,X_{n})$  的协方差矩阵  $C = (C_{ij})$  是  $n$  阶正定对称矩阵,联合概率密度为
$$
\phi (x_{1},x_{2},\dots ,x_{n}) = \frac{1}{(2\pi)^{\frac{n}{2}}|C|^{\frac{1}{2}}}\exp \left\{-\frac{1}{2} (X - \mu)^{\mathrm{T}}C^{-1}(X - \mu)\right\}
$$
其中
$$
X = \left[ \begin{array}{c}x_{1} \\ x_{2} \\ \vdots \\ x_{n} \end{array} \right], \quad \mu = \left[ \begin{array}{c}\mu_{1} \\ \mu_{2} \\ \vdots \\ \mu_{n} \end{array} \right],
$$
则称  $(X_{1},X_{2},\dots ,X_{n})$  服从  $n$  维正态分布

*性质*：
1. $n$  维正态分布随机变量的任一  $m (m \leqslant n)$  维子向量服从  $m$  维正态分布,特别  $X_{i}$  均为一维正态随机变量；
2. $n$  维正态随机变量  $(X_{1}, X_{2}, \dots , X_{n})$  相互独立的充要条件是 $\rho=0$ 等价于其协方差矩阵是对角矩阵
$$
\begin{array}{r}{C=\left[\begin{array}{l l l l}{C_{11}}&{}&{}&{}\\ {}&{C_{22}}&{}&{}\\ {}&{}&{\ddots}&{}\\ {}&{}&{}&{C_{n n}}\end{array}\right]=\left[\begin{array}{l l l l}{\sigma_{1}^{2}}&{}&{}&{}\\ {}&{\sigma_{2}^{2}}&{}&{}\\ {}&{}&{\ddots}&{}\\ {}&{}&{}&{\sigma_{n}^{2}}\end{array}\right].}\end{array}
$$
3. 相互独立的正态随机变量的有限线性组合仍然服从正态分布；
4. （**线性不变性**）设有矩阵  $\pmb{B} = (b_{ij})_{m \times n}$ ,随机变量  $(X_{1}, X_{2}, \dots , X_{n}) \sim N(\pmb {\mu}, \pmb {C})$ ,其线性变换
$$
\left[ \begin{array}{c c c c}{b_{11}} & {b_{12}} & \dots & {b_{1n}}\\ {b_{21}} & {b_{22}} & \dots & {b_{2n}}\\ \vdots & \vdots & & \vdots \\ {b_{m1}} & {b_{m1}} & \dots & {b_{m n}} \end{array} \right]\left[ \begin{array}{c}{X_{1}}\\ {X_{2}}\\ \vdots \\ {X_{n}} \end{array} \right]
$$
	服从  $m$  维正态分布  $N(B \mu , B C B^{\mathrm{T}})$ .特别若变换矩阵  $\pmb{B}$  为  $n$  阶满秩矩阵,则该线性变换是非退化的  $n$  维正态随机变量；
5. （可加性）$X,Y$ 独立且分别满足正态分布，则 $(X,Y)$ 服从二维正态分布。


## 大数定律和中心极限定理
### 大数定律
#### 马尔科夫不等式
> 设随机变量 $X$ 为非负（即 $P(X \geq 0) = 1$），且其数学期 $E[X]$ 存在。对任意常数 $a > 0$，有：$P(X \geq a) \leq \frac{E[X]}{a}$

#### 切比雪夫不等式
> 设随机变量  $X$  的数学期望  $E(X)$  和方差  $D(X)$  存在,则对任意常数  $\epsilon >0$  ,不等式
> $$P\{ \mid X - E(X)\mid \geqslant \epsilon \} \leqslant \frac{D(X)}{\epsilon^{2}}$$
> 或
> $$P\{ \mid X - E(X)\mid < \epsilon \} \geqslant 1 - \frac{D(X)}{\epsilon^{2}}$$
> 成立。

*频率*：
$$
f_n(A)=\frac{1}{n}\sum^{n}_{i=1}X_i,\quad X_i=\left\{\begin{align}&1 \quad A出现\\&0 \quad A不出现 \end{align}\right.,\quad E[f_n(A)]=P(A)
$$
#### 大数定律
设  $X_{1},X_{2},\dots ,X_{n},\dots$  是随机变量序列,  $X$  是一个随机变量(或为常数  $a$ ),如果对任意给定的正数  $\epsilon$ ,有
$$
\lim_{n\to \infty}P\left\{\left|X_{n} - X\right|< \epsilon \right\} = 1
$$
则称随机变量序列  $X_{1},X_{2},\dots ,X_{n},\dots$  依概率收敛于  $X.$  记为
$$
X_{n}{\xrightarrow{P}}X,\quad 或\quad \lim_{n\to \infty}X_{n} = X(P)
$$

> 设随机变量序列  $X_{1},X_{2},\dots ,X_{n},\dots$  的每个数学期望  $E(X_{i})$  (  $i = 1$ $2,\dots)$  均存在,如果对任意给定的正实数  $\epsilon$  ,有
> $$\lim_{n\to \infty}P\Big\{\Big|\frac{1}{n}\sum_{i = 1}^{n}X_{i} - \frac{1}{n}\sum_{i = 1}^{n}E(X_{i})\Big|< \epsilon \Big\} = 1$$
> 则称随机变量序列  $X_{1},X_{2},\dots ,X_{n},\dots$  服从大数定律

##### 切比雪夫大数定律
> 设  $X_{1},X_{2},\dots ,X_{n},\dots$  是相互独立的随机变量序列,每个随机变量的数学期望  $E(X_{i})$  和方差  $D(X_{i})$  都存在,而且方差一致有界,即存在正常数  $c$  ,使
> $$D(X_{i})< C\quad (i = 1,2,\dots)$$
> 则  $X_{1},X_{2},\dots ,X_{n},\dots$  服从大数定律

##### 独立同分布大数定律
> 设  $X_{1},X_{2},\dots ,X_{n},\dots$  是相互独立且服从同一分布的随机变量序列（i.i.d. 表示独立同分布）,每个随机变量的数学期望与方差存在,即
> $$E(X_{i}) = \mu ,\quad D(X_{i}) = \sigma^{2}\quad (i = 1,2,\dots)$$
> 则  $X_{1},X_{2},\dots ,X_{n},\dots$  服从大数定律,即对任意  $\epsilon >0$  有
> $$\lim_{n\to \infty}P\left\{\left|\frac{1}{n}\sum_{i = 1}^{n}X_{i} - \mu \right|< \epsilon \right\} = 1$$

##### 伯努利大数定律
> 设  $m$  是  $n$  重伯努利试验中事件  $A$  出现的次数,  $p$  是  $A$  在每次试验中发生的概率,则对任意给定的实数  $\epsilon >0$  ,有
> $$\lim_{n\to \infty}P\left\{\left|\frac{m}{n} -p\right|< \epsilon \right\} = 1$$

##### 辛钦大数定律
> 设  $X_{1},X_{2},\dots ,X_{n},\dots$  是相互独立且服从同一分布的随机变量序列,每个随机变量的数学期望存在,即 $$E(X_{i}) = \mu \quad (i = 1,2,\dots)$$
> 则  $X_{1},X_{2},\dots ,X_{n},\dots$  服从大数定律,即对任意正数  $\epsilon >0$  ,有
> $$\lim_{n\to \infty}P\left\{\left|\frac{1}{n}\sum_{i = 1}^{n}X_{i} - \mu \right|< \epsilon \right\} = 1$$

对比独立同分布大数定律少了“方差存在”的条件。


### 中心极限定理
> 设  $X_{1}, X_{2}, \dots , X_{n}, \dots$  是相互独立的随机变量序列, 其前  $n$  项和的标准化随机变量序列为
> $$Z_{n} = \frac{\sum_{i = 1}^{n} X_{i} - \sum_{i = 1}^{n} E\left(X_{i}\right)}{\sqrt{\sum_{i = 1}^{n} D\left(X_{i}\right)}} \qquad (n = 1,2, \dots)$$
> 记  $Z_{n}$  的分布函数为  $F_{n}(x) = P\{Z_{n} \leqslant x\}$ . 若
> $$\lim_{n \to \infty} F_{n}(x) = \Phi (x) = \int_{-\infty}^{x} \frac{1}{\sqrt{2\pi}} \mathrm{e}^{i\frac{x^{2}}{2}} \mathrm{d}t, \quad -\infty < x < +\infty$$
> 则称随机变量序列  $X_{1}, X_{2}, \dots , X_{n}, \dots$  服从中心极限定理。

$$
\frac{\sum_{i = 1}^{n} X_{i} - \sum_{i = 1}^{n} E\left(X_{i}\right)}{\sqrt{\sum_{i = 1}^{n} D\left(X_{i}\right)}} \sim N(0,1)
$$
得到
$$
\sum^n_{k=1}X_k\sim N(\sum^n_{k=1}E(X_k),\sum^n_{k=1}D(X_k))
$$

#### 独立同分布中心极限定理
> 设  $X_{1}, X_{2}, \dots , X_{n}, \dots$  是独立同分布的随机变量序列, 具有数学期望和方差
> $$E\left(X_{i}\right) = \mu , \quad D\left(X_{i}\right) = \sigma^{2} > 0 \quad (i = 1,2, \dots)$$
> 则随机变量序列  $X_{1}, X_{2}, \dots , X_{n}, \dots$  服从中心极限定理,即有
> $$\lim_{n\to \infty}P\left\{\frac{\sum_{i = 1}^{n}X_{i} - n\mu}{\sqrt{n}\sigma}\leqslant x\right\} = \Phi (x)$$

则当  $n$  充分大时,由上述定理可得概率近似计算公式
$$
\scriptstyle P\left\{x_{1}< \sum_{i = 1}^{n}X_{i}\leqslant x_{2}\right\} = P\left\{\frac{x_{1} - n\mu}{\sqrt{n}\sigma} < Z_{n}\leqslant \frac{x_{2} - n\mu}{\sqrt{n}\sigma}\right\}
\approx \Phi \left(\frac{x_{2} - n\mu}{\sqrt{n}\sigma}\right) - \Phi \left(\frac{x_{1} - n\mu}{\sqrt{n}\sigma}\right)
$$

#### 棣莫弗－拉普拉斯中心极限定理
> 设随机变量  $Y_{n} \sim B(n,p)$  （$n = 1,2,\dots$） , 则对任意实数  $x$  有
> $$\lim_{n\to \infty}P\left\{\frac{Y_{n} - n p}{\sqrt{n p\left(1 - p\right)}}\leqslant x\right\} = \Phi \left(x\right)$$



## 数理统计的基本概念
### 总体、样本、统计量
#### 总体
> 研究对象的全体称为总体或母体, 而把组成总体的每个基本元素称为个体。

将总体和数量指标 X 等同起来。总体分布是指数量指标 X 的分布，总体是随机变量。

#### 样本
> 样本是按一定的规定从总体中抽出的一部分个体。取得样本的过程称为抽样。样本中个体的数目称为样本容量。

一组样本  $X_{1}, X_{2}, \dots , X_{n}$  中的每一个  $X_{i}$  也称为样本。

样本是一组随机变量，其具体试验数值记为：$x_1,x_2,\dots,x_n$，称为样本观测值，简称样本值。

为了抽取的样本应尽可能地反映总体的特性，样本应满足**独立同分布**。

*简单随机样本*：
	$X_{1}, X_{2}, \dots , X_{n}$ 是来自总体 X 的样本，如果相互独立且每个分量与总体同分布，称其为简单随机样本，简称样本。

总体  $X$  的分布函数为  $F(x)$ , 则样本  $X_{1}, X_{2}, \dots , X_{n}$  的联合分布函数为
$$
\scriptstyle F(x_{1}, x_{2}, \dots , x_{n}) = P\left\{X_{1} \leqslant x_{1}, X_{2} \leqslant x_{2}, \dots , X_{n} \leqslant x_{n}\right\} = \prod_{i = 1}^{n} P\left\{X_{i} \leqslant x_{i}\right\} .
$$

#### 统计量
> 设 $X_{1}, X_{2}, \dots , X_{n}$ 为来自总体 $X$ 的一个样本，若样本函数 $g\left(X_{1}, X_{2}, \dots , X_{n}\right)$ 中不含任何未知参数，则称 $g\left(X_{1}, X_{2}, \dots , X_{n}\right)$ 为一个统计量。统计量一般是样本的连续函数,显然它是随机变量。

*样本均值*：
	$\overline{{X}} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}$。
*样本方差*：
	$S^{2} = \frac{1}{n - 1}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{2}$，注意是除以 $n-1$。$S$ 称为标准差。
*样本 k 阶原点矩*：
	$A_{k} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}$。
*样本 k 阶中心矩*：
	$M_{k} = \frac{1}{n}\sum_{i = 1}^{n}(X_{i} - \overline{{X}})^{k}$。


### 常用统计分布
#### 标准正态分布
$$
f(x)=\frac{1}{2\pi}e^{\frac{-x^{2}}{2 }},x\in R
$$
上侧分位数 $u_\alpha(0<\alpha<1)$ 满足
$$
P\{X>u_\alpha\}=\int_{u_\alpha}^{+\infty}f(x)\mathrm{d}x=\alpha
$$

```handwritten-ink
{
	"versionAtEmbed": "0.3.4",
	"filepath": "笔记/概率论与数理统计/images/Ink/Writing/2025.11.18 - 11.26am.writing"
}
```

#### $\chi^{2}$ （卡方）分布
设随机变量  $\chi^{2}$  的概率密度（不用背）为
$$
f(x) = \left\{ \begin{array}{ll} - \frac{1}{2\Gamma\left(\frac{n}{2}\right)}\left(\frac{x}{2}\right)^{\frac{n}{2} -1}\mathrm{e}^{-\frac{x}{2}}, & x > 0, \\ 0, & x\leqslant 0, \end{array} \right.
$$
则称随机变量  $\chi^{2}$  服从自由度为  $n$  的  $\chi^{2}$  分布,记为  $\chi^{2} \sim \chi^{2}(n)$ .
其中  $\Gamma (s)$  为  $\Gamma$  函数,定义为
$$
\Gamma (s) = \int_{0}^{+\infty} x^{s - 1} \mathrm{e}^{-x} \mathrm{~d} x \qquad (s > 0).
$$
设有  $n$  个相互独立并且都服从正态分布  $N(0,1)$  的随机变量  $X_{1}, X_{2}, \dots , X_{n}$ ,记 $\chi^{2} = \sum_{i = 1}^{n} X_{i}^{2}$，则称随机变量  $\chi^{2}$  服从自由度为  $n$  的  $\chi^{2}$  分布。自由度是指上式右端所包含的独立变量的个数。

卡方分布的上侧分位数 $\chi^{2}_\alpha(n)$ 满足：
$$
P\left\{\chi^{2} > \chi_{\alpha}^{2}(n)\right\} = \int_{\chi_{\alpha}^{2}(n)}^{+\infty} f_{\chi^{2}}(x) \mathrm{d} x = \alpha
$$
*性质*：
1. $E(\chi^2)=n,\quad D(chi^2)=2n$；
2. （可加性）随机变量  $Y_{1}, Y_{2}$  相互独立,且  $Y_{1} \sim \chi^{2}\left(n_{1}\right)$，$Y_{2} \sim \chi^{2}\left(n_{2}\right)$，则有 $Y_{1} + Y_{2} \sim \chi^{2}\left(n_{1} + n_{2}\right)$；
3. 当  $n$  足够大时, 有
$$
\chi_{\alpha}^{2}(n) \approx n + u_{\alpha} \sqrt{2n},
$$
	式中  $u_{\alpha}$  是标准正态分布的上侧分位数, 即  $u_{\alpha}$  是满足等式  $\Phi \left(u_{\alpha}\right) = 1 - \alpha$  的数；
4. $n$ 足够大时，近似有 $\chi^2\sim N(n,2n)$。


#### t 分布
设随机变量  $T$  的概率密度为
$$
f(x) = \frac{\Gamma\left(\frac{n + 1}{2}\right)}{\sqrt{n \pi \Gamma\left(\frac{n}{2}\right)}} \left(1 + \frac{x^{2}}{n}\right)^{\frac{n + 1}{2}}, \quad -\infty < x < +\infty ,
$$
则称  $T$  服从自由度为  $n$  的  $t$  分布, 记为  $T \sim t(n)$ 。

设随机变量  $X, Y$  相互独立,  $X \sim N(0, 1), Y \sim \chi^{2}(n)$ , 记
$$
T = \frac{X}{\sqrt{Y / n}},
$$
则随机变量  $T$  服从自由度为  $n$  的  $t$  分布。

t 分布上侧分位数 $t_\alpha(n)$ 满足：
$$
P\left\{T > t_{\alpha}(n)\right\} = \int_{t_{\alpha}(n)}^{+\infty} f_{T}(x) \mathrm{d}x = \alpha
$$
*性质*：
1. $n$ 较大时，$\lim_{n\to \infty}f_T(x)=\phi(x)$；
2. 关于 y 轴对称。


#### F 分布
设随机变量  $F$  的概率密度为
$$
f(x) = \left\{ \begin{array}{l l}{\frac{n_{1}}{n_{1}^{2}}\frac{n_{2}}{n_{2}^{2}}\frac{\Gamma\left(\frac{n_{1} + n_{2}}{2}\right)}{\Gamma\left(\frac{n_{1}}{2}\right)\Gamma\left(\frac{n_{2}}{2}\right)} x^{\frac{n_{1}}{2} -1}(n_{1}x + n_{2})^{-\frac{n_{1} + n_{2}}{2}},} & {x > 0,}\\ {0,} & {x\leqslant 0,} \end{array} \right.
$$
则称  $F$  服从第一自由度为  $n_{1}$ , 第二自由度为  $n_{2}$  的  $F$  分布, 记为  $F \sim F(n_{1}, n_{2})$。

设随机变量  $X, Y$  相互独立,  $X \sim \chi^{2}(n_{1}), Y \sim \chi^{2}(n_{2})$ , 记
$$
F = \frac{X / n_{1}}{Y / n_{2}},
$$
则随机变量  $F$  服从第一自由度为  $n_{1}$ , 第二自由度为  $n_{2}$  的  $F$  分布。

F 分布上侧分位数 $F_\alpha(n_1,n_2)$ 满足
$$
P\left\{F > F_{\alpha}(n_{1}, n_{2})\right\} = \int_{F_{\alpha}(n_{1}, n_{2})}^{+\infty} f_{F}(x) \mathrm{d}x = \alpha
$$

*性质*：
1. $P\{F > F_{1 - \alpha}(n_{1},n_{2})\} = 1 - \alpha$；
2. $\frac{1}{F} \sim F(n_{2}, n_{1})$；
3. $F_{1 - \alpha}(n_{1},n_{2}) = \frac{1}{F_{\alpha}(n_{2},n_{1})}$。


### 抽样分布定理
设  $X_{1},X_{2},\dots ,X_{n}$  是正态总体  $N(\mu ,\sigma^{2})$  的样本，$\overline{{X}}=\frac{1}{n}\sum^n_{i=1}X_i$，$S^{2}=\frac{1}{n-1}\sum^n_{i=1}(X_i-\overline{X})^2$ 分别是样本均值和样本方差，则有
1. $\overline{{X}}$  与  $S^{2}$  相互独立；
2. $\overline{{X}}\sim N\left(\mu ,\frac{\sigma^{2}}{n}\right)$；
3. $\frac{n - 1}{\sigma^{2}} S^{2}\sim \chi^{2}(n - 1)$；
4. $\frac{\overline{{X}} - \mu}{S\sqrt{n}}\sim t(n - 1)$。
5. 若 T \sim t(k)，则 T^2 \sim F(1, k)

设  $X_{1},X_{2},\dots ,X_{n_{1}}$  和  $Y_{1},Y_{2},\dots ,Y_{n_{2}}$  分别是来自正态总体  $N(\mu_{1},\sigma_{1}^{2})$  和 $N(\mu_{2},\sigma_{2}^{2})$  的样本,并且它们相互独立,  $\overline{{X}},S_{1}^{2}$  及  $\overline{{Y}},S_{2}^{2}$  分别是这两组样本的样本均值和样本方差,则有
1. $F = \frac{S_{1}^{2} / \sigma_{1}^{2}}{S_{2}^{2} / \sigma_{2}^{2}}\sim F\left(n_{1} - 1,n_{2} - 1\right);$
2. 当  $\sigma_{1}^{2} = \sigma_{2}^{2} = \sigma^{2}$  时,
$$
T = \frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}\sim t\left(n_{1} + n_{2} - 2\right),
$$
	其中  $S_{w} = \sqrt{\frac{\left(n_{1} - 1\right)S_{1}^{2} + \left(n_{2} - 1\right)S_{2}^{2}}{n_{1} + n_{2} - 2}}.$


## 参数估计
### 参数的点估计
参数点估计问题的一般提法是:
设总体 $X$ 的分布函数为 $F(x;\theta_{1},\theta_{2},\dots ,\theta_{m})$，其分布类型已知,  $\theta_{1},\theta_{2},\dots ,\theta_{m}$  是未知参数（$\theta$ 的取值范围称为参数空间）。$X_{1},X_{2},\dots ,X_{n}$  是总体  $X$  的样本，对每一个未知参数 $\theta_{i}(i = 1,2,\dots ,m)$，构造一个适当的统计量  $\widehat{\theta}_{i} = \widehat{\theta}_{i}(X_{1},X_{2},\dots ,X_{n})$，作为对参数  $\theta_{i}$  的估计（即点估计量）。

#### 矩估计法
设总体 $X$ 的 $k$ 阶矩 $E(X^k)$ 存在，$X_1,X_2,\dots,X_n$ 是总体的样本，有
$$
E(A_k)=E(\frac{1}{n}\sum^n_{i=1}X_i^k)=\frac{1}{n}\sum^n_{i=1}E(X_i^k)=E(X^k)
$$
即样本原点矩（一个随机变量）按概率趋近于总体原点矩（一个数值）（$\frac{1}{n}\sum^n_{i=1}X_i^k\xrightarrow{P}E(X^k)$）。
（或可通过辛钦大数定理得出）

设总体  $X$  的分布为  $f(x;\theta_{1},\theta_{2},\dots ,\theta_{m})$  ,若总体的各阶矩存在,则它的矩(原点矩或中心矩)是参数  $\theta_{1},\theta_{2},\dots ,\theta_{m}$  的函数。此处以原点矩为例,总体  $k$  阶原点矩为
$$
\gamma_{k} =E(X^k)= \int_{-\infty}^{+\infty}x^{k}f(x;\theta)\mathrm{d}x
$$
或
$$
\gamma_{k} =E(X^k)= \sum_{i}x_{i}^{k}p(x_{i};\theta)
$$
用样本  $k$  阶原点矩  $A_{k} = \frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}$  去估计相应的总体  $k$  阶原点矩,即构造方程组
$$
\gamma_{k}= A_{k}=\frac{1}{n}\sum_{i = 1}^{n}X_{i}^{k}
$$
解此方程组，其解为  $\widehat{\theta}_{k} = \widehat{\theta}_{k}(X_{1},X_{2},\dots ,X_{n}),k = 1,2,\dots ,m.$  就以 $\widehat{\theta}_{k}$ 作为  $\theta_{k}$  的估计。

#### 极大似然估计法（M.L.E.）
设总体分布形式已知,含有一个或几个未知参数  $\theta_{1},\theta_{2},\dots ,\theta_{m}$，$X_{1},X_{2},\dots ,X_{n}$  是来自该总体的样本，$x_{1},x_{2},\dots ,x_{n}$  是相应的样本观测值,相当于事件
$$
\{X_{i} = x_{1},X_{2} = x_{2},\dots ,X_{n} = x_{n}\}
$$
已经发生。我们把已经发生的事件，看成最可能出现的事件，即认为它具有最大的概率。

对于离散型总体，上述事件发生的概率为
$$
\prod_{i = 1}^{n}P\left\{X_{i} = x_{i}\right\} = \prod_{i = 1}^{n}p\left(x_{i};\theta_{1},\theta_{2},\dots ,\theta_{m}\right) \tag{7.1.2}
$$
对于连续型总体，随机样本 $(X_{1},X_{2},\dots ,X_{n})$ 落在点 $(x_{1},x_{2},\dots ,x_{n})$ 的边长依次为 $\mathrm{d}x_{1}, \mathrm{~d}x_{2}, \dots , \mathrm{d}x_{n}$ 的  $n$  维长方体邻域内的概率近似为
$$
\prod_{i = 1}^{n} f(x_{i}; \theta_{1}, \theta_{2}, \dots , \theta_{m}) \mathrm{d}x_{i} = \prod_{i = 1}^{n} f(x_{i}; \theta_{1}, \theta_{2}, \dots , \theta_{m}) \prod_{i = 1}^{n} \mathrm{d}x_{i}.
$$
因为  $\prod_{i = 1}^{n} \mathrm{d}x_{i}$  与参数  $\theta_{1}, \theta_{2}, \dots , \theta_{m}$  无关,故只需考虑
$$
\prod_{i = 1}^{n} f(x_{i}; \theta_{1}, \theta_{2}, \dots , \theta_{m})\tag{7.1.3}
$$
我们将式(7.1.2)和(7.1.3)统称为参数  $\theta_{1}, \theta_{2}, \dots , \theta_{m}$  的似然函数,记为  $L(x_{1}, x_{2}, \dots , x_{n}; \theta_{1}, \theta_{2}, \dots , \theta_{m})$。
$$
L(x_{1}, x_{2}, \dots , x_{n}; \widehat{\theta}_{1}, \widehat{\theta}_{2}, \dots , \widehat{\theta}_{m}) = \max_{\theta_{1}, \theta_{2}, \dots , \theta_{m}} L(x_{1}, x_{2}, \dots , x_{n}; \theta_{1}, \theta_{2}, \dots , \theta_{m})
$$
则称  $\widehat{\theta}_{1}, \widehat{\theta}_{2}, \dots , \widehat{\theta}_{m}$  为  $\theta_{1}, \theta_{2}, \dots , \theta_{m}$  的最大似然估计值,称  $\widehat{\theta}_{k} (X_{1}, X_{2}, \dots , X_{n})$ $(k = 1,2, \dots , m)$  为参数  $\theta_{k}$  的最大似然估计量.

由上可见,求未知参数的似然估计就归结为求似然函数  $L$  的最大值点. 因为对数函数是单调增函数,所以  $\ln L$  与  $L$  在相同点处达到最大值. 为了计算方便,一般通过求解如下的似然方程组
$$
\frac{\partial \ln L}{\partial \theta_{k}} = 0, \qquad k = 1, 2, \dots , m
$$
得到未知参数的最大似然估计,多数常见情形都属于这种情况。

求极大似然估计量的一般步骤：
1. 写出似然函数
$$L(x_{1},x_{2},\cdots,x_{n};\theta_{1},\theta_{2},\cdots,\theta_{l})=\prod\limits_{i = 1}^{n}f(x_{i};\theta_{1},\theta_{2},\cdots,\theta_{l})$$
2. 对似然函数取对数
$$\ln L=\sum\limits_{i = 1}^{n}\ln f(x_{i};\theta_{1},\theta_{2},\cdots,\theta_{m})$$
3. 对 $\theta_{j}(j = 1,\cdots,l)$ 分别求偏导，建立似然方程(组)
$$\frac{\partial\ln L}{\partial\theta_{j}} = 0,\quad(j = 1,2,\cdots,l)$$
	解得 $\hat{\theta}_{1},\cdots,\hat{\theta}_{l}$ 分别为 $\theta_{1},\cdots,\theta_{l}$ 的极大估计值。
4. 写出 $\theta_{1},\cdots,\theta_{l}$ 的极大估计量。


### 估计量的优良性准则
#### 无偏性
设  $\widehat{\theta} = \widehat{\theta} (X_{1}, X_{2}, \dots , X_{n})$  是未知参数  $\theta$  的一个估计量,若对  $\theta$  的所有可能取值,都有
$$
E(\widehat{\theta}) = \theta ,
$$
则称  $\widehat{\theta}$  是  $\theta$  的一个无偏估计量。

一个估计量如果不是无偏的就称之为有偏估计量。称  $E(\widehat{\theta} - \theta)$  为估计量  $\widehat{\theta}$  的偏差，在科学技术中也称之为  $\widehat{\theta}$  的系统误差。由此,无偏估计的实际意义就在于无系统误差。

如果 $\theta$ 的实函数 $g(\theta)$ 的无偏估计量存在，称 $g(\theta)$ 为可估计函数。

样本均值 $\overline{X}$ 是总体均值 $E(X)$ 的无偏估计量。
样本方差 $S^2$ 是总体方差 $\sigma^2$ 的无偏估计量。

#### 有效性
设  $\widehat{\theta}_{1}\left(X_{1}, X_{2}, \dots , X_{n}\right), \widehat{\theta}_{2}\left(X_{1}, X_{2}, \dots , X_{n}\right)$  是未知参数  $\theta$  的两个无偏估计, 若对  $\theta$  的所有可能取值, 都有
$$
D\left(\widehat{\theta}_{1}\right) \leqslant D\left(\widehat{\theta}_{2}\right),
$$
则称  $\widehat{\theta}_{1}$  比  $\widehat{\theta}_{2}$  有效。

设  $\widehat{\theta}_{0}$  是  $\theta$  的无偏估计,若对  $\theta$  的任何一个无偏估计  $\widehat{\theta}$ ,都有
$$
D(\widehat{\theta}_{0}) \leqslant D(\widehat{\theta})
$$
对  $\theta$  的所有可能取值成立,则称  $\widehat{\theta}_{0}$  为  $\theta$  的最小方差无偏估计。

$\overline{X}$  和  $S^{2}$  是  $\mu$  和  $\sigma^{2}$  的最小方差无偏估计。

#### 相合性
设  $\widehat{\theta}_{n} = \widehat{\theta}_{n}\left(X_{1}, X_{2}, \dots , X_{n}\right)$  是  $\theta$  的估计量,若对  $\theta$  的所有可能取值,当  $n \to \infty$  时, $\widehat{\theta}_{n}$  依概率收敛于  $\theta$ ,即对任意  $\epsilon > 0$ ,有
$$
\lim_{n\to \infty}P\left\{\left|\widehat{\theta}_{n} - \theta \right|< \epsilon \right\} = 1\quad 
$$
成立,则称  $\widehat{\theta}_{n}$  为  $\theta$  的相合估计量或一致估计量。

利用大数定律和切比雪夫不等式证明相合性。

$\overline{X} = \frac{1}{n} \sum_{i = 1}^{n} X_{i}$  是  $\mu$  的相合估计量。
$S^{2}$  与  $M_{2}$  都是  $\sigma^{2}$  的相合估计量。


### 区间估计
给定一个很小的数  $\alpha >0$  ,如果对于参数  $\theta$  的所有可能取值,都有
$$
P\{\widehat{\theta}_{1}(X_{1},X_{2},\dots ,X_{n})\leqslant \theta \leqslant \widehat{\theta}_{2}(X_{1},X_{2},\dots ,X_{n})\} = 1 - \alpha
$$
则称随机区间  $[\widehat{\theta}_{1},\widehat{\theta}_{2}]$  是  $\theta$  的置信水平为  $1 - \alpha$  的置信区间。

#### 枢轴变量法构造置信区间
一种寻找置信区间的一般方法.归结如下:
1. 选取待估计参数  $\theta$  的良好的估计量（常用 $\overline{{X}}\to \mu,S^{2}\to\sigma^{2}$）；
2. 构造枢轴量（一个**仅**包含参数  $\theta$  及其估计量的函数）$W(X_{1},X_{2},\dots ,X_{n};\theta)$，$W$  的概率分布能完全确定,与  $\theta$  无关(如上例中  $U =$ $\frac{\overline{{X}} - \mu}{\sigma / \sqrt{n}}$  ,其分布是  $N(0,1)$  ,与  $\mu$  无关)，确定 $W$ 的分布；
3. 对任何参数  $a< b$  ,不等式  $a\leqslant W\leqslant b$  可以改写为等价的形式  $A\leqslant \theta \leqslant B,A$  与  $B$  是不包含未知参数的统计量；
4. 根据  $W$  的分布,找出其上侧  $\frac{\alpha}{2}$  分位数  $w_{\frac{\alpha}{2}}$  （求单侧置信区间时则找出分位数 $w_{\alpha}$）和上侧  $\left(1 - \frac{\alpha}{2}\right)$  分位数  $w_{1 - \frac{\alpha}{2}}$  ,有  $P\{w_{1 - \frac{\alpha}{2}}\leqslant W\leqslant w_{\frac{\alpha}{2}}\} = 1 - \alpha$  ,改写为等价的形式  $P\{A\leqslant \theta \leqslant B\} = 1 - \alpha$  ,区间  $[A,B]$  即是参数  $\theta$  的置信水平为  $1 - \alpha$  的置信区间.

#### 一个正态总体参数的置信区间
##### 总体均值 $\mu$ 的置信区间
$\sigma^{2}$  已知时构造枢轴量服从正态分布：$U = \frac{\overline{{X}} - \mu}{\sigma / \sqrt{n}}\sim N(0,1)$；
$\sigma^{2}$  未知时构造枢轴量服从 t 分布：$T = \frac{\overline{{X}} - \mu}{S / \sqrt{n}} \sim t(n - 1)$。
##### 总体方差 $\sigma^{2}$ 的置信区间
$\mu$ 未知，由于 $S^{2}$ 是 $\sigma^{2}$ 的无偏估计，取 $\frac{n - 1}{\sigma^{2}} S^{2}\sim \chi^{2}(n - 1)$ 作为枢轴变量。

#### 两个正态总体的区间估计
##### 两个正态总体均值差  $\mu_{1} - \mu_{2}$  的置信区间
$\sigma_{1}^{2},\sigma_{2}^{2}$ 已知时，
$$
\overline{X} - \overline{Y}\sim N\left(\mu_{1} - \mu_{2},\frac{\sigma_{1}^{2}}{n_{1}} +\frac{\sigma_{2}^{2}}{n_{2}}\right),
$$
取枢轴变量为
$$
U = \frac{(\overline{X} - \overline{Y}) - (\mu_{1} - \mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}}\sim N(0,1),
$$

$\sigma_{1}^{2},\sigma_{2}^{2}$  未知,但  $\sigma_{1}^{2} = \sigma_{2}^{2}$ 时，
记
$$
\begin{array}{l}S_{w}&=\sqrt{\left[\sum_{i=1}^{n_{1}}\left(X_{i}-\overline{{X}}\right)^{2}+\sum_{j=1}^{n_{2}}\left(Y_{j}-\overline{{Y}}\right)^{2}\right]/\left(n_{1}+n_{2}-2\right)}\\ &=\sqrt{\frac{\left(n_{1}-1\right)S_{1}^{2}+\left(n_{2}-1\right)S_{2}^{2}}{n_{1}+n_{2}-2}}.\end{array}
$$
于是以  $T$  作为枢轴变量
$$
T = \frac{(\overline{X} - \overline{Y}) - (\mu_{1} - \mu_{2})}{S_{w} \sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}} \sim t(n_{1} + n_{2} - 2),
$$

##### 两个正态总体方差比  $\frac{\sigma_{2}^{2}}{\sigma_{1}^{2}}$  的置信区间
$\mu_{1}, \mu_{2}$ 未知时，$F$ 作为枢轴变量
$$
F = \frac{S_{1}^{2} / \sigma_{1}^{2}}{S_{2}^{2} / \sigma_{2}^{2}} = \frac{\sigma_{2}^{2}}{\sigma_{1}^{2}} \cdot \frac{S_{1}^{2}}{S_{2}^{2}} \sim F(n_{1} - 1, n_{2} - 1),
$$

$\mu_{1}$  和  $\mu_{2}$  均已知时，构造枢轴变量
$$
F = \frac{\frac{1}{n_{1}}\sum_{i = 1}^{n}(X_{i} - \mu_{1})^{2} / \sigma_{1}^{2}}{\frac{1}{n_{2}}\sum_{j = 1}^{n_{2}}(Y_{j} - \mu_{2})^{2} / \sigma_{2}^{2}}\sim F(n_{1},n_{2})
$$


## 假设检验
### 假设检验基本概念
设总体  $X$  的分布未知,或  $X$  的某个分布参数  $\theta$  未知,对总体分布或分布参数  $\theta$  提出一个假设  $H_{0}$ ,然后根据样本所提供的信息,运用统计分析的方法进行判断,从而做出是接受还是拒绝  $H_{0}$  的决定,这就是假设检验问题。

记 $H_0$ 为原假设或零假设；与原假设相对立的称为备择假设，记作 $H_1$。

使原假设  $H_{0}$  得以接受的检验统计量取值的区域称为检验的接受域,使原假设  $H_{0}$  被拒绝的检验统计量取值的区域称为检验的拒绝域（否定域）。

#### 假设检验基本步骤
1. 提出原假设：根据问题的具体要求,提出原假设  $H_{0}$  和备择假设  $H_{1}$；
2. 简历检验统计量：寻找参数的一个良好估计量，选取不带任何未知参数的检验统计量，并在  $H_{0}$  成立的条件下，能确定检验统计量的分布(或近似分布)；
3. 确定 $H_{0}$ 的否定域：按问题的要求选定显著性水平  $\alpha$，根据检验统计量的分布和备择假设  $H_{1}$  的内容，确定拒绝域；
4. 对 $H_{0}$ 做判断：根据样本观测值计算检验统计量的值,判断该值是在拒绝域还是在接受域内,做出拒绝  $H_{0}$  或接受  $H_{0}$  的检验结论

对原假设做出判断，称为对 $H_0$ 做显著性检验，$1-\alpha$ 称为置信水平。

#### 假设检验的两类错误
1. 第一类错误（弃真）：$H_{0}$  成立的情况下，错误地拒绝了 $H_{0}$；
2. 第二类错误（纳伪）：$H_{0}$  不成立的情况下，错误地接受了 $H_{0}$。

检验假设 $H_0: \mu = \mu_0$，$H_1: \mu \neq \mu_0$。原假设成立时，$U = \frac{\overline{X} - \mu_0}{\sigma_0 / \sqrt{n}} \sim N(0,1)$，若 $H_1$ 成立时，(即$\mu\neq\mu_0$)，$U = \frac{\overline{X}-\mu_0}{\sigma_0/\sqrt{n}} = \frac{\overline{X}-\mu}{\sigma_0/\sqrt{n}} + \frac{\mu-\mu_0}{\sigma_0/\sqrt{n}} \sim N(\frac{\mu-\mu_0}{\sigma_0/\sqrt{n}},1)$
犯第一类错误的概率 $\alpha$：$P\{|U| > u_{\frac{\alpha}{2}}|H_{0}真\} = \alpha$；
犯第二类错误的概率 $\beta(\mu)$：$P_{\mu}\{|U| \leq u_{\frac{\alpha}{2}}\} = \beta(\mu),\mu \neq \mu_0$。


### 正态总体的参数检验
#### 单样本检验
##### 均值 $\mu$ 的检验
$\sigma^{2}$ 已知时，用 U 检验法，检验 $H_0: \mu = \mu_0$，$H_1: \mu \neq \mu_0$。原假设成立时，$U = \frac{\overline{X} - \mu_0}{\sigma_0 / \sqrt{n}} \sim N(0,1)$，拒绝域为：$|u| > u_{\frac{\alpha}{2}}$。
$\sigma^{2}$ 未知时，用 t 检验法，检验 $H_0: \mu = \mu_0$，$H_1: \mu \neq \mu_0$。原假设成立时，$T = \frac{\overline{X} - \mu_0}{S / \sqrt{n}} \sim t(n-1)$，拒绝域为：$|T| > t_{\frac{\alpha}{2}}(n-1)$。
##### 方差 $\sigma^{2}$ 的检验
$\mu$ 已知时，用 $\chi^{2}$ 检验法，检验 $H_0: \sigma^{2} = \sigma_{0}^{2}$，$H_1: \sigma^{2} \neq \sigma_{0}^{2}$。原假设成立时，$\chi^{2} = \sum^{n}_{i=1}\left(\frac{X_{i} - \mu}{\sigma_0}\right)^{2} \sim \chi^{2}(n)$，拒绝域为：$\chi^{2} > \chi^{2}_{\frac{\alpha}{2}}(n)$ 或 $\chi^{2} < \chi^{2}_{1-\frac{\alpha}{2}}(n)$。
$\mu$ 未知时，用 $\chi^{2}$ 检验法，检验 $H_0: \sigma^{2} = \sigma_{0}^{2}$，$H_1: \sigma^{2} \neq \sigma_{0}^{2}$。原假设成立时，$\chi^{2} = (n-1)\frac{S^{2}}{\sigma_{0}^{2}} \sim \chi^{2}(n-1)$，拒绝域为：$\chi^{2} > \chi^{2}_{\frac{\alpha}{2}}(n-1)$ 或 $\chi^{2} < \chi^{2}_{1-\frac{\alpha}{2}}(n-1)$。

#### 双样本检验
##### 均值差 $\mu_1-\mu_2$ 的检验
已知 $\sigma_{1}^{2}$ 与 $\sigma_{2}^{2}$，用双样本 U 检验法，检验 $H_0\colon \mu_1 = \mu_2$，$H_1\colon \mu_1 \neq \mu_2$，原假设 $H_0$ 成立时，
$$
U = \frac{(\overline{X} - \overline{Y}) - (\mu_{1} - \mu_{2})}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}} = \frac{\overline{X} - \overline{Y}}{\sqrt{\frac{\sigma_{1}^{2}}{n_{1}} + \frac{\sigma_{2}^{2}}{n_{2}}}} \sim N(0,1),
$$
拒绝域为  $|U| > u_{\frac{\alpha}{2}}$。

未知 $\sigma_{1}^{2}$ 与 $\sigma_{2}^{2}$，但 $\sigma_{1}^{2} = \sigma_{2}^{2} = \sigma^{2}$，检验 $H_0\colon \mu_1 = \mu_2$，$H_1\colon \mu_1 \neq \mu_2$，原假设 $H_0$ 成立时，
$$
T = \frac{(\overline{{X}} - \overline{{Y}}) - (\mu_{1} - \mu_{2})}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}} = \frac{\overline{{X}} - \overline{{Y}}}{S_{w}\sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}\sim t\left(n_{1} + n_{2} - 2\right),
$$
$$
\begin{array}{l}S_{w}^{2}&=\frac{1}{n_{1}+n_{2}-2}\big[\left(n_{1}-1\right)S_{1}^{2}+\left(n_{2}-1\right)S_{2}^{2}\big]\\ & =\frac{1}{n_{1}+n_{2}-2}\Big[\sum_{i=1}^{n_{1}}\left(X_{i}-\overline{{X}}\right)^{2}+\sum_{j=1}^{n_{2}}\left(Y_{j}-\overline{{Y}}\right)^{2}\Big]~.\end{array}
$$
拒绝域为 $|T| > t_{\frac{\alpha}{2}}(n_{1} + n_{2} - 2)$。

##### 方差 $\sigma^2$ 的检验
检验 $H_0: \sigma^{2} = \sigma_{0}^{2}$，$H_1: \sigma^{2} \neq \sigma_{0}^{2}$。
已知 $\mu_1$ 和 $\mu_2$，原假设成立时，
$$
F = \frac{n_2\sum\limits_{i = 1}^{n_1}(X_i - \mu_1)^2}{n_1\sum\limits_{j = 1}^{n_2}(Y_j - \mu_2)^2} \sim F(n_1, n_2)
$$
- 拒绝域为：$f > F_{\frac{\alpha}{2}}(n_1, n_2)$ 或 $f < F_{1 - \frac{\alpha}{2}}(n_1, n_2)$。

已知 $\mu_1$ 和 $\mu_2$，原假设成立时，
$$
F=\frac{S_{1}^{2}/\sigma_{1}^{2}}{S_{2}^{2}/\sigma_{2}^{2}}=\frac{S_{1}^{2}}{S_{2}^{2}}\sim F(n_{1}-1,n_{2}-1)
$$
拒绝域为：$f > F_{\frac{\alpha}{2}}(n_1-1, n_2-1)$ 或 $f < F_{1 - \frac{\alpha}{2}}(n_1-1, n_2-1)$。


## 回归分析
### 相关关系与回归分析
*确定性关系*：
	可表述为函数关系；
*相关关系*：
	有关系但不确定。

在一个问题中,自变量  $X_{1},X_{2},\dots ,X_{k}$  的取值为  $x_{1},x_{2},\dots ,x_{k}$，得到模型
$$
Y = \mu \left(x_{1}, x_{2}, \dots , x_{k}\right) + \epsilon
$$
$\epsilon$  作为随机误差, 通常要求其均值为 0、方差存在, 即 $E(\epsilon) = 0, D(\epsilon) = \sigma^{2}$，$\sigma^{2}$ 是用回归函数近似因变量 Y 产生的均方误差。在这样的假定下,  $\mu \left(x_{1}, x_{2}, \dots , x_{k}\right)$  就是在自变量  $X_{1}, X_{2}, \dots , X_{k}$  取值为  $x_{1}, x_{2}, \dots , x_{k}$  时, 因变量  $Y$  的数学期望值, 可写为
$$
\mu \left(x_{1}, x_{2}, \dots , x_{k}\right) = E\left(Y \mid X_{1} = x_{1}, X_{2} = x_{2}, \dots , X_{k} = x_{k}\right).
$$
函数  $\mu (x_{1},x_{2},\dots ,x_{k})$  称为  $Y$  对  $X_{1},X_{2},\dots ,X_{k}$  的**回归函数**，而方程
$$
y = \mu (x_{1},x_{2},\dots ,x_{k})
$$
称为  $Y$  对  $X_{1},X_{2},\dots ,X_{k}$  的**回归方程**。有时为明确起见,在"回归函数"和"回归方程"之前加上"理论"二字,以表明它们是直接来自模型。
以上模型称为回归模型,其中回归方程是一个确定性的函数关系,它近似地描述了非确定性的相关关系。回归分析就是以此为基础处理相关关系的一种方法。


### 一元回归分析
#### 一元线性回归模型
回归函数  $\mu (x_{1}, x_{2}, \dots , x_{k})$  为线性函数的情形:
$$
\mu (x_{1}, x_{2}, \dots , x_{k}) = b_{0} + b_{1} x_{1} + \dots + b_{k} x_{k},
$$
其中  $b_{0}, b_{1}, \dots , b_{k}$  是未知常系数。这种情形叫做线性回归问题。

回归模型
$$
Y = a + b x + \epsilon , \quad E(\epsilon) = 0, D(\epsilon) = \sigma^{2}
$$
称为一元线性回归模型, 其中  $a, b, \sigma^{2}(0< \sigma < +\infty)$  为未知参数。  $a$  称为回归常数（截距），$b$  称为  $Y$  对  $X$  的回归系数（斜率），$\epsilon \sim N(0, \sigma^{2})$。

#### 一元线性回归模型的参数估计
取定自变量  $X$  的一组值  $x_{1}, x_{2}, \dots , x_{n}$ , 对  $Y$  做  $n$  次独立观测 (试验)，记试验结果为  $Y_{1}, Y_{2}, \dots , Y_{n}$。
选 $a,b$ 估计使离差平方和最小：
$$
\sum^{n}_{i=1}(y_{i}-\hat{y_{i}})^{2}=\sum^{n}_{i=1}(y_{i}-\hat{a}-\hat{b}x_{i})^{2}
$$
##### $a,b,\sigma^{2}$ 的估计
$a,b$ 估计利用最小二乘法：
上式分别对 $a,b$ 求一阶偏导，建立方程组：
$$
\begin{cases} \displaystyle\sum_{i = 1}^{n}(y_{i}-a - bx_{i}) = 0\\ \displaystyle\sum_{i = 1}^{n}(y_{i}-a - bx_{i})x_{i}=0 \end{cases}
$$
改写得到**正规方程组**：
$$
\begin{cases} na + \left( \sum_{i=1}^{n} x_{i} \right) b = \sum_{i=1}^{n} y_{i} \\ \left( \sum_{i=1}^{n} x_{i} \right) a + \left( \sum_{i=1}^{n} x_{i}^{2} \right) b = \sum_{i=1}^{n} x_{i} y_{i} \end{cases}
$$
解得
$$
\begin{cases} \hat{b}=\dfrac{l_{xy}}{l_{xx}}\\ \hat{a}=\overline{y}-\hat{b}\overline{x} \end{cases}
$$
其中
$$
\overline{x}=\frac{1}{n}\sum\limits_{i = 1}^{n}x_{i},\quad\overline{y}=\frac{1}{n}\sum\limits_{i = 1}^{n}y_{i}
$$
$$
l_{xy}=\sum\limits_{i = 1}^{n}(x_{i}-\overline{x})(y_{i}-\overline{y})=\sum\limits_{i = 1}^{n}x_{i}y_{i}-n\overline{x}\ \overline{y}
$$
$$
l_{xx}=\sum\limits_{i = 1}^{n}(x_{i}-\overline{x})^{2}=\sum\limits_{i = 1}^{n}x_{i}^{2}-n\overline{x}^{2}
$$
$\sigma^{2}$ 的估计：
由回归假定 $E(\epsilon_{i}) = 0, D(\epsilon_{i}) = \sigma^{2}$，有 $\sigma^{2}=D(\epsilon)=E(\epsilon^{2})$，故 $\frac{1}{n}\sum^{n}_{i=1}\epsilon_{i}^{2}$ 是 $\sigma^{2}$ 的矩估计量。
$\sigma^{2}$ 的无偏估计量为
$$
\hat{\sigma}^{2}=\frac{1}{n-2}\sum^{n}_{i=1}(y_{i}-\hat{y_{i}})^{2}
$$
代入 $\hat{y}_i = \hat{a} + \hat{b}x_i$，得
$$
\hat{\sigma}^2 = \frac{1}{n - 2}(l_{yy} - \hat{b}^2 l_{xx})
$$
其中
$$
l_{yy} = \sum_{i = 1}^{n}(y_{i} - \bar{y})^{2} = \sum_{i = 1}^{n}y_{i}^{2} - n\bar{y}^{2}
$$

##### 一元线性回归的假设检验（相关系数法）
相关系数：
$$
\rho_{\small{X Y}} = \frac{\operatorname{cov}(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}} = \frac{E\{[X-E(X)][Y-E(Y)]\}}{\sqrt{D(X)}\sqrt{D(Y)}}
$$
样本相关系数：
$$
\hat{\rho}_{\small{XY}} = R = \frac{\frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})(y_i - \bar{y})}{\sqrt{\frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2}\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \bar{y})^2}}= \frac{l_{xy}}{\sqrt{l_{xx}}\sqrt{l_{yy}}}
$$
结论：
1. $|R|$ 越接近于1，X与Y间的线性相关关系越显著；
2. $|R|$ 越靠近于0，X与Y间的线性相关关系越不显著。

判别准则：
1. 给定显著性水平 $\alpha$，当 $|R| > R_{\alpha}(n-2)$ 认为 X 与 Y 之间的线性相关关系显著；
2. 给定显著性水平 $\alpha$，当 $|R| \leq R_{\alpha}(n-2)$ 认为 X 与 Y 之间的线性相关关系显著。

可以通过求对数等方法将变量间相关关系转换成线性关系。
